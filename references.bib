
@article{chen2023ElectrochemicalMemristorBased,
	title = {Electrochemical-{Memristor}-{Based} {Artificial} {Neurons} and {Synapses}—{Fundamentals}, {Applications}, and {Challenges}},
	volume = {n/a},
	copyright = {© 2023 The Authors. Advanced Materials published by Wiley-VCH GmbH},
	issn = {1521-4095},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/adma.202301924},
	doi = {10.1002/adma.202301924},
	abstract = {Artificial neurons and synapses are considered essential for the progress of the future brain-inspired computing, based on beyond von Neumann architectures. Here, a discussion on the common electrochemical fundamentals of biological and artificial cells is provided, focusing on their similarities with the redox-based memristive devices. The driving forces behind the functionalities and the ways to control them by an electrochemical-materials approach are presented. Factors such as the chemical symmetry of the electrodes, doping of the solid electrolyte, concentration gradients, and excess surface energy are discussed as essential to understand, predict, and design artificial neurons and synapses. A variety of two- and three-terminal memristive devices and memristive architectures are presented and their application for solving various problems is shown. The work provides an overview of the current understandings on the complex processes of neural signal generation and transmission in both biological and artificial cells and presents the state-of-the-art applications, including signal transmission between biological and artificial cells. This example is showcasing the possibility for creating bioelectronic interfaces and integrating artificial circuits in biological systems. Prospectives and challenges of the modern technology toward low-power, high-information-density circuits are highlighted.},
	language = {en},
	number = {n/a},
	urldate = {2023-08-13},
	journal = {Advanced Materials},
	author = {Chen, Shaochuan and Zhang, Teng and Tappertzhofen, Stefan and Yang, Yuchao and Valov, Ilia},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/adma.202301924},
	keywords = {/unread, artificial neurons and synapses, brain-inspired computing, memristors, nanoionics},
	pages = {2301924},
}

@article{recht2019Tour,
	title = {A {Tour} of {Reinforcement} {Learning}: {The} {View} from {Continuous} {Control}},
	volume = {2},
	shorttitle = {A {Tour} of {Reinforcement} {Learning}},
	url = {https://doi.org/10.1146/annurev-control-053018-023825},
	doi = {10.1146/annurev-control-053018-023825},
	abstract = {This article surveys reinforcement learning from the perspective of optimization and control, with a focus on continuous control applications. It reviews the general formulation, terminology, and typical experimental implementations of reinforcement learning as well as competing solution paradigms. In order to compare the relative merits of various techniques, it presents a case study of the linear quadratic regulator (LQR) with unknown dynamics, perhaps the simplest and best-studied problem in optimal control. It also describes how merging techniques from learning theory and control can provide nonasymptotic characterizations of LQR performance and shows that these characterizations tend to match experimental behavior. In turn, when revisiting more complex applications, many of the observed phenomena in LQR persist. In particular, theory and experiment demonstrate the role and importance of models and the cost of generality in reinforcement learning algorithms. The article concludes with a discussion of some of the challenges in designing learning systems that safely and reliably interact with complex and uncertain environments and how tools from reinforcement learning and control might be combined to approach these challenges.},
	number = {1},
	urldate = {2023-03-09},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Recht, Benjamin},
	year = {2019},
	note = {432 citations (Semantic Scholar/DOI) [2023-04-11]
\_eprint: https://doi.org/10.1146/annurev-control-053018-023825},
	keywords = {/unread, Review, control theory, machine learning, optimization, reinforcement learning},
	pages = {253--279},
}

@article{gong2010Review,
	title = {A {Review} of {Gait} {Optimization} {Based} on {Evolutionary} {Computation}},
	volume = {2010},
	issn = {1687-9724},
	url = {https://www.hindawi.com/journals/acisc/2010/413179/},
	doi = {10.1155/2010/413179},
	abstract = {Gait generation is very important as it directly affects the quality of locomotion of legged robots. As this is an optimization problem with constraints, it readily lends itself to Evolutionary Computation methods and solutions. This paper reviews the techniques used in evolution-based gait optimization, including why Evolutionary Computation techniques should be used, how fitness functions should be composed, and the selection of genetic operators and control parameters. This paper also addresses further possible improvements in the efficiency and quality of evolutionary gait optimization, some problems that have not yet been resolved and the perspectives for related future research.},
	language = {en},
	urldate = {2023-08-13},
	journal = {Applied Computational Intelligence and Soft Computing},
	author = {Gong, Daoxiong and Yan, Jie and Zuo, Guoyu},
	month = jun,
	year = {2010},
	note = {Publisher: Hindawi},
	keywords = {/unread},
	pages = {e413179},
}

@article{hawkes2017Soft,
	title = {A soft robot that navigates its environment through growth},
	volume = {2},
	issn = {2470-9476},
	doi = {10.1126/scirobotics.aan3028},
	abstract = {Across kingdoms and length scales, certain cells and organisms navigate their environments not through locomotion but through growth. This pattern of movement is found in fungal hyphae, developing neurons, and trailing plants, and is characterized by extension from the tip of the body, length change of hundreds of percent, and active control of growth direction. This results in the abilities to move through tightly constrained environments and form useful three-dimensional structures from the body. We report a class of soft pneumatic robot that is capable of a basic form of this behavior, growing substantially in length from the tip while actively controlling direction using onboard sensing of environmental stimuli; further, the peak rate of lengthening is comparable to rates of animal and robot locomotion. This is enabled by two principles: Pressurization of an inverted thin-walled vessel allows rapid and substantial lengthening of the tip of the robot body, and controlled asymmetric lengthening of the tip allows directional control. Further, we demonstrate the abilities to lengthen through constrained environments by exploiting passive deformations and form three-dimensional structures by lengthening the body of the robot along a path. Our study helps lay the foundation for engineered systems that grow to navigate the environment.},
	language = {eng},
	number = {8},
	journal = {Science Robotics},
	author = {Hawkes, Elliot W. and Blumenschein, Laura H. and Greer, Joseph D. and Okamura, Allison M.},
	month = jul,
	year = {2017},
	pmid = {33157883},
	note = {409 citations (Crossref) [2022-12-07]},
	keywords = {/unread},
	pages = {eaan3028},
}

@inproceedings{muralidharan2021Soft,
	title = {A soft quadruped robot enabled by continuum actuators},
	doi = {10.1109/CASE49439.2021.9551496},
	abstract = {Soft robots are a group of robots made from highly compliant materials. Compared to their rigid counterparts, soft robots show better mobility and stronger adaptability to the environment. Specifically, soft quadruped robots, using four soft actuators as robot legs, have become a popular design, and are proven to be feasible and reliable in performing soft locomotion. Traditional soft quadruped robots are actuated using pneumatic forces which require high pressure sources. Additionally, the travel range of these robots are limited. This paper proposes a new design of soft quadruped robot that is fully actuated with electric motors. The main components of the robot are 3D printed and can be easily assembled. The four soft legs of the robot are modeled with experimental data and a closed loop controller is developed to regulate the deformation and motion. The legs can perform complex movement which enables the quadruped robot to move with different gaits.},
	booktitle = {2021 {IEEE} 17th {International} {Conference} on {Automation} {Science} and {Engineering} ({CASE})},
	author = {Muralidharan, Seshagopalan Thorapalli and Zhu, Ruihao and Ji, Qinglei and Feng, Lei and Wang, Xi Vincent and Wang, Lihui},
	month = aug,
	year = {2021},
	note = {3 citations (Semantic Scholar/DOI) [2023-04-11]
0 citations (Crossref) [2022-12-07]
ISSN: 2161-8089},
	keywords = {/unread, 3D printing, Actuators, Legged locomotion, Pneumatic systems, Printing, Reliability engineering, Soft quadruped robot, Soft robotics, Three-dimensional displays, closed loop control, continuum actuators},
	pages = {834--840},
}

@article{taheri2023Study,
	title = {A study on quadruped mobile robots},
	volume = {190},
	issn = {0094-114X},
	url = {https://www.sciencedirect.com/science/article/pii/S0094114X23002197},
	doi = {10.1016/j.mechmachtheory.2023.105448},
	abstract = {In recent years, quadruped mobile robots’ development had experienced rapid progress, which has subsequently increased their usage in many human-assisted applications. Numerous researchers from different fields such as mechanics, computers, electronics, biologics, etc. have contributed significantly to advance the quadruped robot developments. In this work, we propose a profound study on the quadruped robots’ mechanism and control and highlight crucial development in the state-of-the-art techniques. Furthermore, we provide a comprehensive review of the most advanced robots that have impacts on the state-of-the-art techniques. In addition, we classify the key leg mechanisms and topologies, joint configurations, actuation systems, gait planning, stabilization, and control approaches. We presented reviews of various techniques such as kinematics, dynamics models and control approaches, and gait planning challenges and solutions. Moreover, we discuss the past and current state of the quadruped mobile robots’ mechanisms and applications, control and trending control approaches, key challenges, and future possible trends. In conclusion, this research provides a comprehensive work on the key aspects of quadruped robot mechanisms, control approaches, evolution, and future trend.},
	urldate = {2023-11-02},
	journal = {Mechanism and Machine Theory},
	author = {Taheri, Hamid and Mozayani, Nasser},
	month = dec,
	year = {2023},
	keywords = {/unread, Dynamics, Gait, Kinematics, Mechanisms, Mobile robotics, Quadruped mobile robots},
	pages = {105448},
}

@article{yu2019Review,
	title = {A {Review} of {Recurrent} {Neural} {Networks}: {LSTM} {Cells} and {Network} {Architectures}},
	volume = {31},
	issn = {0899-7667},
	shorttitle = {A {Review} of {Recurrent} {Neural} {Networks}},
	url = {https://doi.org/10.1162/neco_a_01199},
	doi = {10.1162/neco_a_01199},
	abstract = {Recurrent neural networks (RNNs) have been widely adopted in research areas concerned with sequential data, such as text, audio, and video. However, RNNs consisting of sigma cells or tanh cells are unable to learn the relevant information of input data when the input gap is large. By introducing gate functions into the cell structure, the long short-term memory (LSTM) could handle the problem of long-term dependencies well. Since its introduction, almost all the exciting results based on RNNs have been achieved by the LSTM. The LSTM has become the focus of deep learning. We review the LSTM cell and its variants to explore the learning capacity of the LSTM cell. Furthermore, the LSTM networks are divided into two broad categories: LSTM-dominated networks and integrated LSTM networks. In addition, their various applications are discussed. Finally, future research directions are presented for LSTM networks.},
	number = {7},
	urldate = {2023-10-13},
	journal = {Neural Computation},
	author = {Yu, Yong and Si, Xiaosheng and Hu, Changhua and Zhang, Jianxun},
	month = jul,
	year = {2019},
	keywords = {/unread},
	pages = {1235--1270},
}

@article{denavit1955Kinematic,
	title = {A {Kinematic} {Notation} for {Lower}-{Pair} {Mechanisms} {Based} on {Matrices}},
	volume = {22},
	issn = {0021-8936},
	url = {https://doi.org/10.1115/1.4011045},
	doi = {10.1115/1.4011045},
	abstract = {A symbolic notation devised by Reuleaux to describe mechanisms did not recognize the necessary number of variables needed for complete description. A reconsideration of the problem leads to a symbolic notation which permits the complete description of the kinematic properties of all lower-pair mechanisms by means of equations. The symbolic notation also yields a method for studying lower-pair mechanisms by means of matrix algebra; two examples of application to space mechanisms are given.},
	number = {2},
	urldate = {2023-07-06},
	journal = {Journal of Applied Mechanics},
	author = {Denavit, J. and Hartenberg, R. S.},
	month = dec,
	year = {1955},
	keywords = {/unread},
	pages = {215--221},
}

@article{tolley2014Resilient,
	title = {A {Resilient}, {Untethered} {Soft} {Robot}},
	volume = {1},
	issn = {2169-5172},
	url = {https://www.liebertpub.com/doi/10.1089%2Fsoro.2014.0008},
	doi = {10.1089/soro.2014.0008},
	abstract = {A pneumatically powered, fully untethered mobile soft robot is described. Composites consisting of silicone elastomer, polyaramid fabric, and hollow glass microspheres were used to fabricate a sufficiently large soft robot to carry the miniature air compressors, battery, valves, and controller needed for autonomous operation. Fabrication techniques were developed to mold a 0.65-meter-long soft body with modified Pneu-Net actuators capable of operating at the elevated pressures (up to 138 kPa) required to actuate the legs of the robot and hold payloads of up to 8 kg. The soft robot is safe to interact with during operation, and its silicone body is innately resilient to a variety of adverse environmental conditions including snow, puddles of water, direct (albeit limited) exposure to flames, and the crushing force of being run over by an automobile.},
	number = {3},
	urldate = {2023-11-12},
	journal = {Soft Robotics},
	author = {Tolley, Michael T. and Shepherd, Robert F. and Mosadegh, Bobak and Galloway, Kevin C. and Wehner, Michael and Karpelson, Michael and Wood, Robert J. and Whitesides, George M.},
	month = sep,
	year = {2014},
	note = {Publisher: Mary Ann Liebert, Inc., publishers},
	keywords = {/unread},
	pages = {213--223},
}

@article{ding2020Novel,
	title = {A {Novel} {Dynamic} {Locomotion} {Control} {Method} for {Quadruped} {Robots} {Running} on {Rough} {Terrains}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.3016312},
	abstract = {Quadruped robots have excellent application prospects whereas the locomotion control of them on rough terrains is still a challenging problem, especially for those of large scales. The existing methods are either too complicated or lack of accuracies due to assumptions used. This paper presents a novel control algorithm for quadruped robots running on rough terrains inspired by the virtual model control and the model predictive control. State recursions are carried out based on the dynamic model of the trunk during the standing phase. The modeling of the body is implemented in the self-defined motion reference frame that avoids global state estimations and accumulative errors. The force distribution of the standing legs is realized by quadratic optimization involving state predictions. Forces of the swing legs are calculated by the virtual spring-damping model that follow the desired trajectory which is robust to external disturbances. These two sub-controllers are combined by the time-force based state machine. Simulation results show that the quadruped robot obtains the adaptability to rough terrains and robustness to lateral pushes with the proposed method.},
	journal = {IEEE Access},
	author = {Ding, Chao and Zhou, Lelai and Li, Yibin and Rong, Xuewen},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {/unread, Adaptation models, Dynamics, Legged locomotion, Model predictive control, Robot kinematics, Robot sensing systems, Trajectory, quadratic optimization, quadruped robots, terrain adaptation, virtual model control},
	pages = {150435--150446},
}

@article{owaki2017Quadruped,
	title = {A {Quadruped} {Robot} {Exhibiting} {Spontaneous} {Gait} {Transitions} from {Walking} to {Trotting} to {Galloping}},
	volume = {7},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-017-00348-9},
	doi = {10.1038/s41598-017-00348-9},
	abstract = {Abstract
            
              The manner in which quadrupeds change their locomotive patterns—walking, trotting, and galloping—with changing speed is poorly understood. In this paper, we provide evidence for interlimb coordination during gait transitions using a quadruped robot for which coordination between the legs can be self-organized through a simple “central pattern generator” (CPG) model. We demonstrate spontaneous gait transitions between energy-efficient patterns by changing only the parameter related to speed. Interlimb coordination was achieved with the use of local load sensing only without any preprogrammed patterns. Our model exploits
              physical communication
              through the body, suggesting that knowledge of physical communication is required to understand the leg coordination mechanism in legged animals and to establish design principles for legged robots that can reproduce flexible and efficient locomotion.},
	language = {en},
	number = {1},
	urldate = {2023-02-28},
	journal = {Scientific Reports},
	author = {Owaki, Dai and Ishiguro, Akio},
	month = mar,
	year = {2017},
	note = {0 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread},
	pages = {277},
}

@article{li2022Quadruped,
	title = {A quadruped robot obstacle avoidance and personnel following strategy based on ultra-wideband and three-dimensional laser radar},
	volume = {19},
	issn = {1729-8806},
	url = {https://doi.org/10.1177/17298806221114705},
	doi = {10.1177/17298806221114705},
	abstract = {To improve the human–computer interaction ability and environmental adaptability of the quadruped robot, especially the ability of the quadruped robot to follow people and avoid obstacles. In this article, the fusion of ultra-wideband positioning technology and three-dimensional laser radar is applied to a quadruped robot. The core is to scan the surrounding obstacle information through three-dimensional laser radar, locate the position of both the quadruped robot and the target person, complete the obstacle avoidance, and follow the task of the quadruped robot through an efficient path planning algorithm. To meet the high-precision positioning requirements, the ultra-wideband positioning system is used in this article. When calculating the coordinates, we propose a three-sided weighted least squares positioning algorithm. To improve the efficiency and stability of the quadruped robot in path search, based on the A* algorithm, this article improves and proposes an incremental A* algorithm based on a sliding window. The feasibility and effectiveness of our method are verified by computer simulation analysis and real experiments of the quadruped robot.},
	language = {en},
	number = {4},
	urldate = {2023-07-03},
	journal = {International Journal of Advanced Robotic Systems},
	author = {Li, Zhi and Li, Bin and Liang, Qixing and Liu, Weilong and Hou, Landong and Rong, Xuewen},
	month = jul,
	year = {2022},
	note = {Publisher: SAGE Publications},
	keywords = {/unread},
	pages = {17298806221114705},
}

@inproceedings{atkeson1997Comparison,
	title = {A comparison of direct and model-based reinforcement learning},
	volume = {4},
	doi = {10.1109/ROBOT.1997.606886},
	abstract = {This paper compares direct reinforcement learning (no explicit model) and model-based reinforcement learning on a simple task: pendulum swing up. We find that in this task model-based approaches support reinforcement learning from smaller amounts of training data and efficient handling of changing goals.},
	booktitle = {Proceedings of {International} {Conference} on {Robotics} and {Automation}},
	author = {Atkeson, C.G. and Santamaria, J.C.},
	month = apr,
	year = {1997},
	note = {261 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread, Computational modeling, Control system synthesis, Control systems, Educational institutions, Force control, Jacobian matrices, Learning, Robots, State-space methods, Training data},
	pages = {3557--3564 vol.4},
}

@misc{lipton2015Critical,
	title = {A {Critical} {Review} of {Recurrent} {Neural} {Networks} for {Sequence} {Learning}},
	url = {http://arxiv.org/abs/1506.00019},
	doi = {10.48550/arXiv.1506.00019},
	abstract = {Countless learning tasks require dealing with sequential data. Image captioning, speech synthesis, and music generation all require that a model produce outputs that are sequences. In other domains, such as time series prediction, video analysis, and musical information retrieval, a model must learn from inputs that are sequences. Interactive tasks, such as translating natural language, engaging in dialogue, and controlling a robot, often demand both capabilities. Recurrent neural networks (RNNs) are connectionist models that capture the dynamics of sequences via cycles in the network of nodes. Unlike standard feedforward neural networks, recurrent networks retain a state that can represent information from an arbitrarily long context window. Although recurrent neural networks have traditionally been difficult to train, and often contain millions of parameters, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful large-scale learning with them. In recent years, systems based on long short-term memory (LSTM) and bidirectional (BRNN) architectures have demonstrated ground-breaking performance on tasks as varied as image captioning, language translation, and handwriting recognition. In this survey, we review and synthesize the research that over the past three decades first yielded and then made practical these powerful learning models. When appropriate, we reconcile conflicting notation and nomenclature. Our goal is to provide a self-contained explication of the state of the art together with a historical perspective and references to primary research.},
	urldate = {2023-08-13},
	publisher = {arXiv},
	author = {Lipton, Zachary C. and Berkowitz, John and Elkan, Charles},
	month = oct,
	year = {2015},
	note = {arXiv:1506.00019 [cs]},
	keywords = {/unread, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{wang2022Hierarchical,
	title = {A {Hierarchical} {Reinforcement} {Learning} {Framework} based on {Soft} {Actor}-{Critic} for {Quadruped} {Gait} {Generation}},
	doi = {10.1109/ROBIO55434.2022.10011919},
	abstract = {Recently, reinforcement learning has become a promising control method of legged robot. However, it is challenging to train from scratch which requires perfect networks and reward design. In this paper, a hierarchical reinforcement learning framework based on Soft Actor-Critic has been proposed to find the appropriate gait of quadruped robot in the environment. The framework is composed of a low-level policy for generating joint reference trajectory and a high-level policy for gait optimization. In low-level policy, we use radial basis network and evolutionary computation solver to change the shape of reference trajectory in order to search for a better reference trajectory. In high-level policy, joint angle increment is learned to optimize gait. The experimental results show that the hierarchical framework is better than that of using Soft Actor-Critic only.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Robotics} and {Biomimetics} ({ROBIO})},
	author = {Wang, Yu and Jia, Wenchuan and Sun, Yi},
	month = dec,
	year = {2022},
	keywords = {/unread, Evolutionary computation, Radial basis function networks, Reinforcement learning, Shape, Space exploration, Training, Trajectory},
	pages = {1970--1975},
}

@inproceedings{koenig1996Unsupervised,
	title = {Unsupervised learning of probabilistic models for robot navigation},
	volume = {3},
	url = {https://ieeexplore.ieee.org/abstract/document/506507/authors#authors},
	doi = {10.1109/ROBOT.1996.506507},
	abstract = {Navigation methods for office delivery robots need to take various sources of uncertainty into account in order to get robust performance. In previous work, we developed a reliable navigation technique that uses partially observable Markov models to represent metric, actuator and sensor uncertainties. This paper describes an algorithm that adjusts the probabilities of the initial Markov model by passively observing the robot's interactions with its environment. The learned probabilities more accurately reflect the actual uncertainties in the environment, which ultimately leads to improved navigation performance. The algorithm, an extension of the Baum-Welch algorithm, learns without a teacher and addresses the issues of limited memory and the cost of collecting training data. Empirical results show that the algorithm learns good Markov models with a small amount of training data.},
	urldate = {2023-10-06},
	booktitle = {Proceedings of {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Koenig, S. and Simmons, R.G.},
	month = apr,
	year = {1996},
	note = {ISSN: 1050-4729},
	keywords = {/unread},
	pages = {2301--2308 vol.3},
}

@inproceedings{dai2014Wholebody,
	title = {Whole-body motion planning with centroidal dynamics and full kinematics},
	doi = {10.1109/HUMANOIDS.2014.7041375},
	abstract = {To plan dynamic, whole-body motions for robots, one conventionally faces the choice between a complex, full-body dynamic model containing every link and actuator of the robot, or a highly simplified model of the robot as a point mass. In this paper we explore a powerful middle ground between these extremes. We exploit the fact that while the full dynamics of humanoid robots are complicated, their centroidal dynamics (the evolution of the angular momentum and the center of mass (COM) position) are much simpler. By treating the dynamics of the robot in centroidal form and directly optimizing the joint trajectories for the actuated degrees of freedom, we arrive at a method that enjoys simpler dynamics, while still having the expressiveness required to handle kinematic constraints such as collision avoidance or reaching to a target. We further require that the robot's COM and angular momentum as computed from the joint trajectories match those given by the centroidal dynamics. This ensures that the dynamics considered by our optimization are equivalent to the full dynamics of the robot, provided that the robot's actuators can supply sufficient torque. We demonstrate that this algorithm is capable of generating highly-dynamic motion plans with examples of a humanoid robot negotiating obstacle course elements and gait optimization for a quadrupedal robot. Additionally, we show that we can plan without pre-specifying the contact sequence by exploiting the complementarity conditions between contact forces and contact distance.},
	booktitle = {2014 {IEEE}-{RAS} {International} {Conference} on {Humanoid} {Robots}},
	author = {Dai, Hongkai and Valenzuela, Andrés and Tedrake, Russ},
	month = nov,
	year = {2014},
	note = {ISSN: 2164-0580},
	keywords = {/unread, Collision avoidance, Dynamics, Joints, Kinematics, Optimization, Robots, Trajectory},
	pages = {295--302},
}

@inproceedings{janner2019When,
	title = {When to {Trust} {Your} {Model}: {Model}-{Based} {Policy} {Optimization}},
	shorttitle = {When to {Trust} {Your} {Model}},
	url = {http://arxiv.org/abs/1906.08253},
	doi = {10.48550/arXiv.1906.08253},
	abstract = {Designing effective model-based reinforcement learning algorithms is difficult because the ease of data generation must be weighed against the bias of model-generated data. In this paper, we study the role of model usage in policy optimization both theoretically and empirically. We first formulate and analyze a model-based reinforcement learning algorithm with a guarantee of monotonic improvement at each step. In practice, this analysis is overly pessimistic and suggests that real off-policy data is always preferable to model-generated on-policy data, but we show that an empirical estimate of model generalization can be incorporated into such analysis to justify model usage. Motivated by this analysis, we then demonstrate that a simple procedure of using short model-generated rollouts branched from real data has the benefits of more complicated model-based algorithms without the usual pitfalls. In particular, this approach surpasses the sample efficiency of prior model-based methods, matches the asymptotic performance of the best model-free algorithms, and scales to horizons that cause other model-based methods to fail entirely.},
	urldate = {2023-04-21},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} ({NeurIPS})},
	author = {Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
	month = jun,
	year = {2019},
	note = {arXiv:1906.08253 [cs, stat]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{drotman20173D,
	title = {{3D} printed soft actuators for a legged robot capable of navigating unstructured terrain},
	doi = {10.1109/ICRA.2017.7989652},
	abstract = {Soft robots have recently demonstrated impressive abilities to adapt to objects and their environment with limited sensing and actuation. However, mobile soft robots are typically fabricated using laborious molding processes that result in limited actuated degrees of freedom and hence limited locomotion capabilities. In this paper, we present a 3D printed robot with bellowed soft legs capable of rotation about two axes. This allows our robot to navigate rough terrain that previously posed a significant challenge to soft robots. We present models and FEM simulations for the soft leg modules and predict the robot locomotion capabilities. We use finite element analysis to simulate the actuation characteristics of these modules. We then compared the analytical and computational results to experimental results with a tethered prototype. The experimental soft robot is capable of lifting its legs 5.3 cm off the ground and is able to walk at speeds up to 20 mm/s (0.13 bl/s). This work represents a practical approach to the design and fabrication of functional mobile soft robots.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Drotman, Dylan and Jadhav, Saurabh and Karimi, Mahmood and de Zonia, Philip and Tolley, Michael T.},
	month = may,
	year = {2017},
	note = {118 citations (Semantic Scholar/DOI) [2023-04-11]
91 citations (Crossref) [2022-12-07]},
	keywords = {/unread, Actuators, Bellows, Force, Geometry, Legged locomotion, Three-dimensional print},
	pages = {5532--5538},
}

@article{sprowitz2013Dynamic,
	title = {Towards dynamic trot gait locomotion: {Design}, control, and experiments with {Cheetah}-cub, a compliant quadruped robot},
	volume = {32},
	issn = {0278-3649},
	shorttitle = {Towards dynamic trot gait locomotion},
	url = {https://doi.org/10.1177/0278364913489205},
	doi = {10.1177/0278364913489205},
	abstract = {We present the design of a novel compliant quadruped robot, called Cheetah-cub, and a series of locomotion experiments with fast trotting gaits. The robot’s leg configuration is based on a spring-loaded, pantograph mechanism with multiple segments. A dedicated open-loop locomotion controller was derived and implemented. Experiments were run in simulation and in hardware on flat terrain and with a step down, demonstrating the robot’s self-stabilizing properties. The robot reached a running trot with short flight phases with a maximum Froude number of FR = 1.30, or 6.9 body lengths per second. Morphological parameters such as the leg design also played a role. By adding distal in-series elasticity, self-stability and maximum robot speed improved. Our robot has several advantages, especially when compared with larger and stiffer quadruped robot designs. (1) It is, to the best of the authors’ knowledge, the fastest of all quadruped robots below 30kg (in terms of Froude number and body lengths per second). (2) It shows self-stabilizing behavior over a large range of speeds with open-loop control. (3) It is lightweight, compact, and electrically powered. (4) It is cheap, easy to reproduce, robust, and safe to handle. This makes it an excellent tool for research of multi-segment legs in quadruped robots.},
	language = {en},
	number = {8},
	urldate = {2023-07-08},
	journal = {The International Journal of Robotics Research},
	author = {Spröwitz, Alexander and Tuleu, Alexandre and Vespignani, Massimo and Ajallooeian, Mostafa and Badri, Emilie and Ijspeert, Auke Jan},
	month = jul,
	year = {2013},
	note = {Publisher: SAGE Publications Ltd STM},
	keywords = {/unread},
	pages = {932--950},
}

@inproceedings{lee2017Trajectory,
	title = {Trajectory design and control of quadruped robot for trotting over obstacles},
	doi = {10.1109/IROS.2017.8206368},
	abstract = {Various control strategies using trajectory planning, object recognition and learning are researched for avoiding obstacles when legged robot is walking. In this paper, designed trajectory by using Non Uniform Basis Spline (NUBS) curve and control strategy, by using proposed trajectory, to effectively overcome obstacles are presented. The trajectory designed by NUBS curve has several advantages: 1) local modification, 2) tracking velocity control for each domain, and 3) low degree trajectory with a large number of control points. The robot gets remarkable effectiveness when these advantages are used to generate the trajectory for walking and overcoming obstacles. By implementation of the proposed control strategy, quadruped robot can walk over obstacles while keeping its gait, speed and balance without collision although adjusting relatively preferable state which is more suitable position or posture of the walking robot shortly before encountering obstacles is not required. The proposed trajectory and control strategy are discussed, and performance is validated through experimental evaluations.},
	booktitle = {2017 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Lee, Young Hun and Lee, Yoon Haeng and Lee, Hyunyong and Phan, Luong Tin and Kang, Hansol and Kim, Uikyum and Jeon, Jeongmin and Choi, Hyouk Ryeol},
	month = sep,
	year = {2017},
	note = {ISSN: 2153-0866},
	keywords = {/unread, Collision avoidance, Foot, Legged locomotion, Robot sensing systems, Trajectory, Velocity control},
	pages = {4897--4902},
}

@inproceedings{albawi2017Understanding,
	title = {Understanding of a convolutional neural network},
	doi = {10.1109/ICEngTechnol.2017.8308186},
	abstract = {The term Deep Learning or Deep Neural Network refers to Artificial Neural Networks (ANN) with multi layers. Over the last few decades, it has been considered to be one of the most powerful tools, and has become very popular in the literature as it is able to handle a huge amount of data. The interest in having deeper hidden layers has recently begun to surpass classical methods performance in different fields; especially in pattern recognition. One of the most popular deep neural networks is the Convolutional Neural Network (CNN). It take this name from mathematical linear operation between matrixes called convolution. CNN have multiple layers; including convolutional layer, non-linearity layer, pooling layer and fully-connected layer. The convolutional and fully-connected layers have parameters but pooling and non-linearity layers don't have parameters. The CNN has an excellent performance in machine learning problems. Specially the applications that deal with image data, such as largest image classification data set (Image Net), computer vision, and in natural language processing (NLP) and the results achieved were very amazing. In this paper we will explain and define all the elements and important issues related to CNN, and how these elements work. In addition, we will also state the parameters that effect CNN efficiency. This paper assumes that the readers have adequate knowledge about both machine learning and artificial neural network.},
	booktitle = {2017 {International} {Conference} on {Engineering} and {Technology} ({ICET})},
	author = {Albawi, Saad and Mohammed, Tareq Abed and Al-Zawi, Saad},
	month = aug,
	year = {2017},
	keywords = {/unread, Convolution, Convolutional neural networks, Feature extraction, Image edge detection, Image recognition, Neurons, artificial neural networks, computer vision, convolutional neural networks, deep learning, machine learning},
	pages = {1--6},
}

@misc{fletcher2012Trot,
	title = {Trot},
	url = {http://vanat.cvm.umn.edu/gaits/trot.html},
	abstract = {A running trot is shown in the above cartoon. The step sequence of the trot is shown at the right. The trot is a two-beat gait. Right and left diagonals alternate in supporting weight, i.e., the right forelimb and left hind limb move in unison as do left forelimb and right hind limb. The diagonal is named for the involved forelimb (right/left). Actually, the hind limb of the diagonal impacts slightly earlier than the fore limb, though they appear to impact simultaneously. The hind limb provides both vertical and forward propulsion. The trunk is carried rigidly, undergoing only vertical oscillations, and the neck and head are fixed in an upright position during the trot. In the running trot (quick trot; brisk trot; flying trot) a suspension phase intervenes between each diagonal support phase (illustrated above and left). As the stride is lengthened in the running trot, interference can become a problem (the hind paw hits the ipsilateral forelimb). To avoid interference, the fore paw must be lifted before the ipsilateral hind paw arrives, or the hind paw must land to the side of the fore paw, or the animal must resort to crab-running (trunk at an angle to the line of progression). In a slow trot, the suspension phase is absent, so the body is always supported by one diagonal or the other. If the support phase is prolonged and the swing phase is shortened, three-limb support may intervene between the diagonal support phases. The trot is a common gait in all domestic quadrupeds. It is well-suited for rough, irregular ground and for traveling long distances at a fair rate of speed. Work is spread evenly over all four limbs, and diagonal support makes it easy to maintain equilibrium. The trot is the natural foraging gait of most wild animals. Relative to other quadrupeds, the dog exhibits a greater variety of trot variations (dog-trot; thrown trot; swung trot). In a "dog-trot", the forelimb precedes the hindlimb at impact and lift. The German Shepherd typically exhibits suspension (running trot; flying trot) when it trots. It's long body and low center of gravity of precludes interference and the need for compensatory crab-running. The running trot is used by racing Standardbred horses. Interference is avoided by developing a long-bodied (long-coupled) horse, or the problem is minimized by using protective shoes.},
	language = {en},
	urldate = {2023-03-06},
	journal = {Trot},
	author = {Fletcher, Thomas F. and Datt (nee Johnson), Vicki L.},
	month = aug,
	year = {2012},
	keywords = {/unread},
}

@article{billard2019Trends,
	title = {Trends and challenges in robot manipulation},
	volume = {364},
	url = {https://www.science.org/doi/full/10.1126/science.aat8414},
	doi = {10.1126/science.aat8414},
	abstract = {Dexterous manipulation is one of the primary goals in robotics. Robots with this capability could sort and package objects, chop vegetables, and fold clothes. As robots come to work side by side with humans, they must also become human-aware. Over the past decade, research has made strides toward these goals. Progress has come from advances in visual and haptic perception and in mechanics in the form of soft actuators that offer a natural compliance. Most notably, immense progress in machine learning has been leveraged to encapsulate models of uncertainty and to support improvements in adaptive and robust control. Open questions remain in terms of how to enable robots to deal with the most unpredictable agent of all, the human.},
	number = {6446},
	urldate = {2023-07-03},
	journal = {Science},
	author = {Billard, Aude and Kragic, Danica},
	month = jun,
	year = {2019},
	note = {Publisher: American Association for the Advancement of Science},
	keywords = {/unread},
	pages = {eaat8414},
}

@article{zhang2021Understanding,
	title = {Understanding deep learning (still) requires rethinking generalization},
	volume = {64},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/3446776},
	doi = {10.1145/3446776},
	abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small gap between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models. We supplement this republication with a new section at the end summarizing recent progresses in the field since the original version of this paper.},
	number = {3},
	urldate = {2023-08-13},
	journal = {Communications of the ACM},
	author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	year = {2021},
	keywords = {/unread},
	pages = {107--115},
}

@article{neunert2017Trajectory,
	title = {Trajectory {Optimization} {Through} {Contacts} and {Automatic} {Gait} {Discovery} for {Quadrupeds}},
	volume = {2},
	issn = {2377-3766},
	url = {https://ieeexplore.ieee.org/abstract/document/7845678/authors#authors},
	doi = {10.1109/LRA.2017.2665685},
	abstract = {In this letter, we present a trajectory optimization framework for whole-body motion planning through contacts. We demonstrate how the proposed approach can be applied to automatically discover different gaits and dynamic motions on a quadruped robot. In contrast to most previous methods, we do not prespecify contact-switches, -timings, -points or gait patterns, but they are a direct outcome of the optimization. Furthermore, we optimize over the entire dynamics of the robot, which enables the optimizer to fully leverage the capabilities of the robot. To illustrate the spectrum of achievable motions, we show eight different tasks, which would require very different control structures when solved with state-of-the-art methods. Using our trajectory optimization approach, we are solving each task with a simple, high level cost function and without any changes in the control structure. Furthermore, we fully integrate our approach with the robot's control and estimation framework such that we are able to run the optimization online. Through several hardware experiments, we show that the optimized trajectories and control inputs can be directly applied to physical systems.},
	number = {3},
	urldate = {2023-11-11},
	journal = {IEEE Robotics and Automation Letters},
	author = {Neunert, Michael and Farshidian, Farbod and Winkler, Alexander W. and Buchli, Jonas},
	month = jul,
	year = {2017},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {/unread},
	pages = {1502--1509},
}

@inproceedings{zhang2017Effective,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Toward {Effective} {Soft} {Robot} {Control} via {Reinforcement} {Learning}},
	isbn = {978-3-319-65289-4},
	doi = {10.1007/978-3-319-65289-4_17},
	abstract = {A soft robot is a kind of robot that is constructed with soft, deformable and elastic materials. Control of soft robots presents complex modeling and planning challenges. We introduce a new approach to accomplish that, making two key contributions: designing an abstract representation of the state of soft robots, and developing a reinforcement learning method to derive effective control policies. The reinforcement learning process can be trained quickly by ignoring the specific materials and structural properties of the soft robot. We apply the approach to the Honeycomb PneuNets Soft Robot and demonstrate the effectiveness of the training method and its ability to produce good control policies under different conditions.},
	language = {en},
	booktitle = {Intelligent {Robotics} and {Applications}},
	publisher = {Springer International Publishing},
	author = {Zhang, Haochong and Cao, Rongyun and Zilberstein, Shlomo and Wu, Feng and Chen, Xiaoping},
	editor = {Huang, YongAn and Wu, Hao and Liu, Honghai and Yin, Zhouping},
	year = {2017},
	note = {23 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread, PneuNets, Reinforcement learning, Soft robot control},
	pages = {173--184},
}

@inproceedings{riedo2013Thymio,
	title = {Thymio {II}, a robot that grows wiser with children},
	doi = {10.1109/ARSO.2013.6705527},
	abstract = {Thymio II is a small robot developed for education. It aims at offering a wide public the possibility to understand the basics of robotics and programming. To achieve this, it aims at being appealing to a large age range and serve as a medium for several types of activities. In this study, we tested it in five different workshops of the EPFL Robotics Festival with various activities. The workshops target different age groups and the participants can control the robot via different means: built-in buttons, graphical programming and text programming. At the end of the activities, participants were asked to fill a short survey to give their impressions about the robot, their appreciation of the tasks and their motivations to take part. We could show through this feedback that Thymio II appeals to young children as much as to teenagers, to both girls and boys, and allows them to have fun and learn new things.},
	booktitle = {2013 {IEEE} {Workshop} on {Advanced} {Robotics} and its {Social} {Impacts}},
	author = {Riedo, Fanny and Chevalier, Morgane and Magnenat, Stéphane and Mondada, Francesco},
	month = nov,
	year = {2013},
	note = {ISSN: 2162-7576},
	keywords = {/unread, Computers, Conferences, Educational institutions, Programming profession, Robot sensing systems},
	pages = {187--193},
}

@article{wu2018Structure,
	title = {The {Structure}, {Design}, and {Closed}-{Loop} {Motion} {Control} of a {Differential} {Drive} {Soft} {Robot}},
	volume = {5},
	issn = {2169-5172},
	url = {https://www.liebertpub.com/doi/full/10.1089/soro.2017.0042},
	doi = {10.1089/soro.2017.0042},
	abstract = {This article presents the structure, design, and motion control of an inchworm inspired pneumatic soft robot, which can perform differential movement. This robot mainly consists of two columns of pneumatic multi-airbags (actuators), one sensor, one baseboard, front feet, and rear feet. According to the different inflation time of left and right actuators, the robot can perform both linear and turning movements. The actuators of this robot are composed of multiple airbags, and the design of the airbags is analyzed. To deal with the nonlinear performance of the soft robot, we use radial basis function neural networks to train the turning ability of this robot on three different surfaces and create a mathematical model among coefficient of friction, deflection angle, and inflation time. Then, we establish the closed-loop automatic control model using three-axis electronic compass sensor. Finally, the automatic control model is verified by linear and turning movement experiments. According to the experiment, the robot can finish the linear and turning movements under the closed-loop control system.},
	number = {1},
	urldate = {2023-11-02},
	journal = {Soft Robotics},
	author = {Wu, Pang and Jiangbei, Wang and Yanqiong, Fei},
	month = feb,
	year = {2018},
	note = {Publisher: Mary Ann Liebert, Inc., publishers},
	keywords = {/unread, RBF neural networks, automatic control, differential movement, soft robot},
	pages = {71--80},
}

@article{poulakakis2009Spring,
	title = {The {Spring} {Loaded} {Inverted} {Pendulum} as the {Hybrid} {Zero} {Dynamics} of an {Asymmetric} {Hopper}},
	volume = {54},
	issn = {1558-2523},
	doi = {10.1109/TAC.2009.2024565},
	abstract = {A hybrid controller that induces provably stable running gaits on an asymmetric spring loaded inverted pendulum (ASLIP) is developed. The controller acts on two levels. On the first level, continuous within-stride control asymptotically imposes a (virtual) holonomic constraint corresponding to a desired torso posture, and creates an invariant surface on which the two-degree-of-freedom restriction dynamics of the closed-loop system (i.e., the hybrid zero dynamics) is diffeomorphic to the center-of-mass dynamics of a spring loaded inverted pendulum (SLIP). On the second level, event-based control stabilizes the closed-loop hybrid system along a periodic orbit of the SLIP dynamics. The controller's performance is discussed through comparison with a second control law that creates a one-degree-of-freedom non-compliant hybrid zero dynamics. Both controllers induce identical steady-state behaviors (i.e., periodic solutions). Under transient conditions, however, the controller inducing a compliant hybrid zero dynamics based on the SLIP accommodates significantly larger disturbances, with less actuator effort, and without violation of the unilateral ground force constraints.},
	number = {8},
	journal = {IEEE Transactions on Automatic Control},
	author = {Poulakakis, Ioannis and Grizzle, Jessy W.},
	month = aug,
	year = {2009},
	note = {Conference Name: IEEE Transactions on Automatic Control},
	keywords = {/unread, Actuators, Animals, Context modeling, Control systems, Dynamic running, Hybrid Zero Dynamics (HZD), Leg, Motion control, Predictive models, Robot kinematics, Spring Loaded Inverted Pendulum (SLIP), Springs, Torso, legged robots},
	pages = {1779--1793},
}

@article{huang2023Symmetryinformed,
	title = {Symmetry-informed {Reinforcement} {Learning} and {Its} {Application} to the {Attitude} {Control} of {Quadrotors}},
	issn = {2691-4581},
	doi = {10.1109/TAI.2023.3249683},
	abstract = {Symmetry is ubiquitous in nature, physics, and mathematics. However, a classical symmetry-agnostic Reinforcement Learning (RL) approach cannot guarantee to respect symmetry. Researchers have shown that if the symmetry of a system cannot be respected, the performance of a symmetry-agnostic RL approach can be inhibited. To this end, this paper develops a generally applicable Neural Network (NN) module with symmetry that can enforce the symmetry of a system to be respected. Based on the NN module with symmetry, this paper proposes a symmetry-informed Model-Based RL (MBRL) approach that respects symmetry and improves data efficiency. The symmetry-informed MBRL approach is applied to the attitude control of a quadrotor in simulation to evaluate the effectiveness of the approach. The simulation results show that the data efficiency of the symmetry-informed MBRL approach is much superior to that of a symmetry-agnostic MBRL approach. An NN module with symmetry can respect the symmetry of a quadrotor while a naive NN cannot enforce the symmetry of a quadrotor to be respected.},
	journal = {IEEE Transactions on Artificial Intelligence},
	author = {Huang, Junchang and Zeng, Weifeng and Xiong, Hao and Noack, Bernd R. and Hu, Gang and Liu, Shugao and Xu, Yuchen and Cao, Huanhui},
	year = {2023},
	note = {0 citations (Semantic Scholar/DOI) [2023-04-11]
Conference Name: IEEE Transactions on Artificial Intelligence},
	keywords = {/unread, Artificial neural networks, Attitude control, Data efficiency, Data models, Quadrotors, Reinforcement learning, Rotors, Torque, model-based reinforcement learning, neural network, quadrotor, symmetry},
	pages = {1--14},
}

@article{polydoros2017Survey,
	title = {Survey of {Model}-{Based} {Reinforcement} {Learning}: {Applications} on {Robotics}},
	volume = {86},
	issn = {1573-0409},
	shorttitle = {Survey of {Model}-{Based} {Reinforcement} {Learning}},
	url = {https://doi.org/10.1007/s10846-017-0468-y},
	doi = {10.1007/s10846-017-0468-y},
	abstract = {Reinforcement learning is an appealing approach for allowing robots to learn new tasks. Relevant literature reveals a plethora of methods, but at the same time makes clear the lack of implementations for dealing with real life challenges. Current expectations raise the demand for adaptable robots. We argue that, by employing model-based reinforcement learning, the—now limited—adaptability characteristics of robotic systems can be expanded. Also, model-based reinforcement learning exhibits advantages that makes it more applicable to real life use-cases compared to model-free methods. Thus, in this survey, model-based methods that have been applied in robotics are covered. We categorize them based on the derivation of an optimal policy, the definition of the returns function, the type of the transition model and the learned task. Finally, we discuss the applicability of model-based reinforcement learning approaches in new applications, taking into consideration the state of the art in both algorithms and hardware.},
	language = {en},
	number = {2},
	urldate = {2023-02-28},
	journal = {Journal of Intelligent \& Robotic Systems},
	author = {Polydoros, Athanasios S. and Nalpantidis, Lazaros},
	month = may,
	year = {2017},
	note = {0 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread},
	pages = {153--173},
}

@article{ji2022Synthesizing,
	title = {Synthesizing the optimal gait of a quadruped robot with soft actuators using deep reinforcement learning},
	volume = {78},
	issn = {0736-5845},
	url = {https://www.sciencedirect.com/science/article/pii/S0736584522000692},
	doi = {10.1016/j.rcim.2022.102382},
	abstract = {Quadruped robots have the advantages of traversing complex terrains that are difficult for wheeled robots. Most of the reported quadruped robots are built by rigid parts. This paper proposes a new design of quadruped robots using soft actuators driven by tendons as the four legs. Compared to the rigid robots, the proposed soft quadruped robot has inherent safety, less weight and simpler mechanism for fabrication and control, but the corresponding challenge is that the accurate mathematical model applicable to model-based control design of the soft robot is difficult to derive by dynamics. To synthesize the optimal gait controller of the soft-legged robot, the paper makes the following contributions. First, the flexible components of the quadruped robot are modeled with different finite element and lumped parameter methods. The model accuracy and computation efficiency are analyzed. Second, soft actor–critic methods and curriculum learning are applied to learn the optimal gaits for different walking tasks. Third, The learned gaits are implemented in an in-house robot to transport hand tools. Preliminary results show that the robot can walk forward and correct the walking directions.},
	language = {en},
	urldate = {2022-10-14},
	journal = {Robotics and Computer-Integrated Manufacturing},
	author = {Ji, Qinglei and Fu, Shuo and Tan, Kaige and Thorapalli Muralidharan, Seshagopalan and Lagrelius, Karin and Danelia, David and Andrikopoulos, Georgios and Wang, Xi Vincent and Wang, Lihui and Feng, Lei},
	month = dec,
	year = {2022},
	note = {4 citations (Semantic Scholar/DOI) [2023-04-11]
2 citations (Crossref) [2022-12-07]},
	keywords = {/unread, Motion control, Quadruped robot, Reinforcement learning, Robot gait, Soft actuators, Tendon-driven motion},
	pages = {102382},
}

@phdthesis{danelia2021Structure,
	title = {Structure and {Gait} {Optimizationof} a {Soft} {Quadrupedal} {Robot}},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-305510},
	abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
	language = {eng},
	urldate = {2022-10-14},
	school = {KTH Royal Institute of Technology},
	author = {Danelia, David and Fu, Shuo},
	year = {2021},
	keywords = {/unread},
}

@article{jia2018Stability,
	title = {Stability {Criterion} for {Dynamic} {Gaits} of {Quadruped} {Robot}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/8/12/2381},
	doi = {10.3390/app8122381},
	abstract = {Dynamic-stability criteria are crucial for robot’s motion planning and balance recovery. Nevertheless, few studies focus on the motion stability of quadruped robots with dynamic gait, none of which have accurately evaluated the robots’ stability. To fill the gaps in this field, this paper presents a new stability criterion for the motion of quadruped robots with dynamic gaits running over irregular terrain. The traditional zero-moment point (ZMP) is improved to analyze the motion on irregular terrain precisely for dynamic gaits. A dynamic-stability criterion and measurement are proposed to determine the stability state of the robot and to evaluate its stability. The simulation results show the limitations of the existing stability criteria for dynamic gaits and indicate that the criterion proposed in this paper can accurately and efficiently evaluate the stability of a quadruped robot using such gaits.},
	language = {en},
	number = {12},
	urldate = {2023-03-15},
	journal = {Applied Sciences},
	author = {Jia, Yan and Luo, Xiao and Han, Baoling and Liang, Guanhao and Zhao, Jiaheng and Zhao, Yuting},
	month = dec,
	year = {2018},
	note = {10 citations (Semantic Scholar/DOI) [2023-04-11]
Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {/unread, dynamic gait, quadruped robot, stability criterion},
	pages = {2381},
}

@article{polygerinos2017Soft,
	title = {Soft {Robotics}: {Review} of {Fluid}-{Driven} {Intrinsically} {Soft} {Devices}; {Manufacturing}, {Sensing}, {Control}, and {Applications} in {Human}-{Robot} {Interaction}},
	volume = {19},
	issn = {1527-2648},
	shorttitle = {Soft {Robotics}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/adem.201700016},
	doi = {10.1002/adem.201700016},
	abstract = {The emerging field of soft robotics makes use of many classes of materials including metals, low glass transition temperature (Tg) plastics, and high Tg elastomers. Dependent on the specific design, all of these materials may result in extrinsically soft robots. Organic elastomers, however, have elastic moduli ranging from tens of megapascals down to kilopascals; robots composed of such materials are intrinsically soft − they are always compliant independent of their shape. This class of soft machines has been used to reduce control complexity and manufacturing cost of robots, while enabling sophisticated and novel functionalities often in direct contact with humans. This review focuses on a particular type of intrinsically soft, elastomeric robot − those powered via fluidic pressurization.},
	language = {en},
	number = {12},
	urldate = {2022-12-07},
	journal = {Advanced Engineering Materials},
	author = {Polygerinos, Panagiotis and Correll, Nikolaus and Morin, Stephen A. and Mosadegh, Bobak and Onal, Cagdas D. and Petersen, Kirstin and Cianchetti, Matteo and Tolley, Michael T. and Shepherd, Robert F.},
	year = {2017},
	note = {558 citations (Semantic Scholar/DOI) [2023-04-11]
531 citations (Crossref) [2022-12-07]
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/adem.201700016},
	keywords = {/unread},
	pages = {1700016},
}

@inproceedings{haarnoja2018Soft,
	title = {Soft {Actor}-{Critic}: {Off}-{Policy} {Maximum} {Entropy} {Deep} {Reinforcement} {Learning} with a {Stochastic} {Actor}},
	shorttitle = {Soft {Actor}-{Critic}},
	url = {https://proceedings.mlr.press/v80/haarnoja18b.html},
	abstract = {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.},
	language = {en},
	urldate = {2023-04-27},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	month = jul,
	year = {2018},
	note = {ISSN: 2640-3498},
	keywords = {/unread},
	pages = {1861--1870},
}

@phdthesis{hwangbo2018Simulation,
	type = {Doctoral {Thesis}},
	title = {Simulation to {Real} {World}: {Learn} to {Control} {Legged} {Robots}},
	copyright = {http://rightsstatements.org/page/InC-NC/1.0/},
	shorttitle = {Simulation to {Real} {World}},
	url = {https://www.research-collection.ethz.ch/handle/20.500.11850/326129},
	abstract = {This thesis addresses both control and design aspects of legged robots. Regarding control, I propose two learning-based control approaches that make a legged robot run faster, more energy-efficiently, and more robustly than ever before. This is possible thanks to an effective modeling technique and a simulation tool, both of which are developed in this thesis. Furthermore, the proposed approaches significantly reduce the laborious process of controller design, which hinders the practicality of prior methods. Only by defining a cost function and initialization/termination strategies, natural behaviors that are realizable on the robot arise. Regarding design, I propose a cable-pulley-based efficient transmission concept which is realized as a single-legged hopping system. The constructed system exhibits remarkable efficiency and power while having a simple structure. Although these two contributions seem disconnected, they cannot be addressed separately. Both control and design aspects of robotics should complement each other to create a great legged machine. A great control algorithm exploits the dynamics of the hardware, and well-designed hardware accounts for the characteristics of existing control approaches.  Prior control approaches for controlling legged systems are highly tailored for a specific task; as a result, a complex control architecture has to be designed for every new task. Such arduous workflow and the complexity have deterred the advancement of legged robotics. This is the primary issue that this thesis addresses with new learning-based control approaches.  Reinforcement learning approaches promote a natural discovery of behaviors through a high-level cost function, unlike the prior approaches that hand-code each behavior. However, they have limited success on real robots due to their extensive data requirements. With the approach proposed in this thesis, a policy trained in a simulated environment can be seamlessly transferred to a real robotic system. Consequently, a development process of a control policy can be automated. The enormous complexity of control algorithms is now managed by a parameterized function -- a deep neural network -- relieving humans from the cognitive labor.  The proposed approaches are also uncompromising in performance: a sampling-based search can often find an effective solution near the global optimum even in some highly non-convex problems. The resulting behavior is thus highly performant with respect to the cost function. In addition, the training is performed using a very detailed physics model of the system, whereas many of the prior control methods are based on highly approximated models. Consequently, the performance of the proposed approaches on the real robot is likely to be higher.  As the core of the proposed approaches for control relied heavily on simulation, they can be greatly aided by a high-performance physics simulator. With a new novel numerical optimization scheme, a rigid-body simulator was developed in this thesis. The simulator solves a rigid-body contact problem faster, more stably, and more accurately compared to previous approaches. This simulator ensures the computational practicality and the transferability of the proposed control approaches.  One of the proposed approaches for control was tested on ANYmal, a dog-sized versatile quadrupedal robot. Without any modification, tuning or filtering, the trained policies manifest highly agile and complex behaviors: ANYmal precisely follows random combinations of command velocities, balances under high external perturbations, runs faster than ever before, and recovers itself from a fall. This proves the effectiveness of the proposed approaches for simulation and control, respectively.  This thesis also introduces an ambitious new legged robotic platform: Capler-Leg. Capler-Leg is equipped with nearly frictionless cable-driven transmission systems, thereby increasing the energy efficiency and the power output. Through comprehensive evaluations, I observed unmatched results. A robot that weighs only about 4 kg outputs more than 4 kW of instantaneous power, while recuperating more than 97 \% of kinematic energy back to the battery. It is a promising approach for constructing high performance legged robots.  The contributions of this thesis are key technologies for advancing legged robotics. It is my firm belief that further efforts in the outlined directions will soon make legged robots meaningfully aid humans in multiple domains.},
	language = {en},
	urldate = {2023-04-26},
	school = {ETH Zurich},
	author = {Hwangbo, Je Min},
	year = {2018},
	doi = {10.3929/ethz-b-000326129},
	note = {Accepted: 2020-04-01T08:06:46Z},
	keywords = {/unread},
}

@article{thuruthel2019Soft,
	title = {Soft robot perception using embedded soft sensors and recurrent neural networks},
	volume = {4},
	url = {https://www.science.org/doi/full/10.1126/scirobotics.aav1488},
	doi = {10.1126/scirobotics.aav1488},
	abstract = {Recent work has begun to explore the design of biologically inspired soft robots composed of soft, stretchable materials for applications including the handling of delicate materials and safe interaction with humans. However, the solid-state sensors traditionally used in robotics are unable to capture the high-dimensional deformations of soft systems. Embedded soft resistive sensors have the potential to address this challenge. However, both the soft sensors—and the encasing dynamical system—often exhibit nonlinear time-variant behavior, which makes them difficult to model. In addition, the problems of sensor design, placement, and fabrication require a great deal of human input and previous knowledge. Drawing inspiration from the human perceptive system, we created a synthetic analog. Our synthetic system builds models using a redundant and unstructured sensor topology embedded in a soft actuator, a vision-based motion capture system for ground truth, and a general machine learning approach. This allows us to model an unknown soft actuated system. We demonstrate that the proposed approach is able to model the kinematics of a soft continuum actuator in real time while being robust to sensor nonlinearities and drift. In addition, we show how the same system can estimate the applied forces while interacting with external objects. The role of action in perception is also presented. This approach enables the development of force and deformation models for soft robotic systems, which can be useful for a variety of applications, including human-robot interaction, soft orthotics, and wearable robotics.},
	number = {26},
	urldate = {2023-11-20},
	journal = {Science Robotics},
	author = {Thuruthel, Thomas George and Shih, Benjamin and Laschi, Cecilia and Tolley, Michael Thomas},
	month = jan,
	year = {2019},
	note = {Publisher: American Association for the Advancement of Science},
	keywords = {/unread},
	pages = {eaav1488},
}

@misc{haarnoja2019Soft,
	title = {Soft {Actor}-{Critic} {Algorithms} and {Applications}},
	url = {http://arxiv.org/abs/1812.05905},
	abstract = {Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.},
	urldate = {2023-06-15},
	publisher = {arXiv},
	author = {Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
	month = jan,
	year = {2019},
	note = {arXiv:1812.05905 [cs, stat]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
}

@misc{tan2018SimtoReal,
	title = {Sim-to-{Real}: {Learning} {Agile} {Locomotion} {For} {Quadruped} {Robots}},
	shorttitle = {Sim-to-{Real}},
	url = {http://arxiv.org/abs/1804.10332},
	doi = {10.48550/arXiv.1804.10332},
	abstract = {Designing agile locomotion for quadruped robots often requires extensive expertise and tedious manual tuning. In this paper, we present a system to automate this process by leveraging deep reinforcement learning techniques. Our system can learn quadruped locomotion from scratch using simple reward signals. In addition, users can provide an open loop reference to guide the learning process when more control over the learned gait is needed. The control policies are learned in a physics simulator and then deployed on real robots. In robotics, policies trained in simulation often do not transfer to the real world. We narrow this reality gap by improving the physics simulator and learning robust policies. We improve the simulation using system identification, developing an accurate actuator model and simulating latency. We learn robust controllers by randomizing the physical environments, adding perturbations and designing a compact observation space. We evaluate our system on two agile locomotion gaits: trotting and galloping. After learning in simulation, a quadruped robot can successfully perform both gaits in the real world.},
	urldate = {2022-11-21},
	publisher = {arXiv},
	author = {Tan, Jie and Zhang, Tingnan and Coumans, Erwin and Iscen, Atil and Bai, Yunfei and Hafner, Danijar and Bohez, Steven and Vanhoucke, Vincent},
	month = may,
	year = {2018},
	note = {549 citations (Semantic Scholar/arXiv) [2023-04-11]
arXiv:1804.10332 [cs]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{escobar-naranjo2023Selfsupervised,
	address = {Singapore},
	series = {Lecture {Notes} in {Networks} and {Systems}},
	title = {Self-supervised {Learning} {Approach} to {Local} {Trajectory} {Planning} for {Mobile} {Robots} {Using} {Optimization} of {Trajectories}},
	isbn = {978-981-19766-0-5},
	doi = {10.1007/978-981-19-7660-5_66},
	abstract = {In Industry 4.0, various control methods have been developed for autonomous navigation of robots. Some investigations are based on the use of SLAMs or routing systems for route tracking, but there are some limitations when it comes to obstacle avoidance and real-time parameter changes. Current work shows an algorithm based on the use of DQN and reinforcement learning. The model maximizes rewards and extracts information about the robot’s position and obstacles within the simulated environment as the robot performs its actions. A series of experiments have been conducted to build the algorithm, and the results show that the robot learns through exploration and uses the knowledge gained in the previous scenarios. Using a simulated environment, the DQN network computes complex functions due to randomness, resulting in better learning performance than other control methods.},
	language = {en},
	booktitle = {Intelligent {Sustainable} {Systems}},
	publisher = {Springer Nature},
	author = {Escobar-Naranjo, Juan and Garcia, Marcelo V.},
	editor = {Nagar, Atulya K. and Singh Jat, Dharm and Mishra, Durgesh Kumar and Joshi, Amit},
	year = {2023},
	keywords = {/unread, Obstacle avoidance, Reinforcement learning, Robotics},
	pages = {741--748},
}

@inproceedings{peng2018SimtoReal,
	title = {Sim-to-{Real} {Transfer} of {Robotic} {Control} with {Dynamics} {Randomization}},
	doi = {10.1109/ICRA.2018.8460528},
	abstract = {Simulations are attractive environments for training agents as they provide an abundant source of data and alleviate certain safety concerns during the training process. But the behaviours developed by agents in simulation are often specific to the characteristics of the simulator. Due to modeling error, strategies that are successful in simulation may not transfer to their real world counterparts. In this paper, we demonstrate a simple method to bridge this “reality gap”. By randomizing the dynamics of the simulator during training, we are able to develop policies that are capable of adapting to very different dynamics, including ones that differ significantly from the dynamics on which the policies were trained. This adaptivity enables the policies to generalize to the dynamics of the real world without any training on the physical system. Our approach is demonstrated on an object pushing task using a robotic arm. Despite being trained exclusively in simulation, our policies are able to maintain a similar level of performance when deployed on a real robot, reliably moving an object to a desired location from random initial configurations. We explore the impact of various design decisions and show that the resulting policies are robust to significant calibration error.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Peng, Xue Bin and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
	month = may,
	year = {2018},
	note = {ISSN: 2577-087X},
	keywords = {/unread, Adaptation models, Data models, Robots, Robustness, Task analysis, Training, Trajectory},
	pages = {3803--3810},
}

@article{fazeli2019See,
	title = {See, feel, act: {Hierarchical} learning for complex manipulation skills with multisensory fusion},
	volume = {4},
	shorttitle = {See, feel, act},
	url = {https://www.science.org/doi/abs/10.1126/scirobotics.aav3123},
	doi = {10.1126/scirobotics.aav3123},
	abstract = {Humans are able to seamlessly integrate tactile and visual stimuli with their intuitions to explore and execute complex manipulation skills. They not only see but also feel their actions. Most current robotic learning methodologies exploit recent progress in computer vision and deep learning to acquire data-hungry pixel-to-action policies. These methodologies do not exploit intuitive latent structure in physics or tactile signatures. Tactile reasoning is omnipresent in the animal kingdom, yet it is underdeveloped in robotic manipulation. Tactile stimuli are only acquired through invasive interaction, and interpretation of the data stream together with visual stimuli is challenging. Here, we propose a methodology to emulate hierarchical reasoning and multisensory fusion in a robot that learns to play Jenga, a complex game that requires physical interaction to be played effectively. The game mechanics were formulated as a generative process using a temporal hierarchical Bayesian model, with representations for both behavioral archetypes and noisy block states. This model captured descriptive latent structures, and the robot learned probabilistic models of these relationships in force and visual domains through a short exploration phase. Once learned, the robot used this representation to infer block behavior patterns and states as it played the game. Using its inferred beliefs, the robot adjusted its behavior with respect to both its current actions and its game strategy, similar to the way humans play the game. We evaluated the performance of the approach against three standard baselines and show its fidelity on a real-world implementation of the game.},
	number = {26},
	urldate = {2023-02-28},
	journal = {Science Robotics},
	author = {Fazeli, N. and Oller, M. and Wu, J. and Wu, Z. and Tenenbaum, J. B. and Rodriguez, A.},
	month = jan,
	year = {2019},
	note = {80 citations (Semantic Scholar/DOI) [2023-04-11]
Publisher: American Association for the Advancement of Science},
	keywords = {/unread},
	pages = {eaav3123},
}

@article{tan2022Shape,
	title = {Shape {Estimation} of a {3D} {Printed} {Soft} {Sensor} {Using} {Multi}-{Hypothesis} {Extended} {Kalman} {Filter}},
	volume = {7},
	issn = {2377-3766},
	doi = {10.1109/LRA.2022.3187832},
	abstract = {This study develops a multi-hypothesis extended Kalman filter (MH-EKF) for the online estimation of the bending angle of a 3D printed soft sensor attached to soft actuators. Despite the advantage of compliance and low interference, the 3D printed soft sensor is susceptible to the hysteresis property and nonlinear effects. Improving measurement accuracy for sensors with hysteresis is a common challenge. Current studies mainly apply complex models and highly nonlinear functions to characterize the hysteresis, requiring a complicated parameter identification process and challenging real-time applications. This study enhances the model simplicity and the real-time performance for the hysteresis characterization. We identify the hysteresis by combining multiple polynomial functions and improving the sensor estimation with the proposed MH-EKF. We examine the performance of the filter in the real-time closed-loop control system. Compared with the baseline methods, the proposed approach shows improvements in the estimation accuracy with low computational complexity.},
	number = {3},
	journal = {IEEE Robotics and Automation Letters},
	author = {Tan, Kaige and Ji, Qinglei and Feng, Lei and Törngren, Martin},
	month = jul,
	year = {2022},
	note = {1 citations (Semantic Scholar/DOI) [2023-04-11]
Conference Name: IEEE Robotics and Automation Letters},
	keywords = {/unread, Actuators, Bending, Control, Hydraulic/Pneumatic Actuators, Hysteresis, Modeling, Resistance, Sensors, Shape, Soft Sensors and Actuators, Soft sensors, and Learning for Soft Robots},
	pages = {8383--8390},
}

@inproceedings{li2011Research,
	title = {Research of mammal bionic quadruped robots: {A} review},
	shorttitle = {Research of mammal bionic quadruped robots},
	doi = {10.1109/RAMECH.2011.6070476},
	abstract = {This paper focuses on the mammal bionic quadruped robots. The main challenge in this field is how to design the highly dynamical and high payload quadruped robots. This paper firstly introduces the history of bionic quadruped robots, particularly the landmark quadruped robots. Then the state-of-the art of drive mode for quadruped robots is reviewed. Subsequently, the development trend of quadruped robots is described. Based on the state-of-the art of quadruped robots, the technical difficulties of bionic quadruped robots are briefly reviewed. And the hydraulic quadruped robot developed in Shandong University is introduced. Finally, the summary and future work of the quadruped robots is given.},
	booktitle = {2011 {IEEE} 5th {International} {Conference} on {Robotics}, {Automation} and {Mechatronics} ({RAM})},
	author = {Li, Yibin and Li, Bin and Ruan, Jiuhong and Rong, Xuewen},
	month = sep,
	year = {2011},
	note = {ISSN: 2158-219X},
	keywords = {/unread, Educational institutions, Legged locomotion, Payloads, Robot kinematics, Robot sensing systems},
	pages = {166--171},
}

@inproceedings{ebert2018Robustness,
	title = {Robustness via {Retrying}: {Closed}-{Loop} {Robotic} {Manipulation} with {Self}-{Supervised} {Learning}},
	shorttitle = {Robustness via {Retrying}},
	url = {https://proceedings.mlr.press/v87/ebert18a.html},
	abstract = {Prediction is an appealing objective for self-supervised learning of behavioral skills, particularly for autonomous robots. However, effectively utilizing predictive models for control, especially with raw image inputs, poses a number of major challenges. How should the predictions be used? What happens when they are inaccurate? In this paper, we tackle these questions by proposing a method for learning robotic skills from raw image observations, using only autonomously collected experience. We show that even an imperfect model can complete complex tasks if it can continuously retry, but this requires the model to not lose track of the objective (e.g., the object of interest). To enable a robot to continuously retry a task, we devise a self-supervised algorithm for learning image registration, which can keep track of objects of interest for the duration of the trial. We demonstrate that this idea can be combined with a video-prediction based controller to enable complex behaviors to be learned from scratch using only raw visual inputs, including grasping, repositioning objects, and non-prehensile manipulation. Our real-world experiments demonstrate that a model trained with 160 robot hours of autonomously collected, unlabeled data is able to successfully perform complex manipulation tasks with a wide range of objects not seen during training.},
	language = {en},
	urldate = {2023-10-06},
	booktitle = {Proceedings of {The} 2nd {Conference} on {Robot} {Learning}},
	publisher = {PMLR},
	author = {Ebert, Frederik and Dasari, Sudeep and Lee, Alex X. and Levine, Sergey and Finn, Chelsea},
	month = oct,
	year = {2018},
	note = {ISSN: 2640-3498},
	keywords = {/unread},
	pages = {983--993},
}

@article{nakamura2007Reinforcement,
	title = {Reinforcement learning for a biped robot based on a {CPG}-actor-critic method},
	volume = {20},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S089360800700024X},
	doi = {10.1016/j.neunet.2007.01.002},
	abstract = {Animals’ rhythmic movements, such as locomotion, are considered to be controlled by neural circuits called central pattern generators (CPGs), which generate oscillatory signals. Motivated by this biological mechanism, studies have been conducted on the rhythmic movements controlled by CPG. As an autonomous learning framework for a CPG controller, we propose in this article a reinforcement learning method we call the “CPG-actor-critic” method. This method introduces a new architecture to the actor, and its training is roughly based on a stochastic policy gradient algorithm presented recently. We apply this method to an automatic acquisition problem of control for a biped robot. Computer simulations show that training of the CPG can be successfully performed by our method, thus allowing the biped robot to not only walk stably but also adapt to environmental changes.},
	language = {en},
	number = {6},
	urldate = {2023-08-13},
	journal = {Neural Networks},
	author = {Nakamura, Yutaka and Mori, Takeshi and Sato, Masa-aki and Ishii, Shin},
	month = aug,
	year = {2007},
	keywords = {/unread, Actor-critic model, Biped walking, Central pattern generator, Policy gradient method, Reinforcement learning},
	pages = {723--735},
}

@inproceedings{dudzik2020Robust,
	title = {Robust {Autonomous} {Navigation} of a {Small}-{Scale} {Quadruped} {Robot} in {Real}-{World} {Environments}},
	url = {https://ieeexplore.ieee.org/abstract/document/9340701},
	doi = {10.1109/IROS45743.2020.9340701},
	abstract = {Animal-level agility and robustness in robots cannot be accomplished by solely relying on blind locomotion controllers. A significant portion of a robot’s ability to traverse terrain comes from reacting to the external world through visual sensing. However, embedding the sensors and compute that provide sufficient accuracy at high speeds is challenging, especially if the robot has significant space limitations. In this paper, we propose a system integration of a small-scale quadruped robot, the MIT Mini-Cheetah Vision, that exteroceptively senses the terrain and dynamically explores the world around it at high velocities. Through extensive hardware and software development, we demonstrate a fully untethered robot with all hardware onboard running a locomotion controller that combines state-of-the-art Regularized Predictive Control (RPC) with Whole-Body Impulse Control (WBIC). We devise a hierarchical state estimator that integrates kinematic, IMU, and localization sensor data to provide state estimates specific to path planning and locomotion tasks. Our integrated system has demonstrated robust autonomous waypoint tracking in dynamic real-world environments at speeds of over 1 m/s with high rates of success.},
	urldate = {2023-11-12},
	booktitle = {2020 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Dudzik, Thomas and Chignoli, Matthew and Bledt, Gerardo and Lim, Bryan and Miller, Adam and Kim, Donghyun and Kim, Sangbae},
	month = oct,
	year = {2020},
	note = {ISSN: 2153-0866},
	keywords = {/unread},
	pages = {3664--3671},
}

@article{lewis2012Reinforcement,
	title = {Reinforcement {Learning} and {Feedback} {Control}: {Using} {Natural} {Decision} {Methods} to {Design} {Optimal} {Adaptive} {Controllers}},
	volume = {32},
	issn = {1941-000X},
	shorttitle = {Reinforcement {Learning} and {Feedback} {Control}},
	doi = {10.1109/MCS.2012.2214134},
	abstract = {This article describes the use of principles of reinforcement learning to design feedback controllers for discrete- and continuous-time dynamical systems that combine features of adaptive control and optimal control. Adaptive control [1], [2] and optimal control [3] represent different philosophies for designing feedback controllers. Optimal controllers are normally designed of ine by solving Hamilton JacobiBellman (HJB) equations, for example, the Riccati equation, using complete knowledge of the system dynamics. Determining optimal control policies for nonlinear systems requires the offline solution of nonlinear HJB equations, which are often difficult or impossible to solve. By contrast, adaptive controllers learn online to control unknown systems using data measured in real time along the system trajectories. Adaptive controllers are not usually designed to be optimal in the sense of minimizing user-prescribed performance functions. Indirect adaptive controllers use system identification techniques to first identify the system parameters and then use the obtained model to solve optimal design equations [1]. Adaptive controllers may satisfy certain inverse optimality conditions [4].},
	number = {6},
	journal = {IEEE Control Systems Magazine},
	author = {Lewis, Frank L. and Vrabie, Draguna and Vamvoudakis, Kyriakos G.},
	month = dec,
	year = {2012},
	note = {Conference Name: IEEE Control Systems Magazine},
	keywords = {/unread, Adaptive control, Decision making, Design methodology, Feedback control, Learning systems, Optimal control, Reinforcement learning},
	pages = {76--105},
}

@article{zhang2021Robot,
	title = {Robot grasping method optimization using improved deep deterministic policy gradient algorithm of deep reinforcement learning},
	volume = {92},
	issn = {0034-6748},
	url = {https://doi.org/10.1063/5.0034101},
	doi = {10.1063/5.0034101},
	abstract = {Robot grasping has become a very hot research field so that the requirements for robot operation are getting higher and higher. In previous research studies, the use of traditional target detection algorithms for grasping is often very inefficient, and this article is dedicated to improving the deep reinforcement learning algorithm to improve the grasping efficiency and solve the problem of robots dealing with the impact of unknown disturbances on grasping. Using the characteristic that deep reinforcement learning actively explores the unknown environment, a Gaussian parameter Deep Deterministic Policy Gradient (Gaussian-DDPG) algorithm based on the Importance-Weighted Autoencoder (IWAE) is proposed to realize the robot’s autonomous learning of the grasping task. Traditional coordinate positioning methods and deep learning methods have poor grasping effects for disturbed situations (such as the movement of the target object). The IWAE algorithm is used to compress the high-dimensional information of the original visual input to the hidden space and pass it to the deep reinforcement learning network as part of the state value. Based on the classic DDPG algorithm, it smoothly adds Gaussian parameters to improve the exploratory nature of the algorithm, dynamically sets the robot grasping space parameters to adapt to the workspace of multiple scales, and finally, realizes the accurate grasping of the robot. Relying on the possible position information deviation of the visual information, the control of the grasping position by the manipulator torque information is further optimized to improve the grasping efficiency of disturbed objects.},
	number = {2},
	urldate = {2023-10-13},
	journal = {Review of Scientific Instruments},
	author = {Zhang, Hongxu and Wang, Fei and Wang, Jianhui and Cui, Ben},
	month = feb,
	year = {2021},
	keywords = {/unread},
	pages = {025114},
}

@inproceedings{chignoli2022Rapid,
	title = {Rapid and {Reliable} {Quadruped} {Motion} {Planning} with {Omnidirectional} {Jumping}},
	doi = {10.1109/ICRA46639.2022.9812088},
	abstract = {Dynamic jumping with legged robots poses a challenging problem in planning and control. Formulating the jump optimization to allow fast online execution is difficult; efficiently using this capability to generate long-horizon motion plans further complicates the problem. In this work, we present a hierarchical planning framework to address this problem. We first formulate a real-time tractable trajectory optimization for performing omnidirectional jumping. We then embed the results of this optimization into a low dimensional jump feasibility classifier. This classifier is leveraged to produce geometric motion plans that select dynamically feasible jumps while mitigating the effects of the process noise. We deploy our framework on the Mini Cheetah Vision quadruped, demonstrating the robot's ability to generate and execute reliable, goal-oriented plans that involve forward, lateral, and rotational jumps onto surfaces as tall as the robot's nominal hip height. The ability to plan through omnidirectional jumping greatly expands the robot's mobility relative to planners that restrict jumping to the sagittal or frontal planes.},
	booktitle = {2022 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Chignoli, Matthew and Morozov, Savva and Kim, Sangbae},
	month = may,
	year = {2022},
	note = {4 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread, Automation, Dynamics, Legged locomotion, Planning, Quadrupedal robots, Real-time systems, Reliability engineering},
	pages = {6621--6627},
}

@book{2006Quadrupedal,
	address = {London},
	title = {Quadrupedal {Locomotion}},
	isbn = {978-1-84628-306-2},
	url = {http://link.springer.com/10.1007/1-84628-307-8},
	language = {en},
	urldate = {2023-07-08},
	publisher = {Springer},
	year = {2006},
	doi = {10.1007/1-84628-307-8},
	keywords = {/unread, Hexapod, algorithms, kinematics, proving, robot, robotics, sensor},
}

@inproceedings{farshidian2017Realtime,
	title = {Real-time motion planning of legged robots: {A} model predictive control approach},
	shorttitle = {Real-time motion planning of legged robots},
	doi = {10.1109/HUMANOIDS.2017.8246930},
	abstract = {We introduce a real-time, constrained, nonlinear Model Predictive Control for the motion planning of legged robots. The proposed approach uses a constrained optimal control algorithm known as SLQ. We improve the efficiency of this algorithm by introducing a multi-processing scheme for estimating value function in its backward pass. This pass has been often calculated as a single process. This parallel SLQ algorithm can optimize longer time horizons without proportional increase in its computation time. Thus, our MPC algorithm can generate optimized trajectories for the next few phases of the motion within only a few milliseconds. This outperforms the state of the art by at least one order of magnitude. The performance of the approach is validated on a quadruped robot for generating dynamic gaits such as trotting.},
	booktitle = {2017 {IEEE}-{RAS} 17th {International} {Conference} on {Humanoid} {Robotics} ({Humanoids})},
	author = {Farshidian, Farbod and Jelavic, Edo and Satapathy, Asutosh and Giftthaler, Markus and Buchli, Jonas},
	month = nov,
	year = {2017},
	note = {ISSN: 2164-0580},
	keywords = {/unread, Heuristic algorithms, Legged locomotion, Mathematical model, Planning, Robot kinematics, Trajectory},
	pages = {577--584},
}

@incollection{hua2021Reinforcement,
	address = {Wiesbaden},
	title = {Reinforcement {Learning} and {Feedback} {Control}},
	isbn = {978-3-658-33034-7},
	url = {https://doi.org/10.1007/978-3-658-33034-7_3},
	abstract = {Reinforcement learning (RL) is a branch of machine learning that deals with making sequences of decisions. It refers to an agent that interacts with its environment, and receives an observation and reward. RL algorithms seek to maximize the agent’s total reward, given an unknown environment, through a trial-and-error learning process. In this chapter, we will apply RL methods to solve two fundamental feedback control problems, the linear quadratic regulator and the linear quadratic Gaussian.},
	language = {en},
	urldate = {2023-06-16},
	booktitle = {Reinforcement {Learning} {Aided} {Performance} {Optimization} of {Feedback} {Control} {Systems}},
	publisher = {Springer Fachmedien},
	author = {Hua, Changsheng},
	editor = {Hua, Changsheng},
	year = {2021},
	doi = {10.1007/978-3-658-33034-7_3},
	keywords = {/unread},
	pages = {27--57},
}

@article{huang2001Planning,
	title = {Planning walking patterns for a biped robot},
	volume = {17},
	issn = {2374-958X},
	doi = {10.1109/70.938385},
	abstract = {Biped robots have better mobility than conventional wheeled robots, but they tend to tip over easily. To be able to walk stably in various environments, such as on rough terrain, up and down slopes, or in regions containing obstacles, it is necessary for the robot to adapt to the ground conditions with a foot motion, and maintain its stability with a torso motion. When the ground conditions and stability constraint are satisfied, it is desirable to select a walking pattern that requires small torque and velocity of the joint actuators. We first formulate the constraints of the foot motion parameters. By varying the values of the constraint parameters, we can produce different types of foot motion to adapt to ground conditions. We then propose a method for formulating the problem of the smooth hip motion with the largest stability margin using only two parameters, and derive the hip trajectory by iterative computation. Finally, the correlation between the actuator specifications and the walking patterns is described through simulation studies, and the effectiveness of the proposed methods is confirmed by simulation examples and experimental results.},
	number = {3},
	journal = {IEEE Transactions on Robotics and Automation},
	author = {Huang, Qiang and Yokoi, K. and Kajita, S. and Kaneko, K. and Arai, H. and Koyachi, N. and Tanie, K.},
	month = jun,
	year = {2001},
	note = {901 citations (Semantic Scholar/DOI) [2023-04-11]
Conference Name: IEEE Transactions on Robotics and Automation},
	keywords = {/unread, Actuators, Computational modeling, Foot, Hip, Iterative methods, Legged locomotion, Mobile robots, Stability, Torque, Torso},
	pages = {280--289},
}

@inproceedings{lee2006Quadruped,
	title = {Quadruped robot obstacle negotiation via reinforcement learning},
	doi = {10.1109/ROBOT.2006.1642158},
	abstract = {Legged robots can, in principle, traverse a large variety of obstacles and terrains. In this paper, we describe a successful application of reinforcement learning to the problem of negotiating obstacles with a quadruped robot. Our algorithm is based on a two-level hierarchical decomposition of the task, in which the high-level controller selects the sequence of foot-placement positions, and the low-level controller generates the continuous motions to move each foot to the specified positions. The high-level controller uses an estimate of the value function to guide its search; this estimate is learned partially from supervised data. The low-level controller is obtained via policy search. We demonstrate that our robot can successfully climb over a variety of obstacles which were not seen at training time},
	booktitle = {Proceedings 2006 {IEEE} {International} {Conference} on {Robotics} and {Automation}, 2006. {ICRA} 2006.},
	author = {Lee, Honglak and Shen, Yirong and Yu, Chih-Han and Singh, G. and Ng, A.Y.},
	month = may,
	year = {2006},
	note = {ISSN: 1050-4729},
	keywords = {/unread, Computer science, Foot, Learning, Leg, Legged locomotion, Mobile robots, Motion control, Path planning, Robot kinematics, Robotics and automation},
	pages = {3003--3010},
}

@article{gehring2016Practice,
	title = {Practice {Makes} {Perfect}: {An} {Optimization}-{Based} {Approach} to {Controlling} {Agile} {Motions} for a {Quadruped} {Robot}},
	volume = {23},
	issn = {1558-223X},
	shorttitle = {Practice {Makes} {Perfect}},
	doi = {10.1109/MRA.2015.2505910},
	abstract = {This article approaches the problem of controlling quadrupedal running and jumping motions with a parameterized, model-based, state-feedback controller. Inspired by the motor learning principles observed in nature, our method automatically fine tunes the parameters of our controller by repeatedly executing slight variations of the same motion task. This learn-through-practice process is performed in simulation to best exploit computational resources and to prevent the robot from damaging itself. To ensure that the simulation results match the behavior of the hardware platform, we introduce and validate an accurate model of the compliant actuation system. The proposed method is experimentally verified on the torque-controllable quadruped robot StarlETH by executing squat jumps and dynamic gaits, such as a running trot, pronk, and a bounding gait.},
	number = {1},
	journal = {IEEE Robotics \& Automation Magazine},
	author = {Gehring, Christian and Coros, Stelian and Hutter, Marco and Dario Bellicoso, Carmine and Heijnen, Huub and Diethelm, Remo and Bloesch, Michael and Fankhauser, Peter and Hwangbo, Jemin and Hoepflinger, Mark and Siegwart, Roland},
	month = mar,
	year = {2016},
	note = {Conference Name: IEEE Robotics \& Automation Magazine},
	keywords = {/unread, Actuators, Dynamics, Legged locomotion, Motion control, Robot kinematics},
	pages = {34--43},
}

@incollection{zou2009Overview,
	address = {Totowa, NJ},
	series = {Methods in {Molecular} {Biology}™},
	title = {Overview of {Artificial} {Neural} {Networks}},
	isbn = {978-1-60327-101-1},
	url = {https://doi.org/10.1007/978-1-60327-101-1_2},
	abstract = {The artificial neural network (ANN), or simply neural network, is a machine learning method evolved from the idea of simulating the human brain. The data explosion in modern drug discovery research requires sophisticated analysis methods to uncover the hidden causal relationships between single or multiple responses and a large set of properties. The ANN is one of many versatile tools to meet the demand in drug discovery modeling. Compared to a traditional regression approach, the ANN is capable of modeling complex nonlinear relationships. The ANN also has excellent fault tolerance and is fast and highly scalable with parallel processing. This chapter introduces the background of ANN development and outlines the basic concepts crucially important for understanding more sophisticated ANN. Several commonly used learning methods and network setups are discussed briefly at the end of the chapter.},
	language = {en},
	urldate = {2023-08-13},
	booktitle = {Artificial {Neural} {Networks}: {Methods} and {Applications}},
	publisher = {Humana Press},
	author = {Zou, Jinming and Han, Yi and So, Sung-Sau},
	editor = {Livingstone, David J.},
	year = {2009},
	doi = {10.1007/978-1-60327-101-1_2},
	keywords = {/unread, Hopfield network, Kohonen network, Transfer function, perceptron, supervised learning, unsupervised learning},
	pages = {14--22},
}

@article{ganguly2020Optimised,
	title = {Optimised building energy and indoor microclimatic predictions using knowledge-based system identification in a historical art gallery},
	volume = {32},
	issn = {1433-3058},
	url = {https://doi.org/10.1007/s00521-019-04224-7},
	doi = {10.1007/s00521-019-04224-7},
	abstract = {This paper presents a system identification (SID) model for an historical art gallery of great cultural significance. These buildings require tight indoor temperature and moisture controls that demand significant energy from air handling units. Complex dynamic building systems, stringent conservation restrictions, and lack of detailed monitoring make diagnosing and optimising their energy use difficult. Building simulation software programmes have proven to be effective, but have tended to rely on data generated by simulation models. This study shows how artificial neural network (ANN) models trained with historical real data can predict a building’s energy use and the optimal indoor microclimate necessary for conservation. Four ANN target-data scenarios were designed for optimised model predictions, and 12 ANN training algorithms were tested with six architectural scenarios collecting daily and hourly data. The ANN models used a randomised 80\% sample of the database, with the remainder (20\%) validating the models. The model displayed a high coefficient of correlation (0.99), with the mean square error and mean absolute error less than 0.1\% and 2\%, respectively. This ANN-based SID tool efficiently represents a complex building system and could be an ideal method for investigating optimisation strategies prior to their implementation.},
	language = {en},
	number = {8},
	urldate = {2023-07-11},
	journal = {Neural Computing and Applications},
	author = {Ganguly, Shashwat and Ahmed, Afaq and Wang, Fan},
	month = apr,
	year = {2020},
	keywords = {/unread, Artificial neural networks, Energy prediction model, Historical art gallery building, Indoor microclimatic control, Optimisation, System identification},
	pages = {3349--3366},
}

@article{koch2012Optimizationbased,
	series = {10th {IFAC} {Symposium} on {Robot} {Control}},
	title = {Optimization-based walking generation for humanoid robot},
	volume = {45},
	issn = {1474-6670},
	url = {https://www.sciencedirect.com/science/article/pii/S147466701633659X},
	doi = {10.3182/20120905-3-HR-2030.00189},
	abstract = {The generation of walking motions for humanoid robots is a challenging task. From the infinite number of possibilities to move the body of the robot with its redundant degrees of freedom (DOF) forward, the task is to determine those motions that are stable, feasible within the robots kinematic and dynamic limitations, and also resemble the way we expect an anthropomorphic system to walk. Several approaches have been developed and implemented on humanoids in the past years, however most of them require fixing several characteristics of the gait, such as foot placement or step time, in advance, and none has lead to truly human-like walking performance. The purpose of this paper is to show that mathematical trajectory optimization or optimal control can be very helpful to generate walking motions for humanoid robots. We propose a method that uses dynamic model information of the robot as well as efficient optimal control techniques to determine joint trajectories and actuator torques at the same time. Foot placement and step times are also left free for optimization. The method is applied to the humanoid robot HRP-2 with 36 DOF and 30 actuators. Different optimization criteria are evaluated, such as maximization of efficiency, walking speed or postural stability, and a minimization of joint torques or angular amplitudes. ZMP constraints (or alternative stability constraints) can be taken into account in the optimization. The results show that different objective functions and constraints have a considerable influence on the resulting gait.},
	language = {en},
	number = {22},
	urldate = {2023-07-08},
	journal = {IFAC Proceedings Volumes},
	author = {Koch, Kai Henning and Mombaur, Katja and Soueres, Philippe},
	month = jan,
	year = {2012},
	keywords = {/unread, HRP-2, Humanoid robot, Optimal Control, Walking motion generation},
	pages = {498--504},
}

@article{kolda2003Optimization,
	title = {Optimization by {Direct} {Search}: {New} {Perspectives} on {Some} {Classical} and {Modern} {Methods}},
	volume = {45},
	issn = {0036-1445},
	shorttitle = {Optimization by {Direct} {Search}},
	url = {https://epubs.siam.org/doi/abs/10.1137/S003614450242889},
	doi = {10.1137/S003614450242889},
	abstract = {This paper addresses the problem of minimization of a nonsmooth function under general nonsmooth constraints when no derivatives of the objective or constraint functions are available. We introduce the mesh adaptive direct search (MADS) class of algorithms which extends the generalized pattern search (GPS) class by allowing local exploration, called polling, in an asymptotically dense set of directions in the space of optimization variables. This means that under certain hypotheses, including a weak constraint qualification due to Rockafellar, MADS can treat constraints by the extreme barrier approach of setting the objective to infinity for infeasible points and treating the problem as unconstrained.The main GPS convergence result is to identify limit points \${\textbackslash}hat\{x\}\$, where the Clarke generalized derivatives are nonnegative in a finite set of directions, called refining directions. Although in the unconstrained case, nonnegative combinations of these directions span the whole space, the fact that there can only be finitely many GPS refining directions limits rigorous justification of the barrier approach to finitely many linear constraints for GPS. The main result of this paper is that the general MADS framework is flexible enough to allow the generation of an asymptotically dense set of refining directions along which the Clarke derivatives are nonnegative. We propose an instance of MADS for which the refining directions are dense in the hypertangent cone at \${\textbackslash}hat\{x\}\$ with probability 1 whenever the iterates associated with the refining directions converge to a single \${\textbackslash}hat\{x\}\$. The instance of MADS is compared to versions of GPS on some test problems. We also illustrate the limitation of our results with examples.An erratum to this article has been appended at the end of the pdf file.},
	number = {3},
	urldate = {2023-08-13},
	journal = {SIAM Review},
	author = {Kolda, Tamara G. and Lewis, Robert Michael and Torczon, Virginia},
	month = jan,
	year = {2003},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {/unread},
	pages = {385--482},
}

@article{wensing2023OptimizationBased,
	title = {Optimization-{Based} {Control} for {Dynamic} {Legged} {Robots}},
	issn = {1941-0468},
	url = {https://ieeexplore.ieee.org/abstract/document/10286076},
	doi = {10.1109/TRO.2023.3324580},
	abstract = {In a world designed for legs, quadrupeds, bipeds, and humanoids have the opportunity to impact emerging robotics applications from logistics, to agriculture, to home assistance. The goal of this survey is to cover the recent progress toward these applications that has been driven by model-based optimization for the real-time generation and control of movement. The majority of the research community has converged on the idea of generating locomotion control laws by solving an optimal control problem (OCP) in either a model-based or data-driven manner. However, solving the most general of these problems online remains intractable due to complexities from intermittent unidirectional contacts with the environment, and from the many degrees of freedom of legged robots. This survey covers methods that have been pursued to make these OCPs computationally tractable, with specific focus on how environmental contacts are treated, how the model can be simplified, and how these choices affect the numerical solution methods employed. The survey focuses on model-based optimization while paving its way for broader combination with learning-based formulations to accelerate progress in this growing field.},
	urldate = {2023-11-12},
	journal = {IEEE Transactions on Robotics},
	author = {Wensing, Patrick M. and Posa, Michael and Hu, Yue and Escande, Adrien and Mansard, Nicolas and Prete, Andrea Del},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Robotics},
	keywords = {/unread},
	pages = {1--20},
}

@inproceedings{chignoli2021Online,
	title = {Online {Trajectory} {Optimization} for {Dynamic} {Aerial} {Motions} of a {Quadruped} {Robot}},
	doi = {10.1109/ICRA48506.2021.9560855},
	abstract = {This work presents a two part framework for online planning and execution of dynamic aerial motions on a quadruped robot. Motions are planned via a centroidal momentum-based nonlinear optimization that is general enough to produce rich sets of novel dynamic motions based solely on the user-specified contact schedule and desired launch velocity of the robot. Since this nonlinear optimization is not tractable for real-time receding horizon control, motions are planned once via nonlinear optimization in preparation of an aerial motion and then tracked continuously using a variational-based optimal controller that offers robustness to the uncertainties that exist in the real hardware such as modeling error or disturbances. Motion planning typically takes between 0.05-0.15 s, while the optimal controller finds stabilizing feedback inputs at 500 Hz. Experimental results on the MIT Mini Cheetah demonstrate that the framework can reliably produce successful aerial motions such as jumps onto and off of platforms, spins, flips, barrel rolls, and running jumps over obstacles.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Chignoli, Matthew and Kim, Sangbae},
	month = may,
	year = {2021},
	note = {4 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2577-087X},
	keywords = {/unread, Dynamics, Legged locomotion, Reliability engineering, Robustness, Schedules, Tracking, Uncertainty},
	pages = {7693--7699},
}

@inproceedings{cebe2021Online,
	title = {Online {Dynamic} {Trajectory} {Optimization} and {Control} for a {Quadruped} {Robot}},
	doi = {10.1109/ICRA48506.2021.9561592},
	abstract = {Legged robot locomotion requires the planning of stable reference trajectories, especially while traversing uneven terrain. The proposed trajectory optimization framework is capable of generating dynamically stable base and footstep trajectories for multiple steps. The locomotion task can be defined with contact locations, base motion or both, making the algorithm suitable for multiple scenarios (e.g., presence of moving obstacles). The planner uses a simplified momentum-based task space model for the robot dynamics, allowing computation times that are fast enough for online replanning. This fast planning capability also enables the quadruped to accommodate for drift and environmental changes. The algorithm is tested on simulation and a real robot across multiple scenarios, which includes uneven terrain, stairs and moving obstacles. The results show that the planner is capable of generating stable trajectories in the real robot even when a box of 15 cm height is placed in front of its path at the last moment.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Cebe, Oguzhan and Tiseo, Carlo and Xin, Guiyang and Lin, Hsiu-chin and Smith, Joshua and Mistry, Michael},
	month = may,
	year = {2021},
	note = {15 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2577-087X},
	keywords = {/unread, Computational modeling, Conferences, Dynamics, Heuristic algorithms, Legged locomotion, Planning, Stairs},
	pages = {12773--12779},
}

@article{forster2017OnManifold,
	title = {On-{Manifold} {Preintegration} for {Real}-{Time} {Visual}–{Inertial} {Odometry}},
	volume = {33},
	issn = {1941-0468},
	doi = {10.1109/TRO.2016.2597321},
	abstract = {Current approaches for visual-inertial odometry (VIO) are able to attain highly accurate state estimation via nonlinear optimization. However, real-time optimization quickly becomes infeasible as the trajectory grows over time; this problem is further emphasized by the fact that inertial measurements come at high rate, hence, leading to the fast growth of the number of variables in the optimization. In this paper, we address this issue by preintegrating inertial measurements between selected keyframes into single relative motion constraints. Our first contribution is a preintegration theory that properly addresses the manifold structure of the rotation group. We formally discuss the generative measurement model as well as the nature of the rotation noise and derive the expression for the maximum a posteriori state estimator. Our theoretical development enables the computation of all necessary Jacobians for the optimization and a posteriori bias correction in analytic form. The second contribution is to show that the preintegrated inertial measurement unit model can be seamlessly integrated into a visual-inertial pipeline under the unifying framework of factor graphs. This enables the application of incremental-smoothing algorithms and the use of a structureless model for visual measurements, which avoids optimizing over the 3-D points, further accelerating the computation. We perform an extensive evaluation of our monocular VIO pipeline on real and simulated datasets. The results confirm that our modeling effort leads to an accurate state estimation in real time, outperforming state-of-the-art approaches.},
	number = {1},
	journal = {IEEE Transactions on Robotics},
	author = {Forster, Christian and Carlone, Luca and Dellaert, Frank and Scaramuzza, Davide},
	month = feb,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Robotics},
	keywords = {/unread, Computational modeling, Computer vision, Estimation, Jacobian matrices, Manifolds, Optimization, Real-time systems, Smoothing methods, sensor fusion, visual–inertial odometry (VIO)},
	pages = {1--21},
}

@article{ji2022Online,
	title = {Online reinforcement learning for the shape morphing adaptive control of {4D} printed shape memory polymer},
	volume = {126},
	issn = {0967-0661},
	url = {https://www.sciencedirect.com/science/article/pii/S096706612200123X},
	doi = {10.1016/j.conengprac.2022.105257},
	abstract = {Combining 3D printing and smart materials, 4D printing technologies enable the printed actuators to further change their shapes or other properties after prototyping. However, the shape morphing of 4D printed actuators suffers from poor controllability and low precision. One of the main challenges is that the 4D printed actuators are hard to be modeled and it is difficult to develop an appropriate controller for them. In this study, various popular reinforcement learning (RL) methods are applied to address the problem of online and adaptive model-free control of 4D printed shape memory polymer (SMP). Their training efficiencies are compared and an adaptive LQR controller based on Q learning is developed to realize efficient online learning. The RL controller achieves precise and quick shape control within 2−−3 learning episodes and is adaptive to the changing properties of SMP. The RL controller performance is then compared with a model-based LQR controller and shows high control precision and excellent adaptability to the varying control plant.},
	language = {en},
	urldate = {2022-11-16},
	journal = {Control Engineering Practice},
	author = {Ji, Qinglei and Wang, Xi Vincent and Wang, Lihui and Feng, Lei},
	month = sep,
	year = {2022},
	note = {3 citations (Semantic Scholar/DOI) [2023-04-11]
0 citations (Crossref) [2022-12-07]},
	keywords = {/unread, 4D printing, Closed loop control, Q-learning, Reinforcement learning, Shape memory polymer},
	pages = {105257},
}

@misc{levine2020Offline,
	title = {Offline {Reinforcement} {Learning}: {Tutorial}, {Review}, and {Perspectives} on {Open} {Problems}},
	shorttitle = {Offline {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/2005.01643},
	abstract = {In this tutorial article, we aim to provide the reader with the conceptual tools needed to get started on research on offline reinforcement learning algorithms: reinforcement learning algorithms that utilize previously collected data, without additional online data collection. Offline reinforcement learning algorithms hold tremendous promise for making it possible to turn large datasets into powerful decision making engines. Effective offline reinforcement learning methods would be able to extract policies with the maximum possible utility out of the available data, thereby allowing automation of a wide range of decision-making domains, from healthcare and education to robotics. However, the limitations of current algorithms make this difficult. We will aim to provide the reader with an understanding of these challenges, particularly in the context of modern deep reinforcement learning methods, and describe some potential solutions that have been explored in recent work to mitigate these challenges, along with recent applications, and a discussion of perspectives on open problems in the field.},
	urldate = {2023-03-22},
	publisher = {arXiv},
	author = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
	month = nov,
	year = {2020},
	note = {858 citations (Semantic Scholar/arXiv) [2023-04-11]
arXiv:2005.01643 [cs, stat]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{hopfield1982Neural,
	title = {Neural networks and physical systems with emergent collective computational abilities.},
	volume = {79},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.79.8.2554},
	doi = {10.1073/pnas.79.8.2554},
	abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
	number = {8},
	urldate = {2023-08-13},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Hopfield, J J},
	month = apr,
	year = {1982},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	keywords = {/unread},
	pages = {2554--2558},
}

@inproceedings{ji2022Omnidirectional,
	title = {Omnidirectional walking of a quadruped robot enabled by compressible tendon-driven soft actuators},
	doi = {10.1109/IROS47612.2022.9981314},
	abstract = {Using soft actuators as legs, soft quadruped robots have shown great potential in traversing unstructured and complex terrains and environments. However, unlike rigid robots whose gaits can be generated using foot pattern design and kinematic model of the rigid legs, the gait generation of soft quadruped robots remains challenging due to the high DoFs of the soft actuators and the uncertain deformations during their contact with the ground. This study is based on a quadruped robot using four Compressible Tendon-driven Soft Actuators (CTSAs) as the legs, with the actuator's compression motion being utilized to improve the walking performance of the robot. For the gait design, an inverse kinematics model considering the compression of the CTSA is developed and validated in simulation. Based on this model, walking gaits realizing different motion speeds and directions are generated. Closed loop direction and speed controllers are developed for increasing the robustness and precision of the robot walking. Simulation and experimental results show that omnidirectional locomotion and complex walking tasks can be realized by tuning the gait parameters and the motions are resistant to external disturbances.},
	booktitle = {2022 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Ji, Qinglei and Fu, Shuo and Feng, Lei and Andrikopoulos, George and Wang, Xi Vincent and Wang, Lihui},
	month = oct,
	year = {2022},
	note = {0 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2153-0866},
	keywords = {/unread, Actuators, Control and Learning for Soft Robots, Kinematics, Legged locomotion, Modeling, Motion Control, Quadrupedal robots, Robot sensing systems, Soft Sensors and Actuators, Ten-don/Wire Mechanism, Trajectory, Turning},
	pages = {11015--11022},
}

@article{hashemi2023Multibody,
	title = {Multibody dynamics and control using machine learning},
	issn = {1573-272X},
	url = {https://doi.org/10.1007/s11044-023-09884-x},
	doi = {10.1007/s11044-023-09884-x},
	abstract = {Artificial intelligence and mechanical engineering are two mature fields of science that intersect more and more often. Computer-aided mechanical analysis tools, including multibody dynamics software, are very versatile and have revolutionalized many industries. However, as shown by the literature presented in this review, combining the advantages of multibody system dynamics and machine learning creates new and exciting possibilities. For example, the multibody method can assist machine learning by providing synthetic data, while machine learning can provide fast and accurate subsystem models. The intersection of both approaches results in surrogate and hybrid modeling techniques, advanced control algorithms, and optimal design applications. A notable example is the development of autonomous systems for vehicles, robots, and mobile machinery. In our review we have found nontrivial, innovative, and even surprising applications of machine learning and multibody dynamics. This review focuses on applying neural networks, mainly deep learning, in connection with the multibody system method. Over one hundred and fifty papers are covered, and three main research areas are identified and introduced: data-driven modeling, model-based control and estimation, and data-driven control. The paper starts with a primer on machine learning and concludes with future research directions. The main goal is to provide a comprehensive and up-to-date review of existing literature to inspire further research.},
	language = {en},
	urldate = {2023-03-27},
	journal = {Multibody System Dynamics},
	author = {Hashemi, Arash and Orzechowski, Grzegorz and Mikkola, Aki and McPhee, John},
	month = feb,
	year = {2023},
	note = {0 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread, Data-driven control, Data-driven modeling, Deep learning, Machine learning, Model-based control, Multibody system dynamics},
}

@inproceedings{nagabandi2018Neural,
	title = {Neural {Network} {Dynamics} for {Model}-{Based} {Deep} {Reinforcement} {Learning} with {Model}-{Free} {Fine}-{Tuning}},
	doi = {10.1109/ICRA.2018.8463189},
	abstract = {Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that neural network dynamics models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits that accomplish various complex locomotion tasks. We further propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We empirically demonstrate on MuJoCo locomotion tasks that our pure model-based approach trained on just random action data can follow arbitrary trajectories with excellent sample efficiency, and that our hybrid algorithm can accelerate model-free learning on high-speed benchmark tasks, achieving sample efficiency gains of 3-5× on swimmer, cheetah, hopper, and ant agents. Videos can be found at https://sites.google.com/view/mbmf.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S. and Levine, Sergey},
	month = may,
	year = {2018},
	note = {729 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2577-087X},
	keywords = {/unread, Complexity theory, Data models, Heuristic algorithms, Machine learning, Neural networks, Predictive models, Task analysis},
	pages = {7559--7566},
}

@article{giorelli2015Neural,
	title = {Neural {Network} and {Jacobian} {Method} for {Solving} the {Inverse} {Statics} of a {Cable}-{Driven} {Soft} {Arm} {With} {Nonconstant} {Curvature}},
	volume = {31},
	issn = {1941-0468},
	url = {https://ieeexplore.ieee.org/document/7112506/authors#authors},
	doi = {10.1109/TRO.2015.2428511},
	abstract = {The solution of the inverse kinematics problem of soft manipulators is essential to generate paths in the task space. The inverse kinematics problem of constant curvature or piecewise constant curvature manipulators has already been solved by using different methods, which include closed-form analytical approaches and iterative methods based on the Jacobian method. On the other hand, the inverse kinematics problem of nonconstant curvature manipulators remains unsolved. This study represents one of the first attempts in this direction. It presents both a model-based method and a supervised learning method to solve the inverse statics of nonconstant curvature soft manipulators. In particular, a Jacobian-based method and a feedforward neural network are chosen and tested experimentally. A comparative analysis has been conducted in terms of accuracy and computational time.},
	number = {4},
	urldate = {2023-10-12},
	journal = {IEEE Transactions on Robotics},
	author = {Giorelli, Michele and Renda, Federico and Calisti, Marcello and Arienti, Andrea and Ferri, Gabriele and Laschi, Cecilia},
	month = aug,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Robotics},
	keywords = {/unread},
	pages = {823--834},
}

@article{wang2016Motion,
	title = {Motion {Planning} {Based} on {Learning} {From} {Demonstration} for {Multiple}-{Segment} {Flexible} {Soft} {Robots} {Actuated} by {Electroactive} {Polymers}},
	volume = {1},
	issn = {2377-3766},
	doi = {10.1109/LRA.2016.2521384},
	abstract = {Multiple-segment flexible and soft robotic arms composed by ionic polymer–metal composite (IPMC) flexible actuators exhibit compliance but suffer from the difficulty of path planning due to their redundant degrees of freedom, although they are promising in complex tasks such as crossing body cavities to grasp objects. We propose a learning from demonstration method to plan the motion paths of IPMC-based manipulators, by statistics machine-learning algorithms. To encode demonstrated trajectories and estimate suitable paths for the manipulators to reproduce the task, models are built based on Gaussian mixture model and Gaussian mixture regression, respectively. The forward and inverse kinematic models of IPMC-based soft robotic arm are derived for the motion control. A flexible and soft robotic manipulator is implemented with six IPMC segments, and it verifies the learned paths by successfully completing a representative task of navigating through a narrow keyhole.},
	number = {1},
	journal = {IEEE Robotics and Automation Letters},
	author = {Wang, Hongqiang and Chen, Jie and Lau, Henry Y. K. and Ren, Hongliang},
	month = jan,
	year = {2016},
	note = {59 citations (Semantic Scholar/DOI) [2023-04-11]
45 citations (Crossref) [2022-12-07]
Conference Name: IEEE Robotics and Automation Letters},
	keywords = {/unread, Actuators, Electrodes, Flexible soft robot, Kinematics, Manipulators, Motion segmentation, Path planning, flexible soft robot, ionic polymer-metal composite, ionic polymer–metal composite, learning from demonstration, motion planning},
	pages = {391--398},
}

@phdthesis{de2017Modular,
	title = {Modular {Hopping} and {Running} via {Parallel} {Composition}},
	abstract = {Though multi-functional robot hardware has been created, the complexity in its functionality has been constrained by a lack of algorithms that appropriately manage flexible and autonomous reconfiguration of interconnections to physical and behavioral components.},
	language = {en},
	school = {University of Pennsylvania},
	author = {De, Avik},
	year = {2017},
	keywords = {/unread},
}

@article{gromov2019Modeling,
	series = {12th {IFAC} {Symposium} on {Advances} in {Control} {Education} {ACE} 2019},
	title = {Modeling and {Control} of {Robotic} {Systems} {Course}: from {Fundamentals} to {Applications}},
	volume = {52},
	issn = {2405-8963},
	shorttitle = {Modeling and {Control} of {Robotic} {Systems} {Course}},
	url = {https://www.sciencedirect.com/science/article/pii/S2405896319305415},
	doi = {10.1016/j.ifacol.2019.08.204},
	abstract = {In this paper the Modeling and Control of Robotic Systems course to build the set of the professional skills is presented. This course is included in the curriculum of the master’s degree program and provided at the Faculty of Control Systems and Robotics of ITMO University. The selection of the tracks to build the professional skills are presented. An important part of the tracks is a using various technical equipment to build the skills and experience.},
	language = {en},
	number = {9},
	urldate = {2023-04-13},
	journal = {IFAC-PapersOnLine},
	author = {Gromov, Vladislav S. and Borisov, Oleg I. and Shavetov, Sergey S. and Pyrkin, Anton A. and Karashaeva, Fatimat B.},
	month = jan,
	year = {2019},
	keywords = {/unread, Control application, Control education, Industrial robots, Robotics, Ship control},
	pages = {224--229},
}

@article{qin2023Modeling,
	title = {Modeling and {Simulation} of {Dynamics} in {Soft} {Robotics}: a {Review} of {Numerical} {Approaches}},
	issn = {2662-4087},
	shorttitle = {Modeling and {Simulation} of {Dynamics} in {Soft} {Robotics}},
	url = {https://doi.org/10.1007/s43154-023-00105-z},
	doi = {10.1007/s43154-023-00105-z},
	abstract = {In this review, we briefly summarize the numerical methods commonly used for the nonlinear dynamic analysis of soft robotic systems. The underlying mechanical principles as well as the geometrical treatment tailored for soft robots are introduced with particular emphasis on one-dimensional models. Additionally, the review encompasses three-dimensional frameworks, available simulation packages, and various types of interaction models, shedding light on the design, actuation, motion control, and internal and external forces of soft robots.},
	language = {en},
	urldate = {2023-10-12},
	journal = {Current Robotics Reports},
	author = {Qin, Longhui and Peng, Haijun and Huang, Xiaonan and Liu, Mingchao and Huang, Weicheng},
	month = aug,
	year = {2023},
	keywords = {/unread, Discrete model, Model order reduction, Nonlinear dynamics, Numerical simulation, Soft robotics},
}

@inproceedings{morimoto2021ModelFree,
	title = {Model-{Free} {Reinforcement} {Learning} with {Ensemble} for a {Soft} {Continuum} {Robot} {Arm}},
	url = {https://ieeexplore.ieee.org/abstract/document/9479340},
	doi = {10.1109/RoboSoft51838.2021.9479340},
	abstract = {Soft robots have more passive degrees of freedom (DoFs) than rigid-body robots, which makes controller design difficult. Model-free reinforcement learning (RL) is a promising tool to resolve control problems in soft robotics alongside detailed and elaborate modeling. However, the adaptation of RL to soft robots requires consideration of the unique nature of soft bodies. In this work, a continuum robot arm is used as an example of a soft robot, and we propose an Ensembled Light-weight model-Free reinforcement learning Network (ELFNet), which is an RL framework with a computationally light ensemble. We demonstrated that the proposed system could learn control policies for a continuum robot arm to reach target positions using its tip not only in simulations but also in the real world. We used a pneumatically controlled continuum robot arm that operates with nine flexible rubber artificial muscles. Each artificial muscle can be controlled independently by pressure control valves, demonstrating that the policy can be learned using a real robot alone. We found that our method is more suitable for compliant robots than other RL methods because the sample efficiency is better than that of the other methods, and there is a significant difference in the performance when the number of passive DoFs is large. This study is expected to lead to the development of model-free RL in future soft robot control.},
	urldate = {2024-03-06},
	booktitle = {2021 {IEEE} 4th {International} {Conference} on {Soft} {Robotics} ({RoboSoft})},
	author = {Morimoto, Ryota and Nishikawa, Satoshi and Niiyama, Ryuma and Kuniyoshi, Yasuo},
	month = apr,
	year = {2021},
	keywords = {/unread, Actuators, Adaptation models, Computational modeling, Muscles, Reinforcement learning, Soft robotics, Uncertainty},
	pages = {141--148},
}

@article{thuruthel2019ModelBased,
	title = {Model-{Based} {Reinforcement} {Learning} for {Closed}-{Loop} {Dynamic} {Control} of {Soft} {Robotic} {Manipulators}},
	volume = {35},
	issn = {1941-0468},
	url = {https://ieeexplore.ieee.org/abstract/document/8531756},
	doi = {10.1109/TRO.2018.2878318},
	abstract = {Dynamic control of soft robotic manipulators is an open problem yet to be well explored and analyzed. Most of the current applications of soft robotic manipulators utilize static or quasi-dynamic controllers based on kinematic models or linearity in the joint space. However, such approaches are not truly exploiting the rich dynamics of a soft-bodied system. In this paper, we present a model-based policy learning algorithm for closed-loop predictive control of a soft robotic manipulator. The forward dynamic model is represented using a recurrent neural network. The closed-loop policy is derived using trajectory optimization and supervised learning. The approach is verified first on a simulated piecewise constant strain model of a cable driven under-actuated soft manipulator. Furthermore, we experimentally demonstrate on a soft pneumatically actuated manipulator how closed-loop control policies can be derived that can accommodate variable frequency control and unmodeled external loads.},
	number = {1},
	urldate = {2024-03-06},
	journal = {IEEE Transactions on Robotics},
	author = {Thuruthel, Thomas George and Falotico, Egidio and Renda, Federico and Laschi, Cecilia},
	month = feb,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Robotics},
	keywords = {/unread, Aerospace electronics, Computational modeling, Dynamic control, Manipulator dynamics, Soft robotics, Trajectory optimization, machine learning, manipulation, reinforcement learning, soft robotics},
	pages = {124--134},
}

@article{moerland2023Modelbased,
	title = {Model-based {Reinforcement} {Learning}: {A} {Survey}},
	volume = {16},
	issn = {1935-8237, 1935-8245},
	shorttitle = {Model-based {Reinforcement} {Learning}},
	url = {https://www.nowpublishers.com/article/Details/MAL-086},
	doi = {10.1561/2200000086},
	abstract = {Model-based Reinforcement Learning: A Survey},
	language = {English},
	number = {1},
	urldate = {2023-03-22},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Moerland, Thomas M. and Broekens, Joost and Plaat, Aske and Jonker, Catholijn M.},
	month = jan,
	year = {2023},
	note = {Publisher: Now Publishers, Inc.},
	keywords = {/unread},
	pages = {1--118},
}

@inproceedings{calisir2019ModelFree,
	title = {Model-{Free} {Reinforcement} {Learning} {Algorithms}: {A} {Survey}},
	shorttitle = {Model-{Free} {Reinforcement} {Learning} {Algorithms}},
	doi = {10.1109/SIU.2019.8806389},
	abstract = {This paper aims to provide a comprehensive survey of the reinforcement learning algorithms given in the literature. Especially model-free reinforcement learning algorithms are given in details and the differences of these algorithms are handled. Finally, some open problems in reinforcement learning are presented for future researches.},
	booktitle = {2019 27th {Signal} {Processing} and {Communications} {Applications} {Conference} ({SIU})},
	author = {Çalışır, Sinan and Pehlivanoğlu, Meltem Kurt},
	month = apr,
	year = {2019},
	note = {13 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2165-0608},
	keywords = {/unread, Dogs, Markov processes, Monte Carlo methods, Noise measurement, Optimization, Reinforcement learning, Robots, artificial intelligence, deep reinforcement learning, learning, reinforcement learning algorithms},
	pages = {1--4},
}

@article{zhang2023Model,
	title = {Model {Predictive} {Control} of {Quadruped} {Robot} {Based} on {Reinforcement} {Learning}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/13/1/154},
	doi = {10.3390/app13010154},
	abstract = {For the locomotion control of a legged robot, both model predictive control (MPC) and reinforcement learning (RL) demonstrate powerful capabilities. MPC transfers the high-level task to the lower-level joint control based on the understanding of the robot and environment, model-free RL learns how to work through trial and error, and has the ability to evolve based on historical data. In this work, we proposed a novel framework to integrate the advantages of MPC and RL, we learned a policy for automatically choosing parameters for MPC. Unlike the end-to-end RL applications for control, our method does not need massive sampling data for training. Compared with the fixed parameters MPC, the learned MPC exhibits better locomotion performance and stability. The presented framework provides a new choice for improving the performance of traditional control.},
	language = {en},
	number = {1},
	urldate = {2023-05-16},
	journal = {Applied Sciences},
	author = {Zhang, Zhitong and Chang, Xu and Ma, Hongxu and An, Honglei and Lang, Lin},
	month = jan,
	year = {2023},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {/unread, model predictive control, parameter adaptive, quadruped robot, reinforcement learning},
	pages = {154},
}

@incollection{ray2010ModelBased,
	address = {Boston, MA},
	title = {Model-{Based} {Reinforcement} {Learning}},
	isbn = {978-0-387-30164-8},
	url = {https://doi.org/10.1007/978-0-387-30164-8_556},
	language = {en},
	urldate = {2022-11-07},
	booktitle = {Encyclopedia of {Machine} {Learning}},
	publisher = {Springer US},
	author = {Ray, Soumya and Tadepalli, Prasad},
	editor = {Sammut, Claude and Webb, Geoffrey I.},
	year = {2010},
	doi = {10.1007/978-0-387-30164-8_556},
	keywords = {/unread},
	pages = {690--693},
}

@article{tang2021Modelbased,
	title = {Model-based online learning and adaptive control for a “human-wearable soft robot” integrated system},
	volume = {40},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364919873379},
	doi = {10.1177/0278364919873379},
	abstract = {Soft robots are considered intrinsically safe with regard to human?robot interaction. This has motivated the development and investigation of soft medical robots, such as soft robotic gloves for stroke rehabilitation. However, the output force of conventional purely soft actuators is usually limited. This restricts their application in stroke rehabilitation, which requires a large force and bidirectional movement. In addition, accurate control of soft actuators is difficult owing to the nonlinearity of purely soft actuators. In this study, a soft robotic glove is designed based on a soft-elastic composite actuator (SECA) that integrates an elastic torque compensating layer to increase the output force as well as achieving bidirectional movement. Such a hybrid design also significantly reduces the degree of nonlinearity compared with a purely soft actuator. A model-based online learning and adaptive control algorithm is proposed for the wearable soft robotic glove, taking its interaction environment into account, namely, the human hand/finger. The designed hybrid controller enables the soft robotic glove to adapt to different hand conditions for reference tracking. Experimental results show that satisfactory tracking performance can be achieved on both healthy subjects and stroke subjects (with the tracking root mean square error (RMSE) {\textless} 0.05 rad). Meanwhile, the controller can output an actuator?finger model for each individual subject (with the learning error RMSE {\textless} 0.06 rad), which provides information on the condition of the finger and, thus, has further potential clinical application.},
	language = {en},
	number = {1},
	urldate = {2022-12-08},
	journal = {The International Journal of Robotics Research},
	author = {Tang, Zhi Qiang and Heung, Ho Lam and Tong, Kai Yu and Li, Zheng},
	month = jan,
	year = {2021},
	note = {30 citations (Semantic Scholar/DOI) [2023-04-11]
Publisher: SAGE Publications Ltd STM},
	keywords = {/unread},
	pages = {256--276},
}

@article{chen2021ModalBased,
	title = {Modal-{Based} {Kinematics} and {Contact} {Detection} of {Soft} {Robots}},
	volume = {8},
	issn = {2169-5172},
	url = {https://www.liebertpub.com/doi/abs/10.1089/soro.2019.0095},
	doi = {10.1089/soro.2019.0095},
	abstract = {Soft robots offer an alternative approach to manipulate within a constrained space while maintaining a safe interaction with the external environment. Owing to its adaptable compliance characteristic, external contact force can easily deform the robot shapes and lead to undesired robot kinematic and dynamic properties. Accurate contact detection and contact location estimation are of critical importance for soft robot modeling, control, trajectory planning, and eventually affect the success of task completion. In this article, we focus on the investigation of a one degree of freedom (1-DoF) soft pneumatic bending robot, which is regarded as one of the fundamental components to construct complex, multi-DoFs soft robots. This 1-DoF soft robot is modeled through the integral representation of the spatial curve, where direct and instantaneous kinematics are calculated explicitly through a modal method. The fixed centrode deviation method is used to detect the external contact and estimate the contact location. Simulation results and experimental studies indicate that the contact location can be accurately estimated by solving a nonlinear least-square optimization problem. Experimental validation shows that the proposed algorithm is able to successfully estimate the contact location with the estimation error of 1.46 mm.},
	number = {3},
	urldate = {2023-10-12},
	journal = {Soft Robotics},
	author = {Chen, Yue and Wang, Long and Galloway, Kevin and Godage, Isuru and Simaan, Nabil and Barth, Eric},
	month = jun,
	year = {2021},
	note = {Publisher: Mary Ann Liebert, Inc., publishers},
	keywords = {/unread, contact detection, contact estimation, pneumatic soft robot, soft robot modeling},
	pages = {298--309},
}

@article{hewing2020Learningbased,
	title = {Learning-based model predictive control: {Toward} safe learning in control},
	volume = {3},
	shorttitle = {Learning-based model predictive control},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Hewing, Lukas and Wabersich, Kim P. and Menner, Marcel and Zeilinger, Melanie N.},
	year = {2020},
	note = {Publisher: Annual Reviews},
	keywords = {/unread, Review},
	pages = {269--296},
}

@phdthesis{ji2022Learningbased,
	address = {Stockholm, Sweden},
	title = {Learning-based {Control} for {4D} {Printing} and {Soft} {Robotics}},
	abstract = {Exploiting novel sensors and actuators made of flexible and smart materials becomes a new trend in robotics research. The studies on the design, production, and control of the new type of robots motivate the research fields of soft robots and 4D printed robots. 3D Printing (3DP) is an additive manufacturing technology that is widely used in printing flexible materials to fabricate soft robots. 4D Printing (4DP) combines 3DP technologies with smart materials to produce transformable devices. 4DP first prints structures with specifically designed responsive materials. When external stimuli such as temperature, voltage, or magnetic field are applied to the printed structure, it changes shape in a programmable way. The shape morphing property of 4DP makes it a novel approach to the actuators of robots.},
	language = {en},
	school = {KTH Royal Institute of Technology},
	author = {Ji, Qinglei},
	year = {2022},
	keywords = {/unread},
}

@inproceedings{bledt2018MIT,
	title = {{MIT} {Cheetah} 3: {Design} and {Control} of a {Robust}, {Dynamic} {Quadruped} {Robot}},
	shorttitle = {{MIT} {Cheetah} 3},
	doi = {10.1109/IROS.2018.8593885},
	abstract = {This paper introduces a new robust, dynamic quadruped, the MIT Cheetah 3. Like its predecessor, the Cheetah 3 exploits tailored mechanical design to enable simple control strategies for dynamic locomotion and features high-bandwidth proprioceptive actuators to manage physical interaction with the environment. A new leg design is presented that includes proprioceptive actuation on the abduction/adduction degrees of freedom in addition to an expanded range of motion on the hips and knees. To make full use of these new capabilities, general balance and locomotion controllers for Cheetah 3 are presented. These controllers are embedded into a modular control architecture that allows the robot to handle unexpected terrain disturbances through reactive gait modification and without the need for external sensors or prior environment knowledge. The efficiency of the robot is demonstrated by a low Cost of Transport (CoT) over multiple gaits at moderate speeds, with the lowest CoT of 0.45 found during trotting. Experiments showcase the ability to blindly climb up stairs as a result of the full system integration. These results collectively represent a promising step toward a platform capable of generalized dynamic legged locomotion.},
	booktitle = {2018 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Bledt, Gerardo and Powell, Matthew J. and Katz, Benjamin and Di Carlo, Jared and Wensing, Patrick M. and Kim, Sangbae},
	month = oct,
	year = {2018},
	note = {324 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2153-0866},
	keywords = {/unread, Actuators, Force, Knee, Legged locomotion, Robot sensing systems, Torque},
	pages = {2245--2252},
}

@article{yang2020Magnetic,
	title = {Magnetic {Actuation} {Systems} for {Miniature} {Robots}: {A} {Review}},
	volume = {2},
	copyright = {© 2020 The Authors. Published by WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim},
	issn = {2640-4567},
	shorttitle = {Magnetic {Actuation} {Systems} for {Miniature} {Robots}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aisy.202000082},
	doi = {10.1002/aisy.202000082},
	abstract = {A magnetic field, which is transparent and relatively safe to biological tissue, is a powerful tool for remote actuation and wireless control of magnetic devices. Furthermore, miniature robots can access complex and narrow regions of the human body as well as manipulate down to subcellular entities; however, integrating onboard components is difficult due to their limited size. Combining these two technologies, magnetic miniature robots have undergone rapid development during the past two decades, mainly because of their high potential in medical and bioengineering applications. To improve the scientific and clinical outcomes of these tiny agents, developing suitable and reliable actuation systems is essential. As a newly emerging field that has progressed in recent years, magnetic actuation systems offer a harmless and effective approach for the remote control of miniature robots via a dynamic magnetic field. Herein, a review on the state-of-the-art magnetic actuation systems for miniature robots is presented with the goal of providing readers with a better understanding of magnetic actuation and guidance for future system design.},
	language = {en},
	number = {9},
	urldate = {2023-07-03},
	journal = {Advanced Intelligent Systems},
	author = {Yang, Zhengxin and Zhang, Li},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/aisy.202000082},
	keywords = {/unread, biomedical applications, magnetic actuation, medical robots and systems, microrobots, miniature robots},
	pages = {2000082},
}

@misc{bemporad2022Linear,
	address = {Piazza San Francesco 19, Lucca, Italy},
	title = {Linear time-varying and nonlinear {MPC}},
	url = {http://cse.lab.imtlucca.it/~bemporad/teaching/mpc/imt/2-ltv_nl_mpc.pdf},
	language = {en},
	urldate = {2022-12-13},
	author = {Bemporad, Alberto},
	month = mar,
	year = {2022},
	keywords = {/unread},
}

@article{rogers2010Materials,
	title = {Materials and {Mechanics} for {Stretchable} {Electronics}},
	volume = {327},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.1182383},
	doi = {10.1126/science.1182383},
	abstract = {Recent advances in mechanics and materials provide routes to integrated circuits that can offer the electrical properties of conventional, rigid wafer-based technologies but with the ability to be stretched, compressed, twisted, bent, and deformed into arbitrary shapes. Inorganic and organic electronic materials in microstructured and nanostructured forms, intimately integrated with elastomeric substrates, offer particularly attractive characteristics, with realistic pathways to sophisticated embodiments. Here, we review these strategies and describe applications of them in systems ranging from electronic eyeball cameras to deformable light-emitting displays. We conclude with some perspectives on routes to commercialization, new device opportunities, and remaining challenges for research.},
	language = {en},
	number = {5973},
	urldate = {2022-12-07},
	journal = {Science},
	author = {Rogers, John A. and Someya, Takao and Huang, Yonggang},
	month = mar,
	year = {2010},
	note = {3877 citations (Semantic Scholar/DOI) [2023-04-11]
3618 citations (Crossref) [2022-12-07]},
	keywords = {/unread},
	pages = {1603--1607},
}

@article{whitehead1991Learning,
	title = {Learning to perceive and act by trial and error},
	volume = {7},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/BF00058926},
	doi = {10.1007/BF00058926},
	abstract = {This article considers adaptive control architectures that integrate active sensory-motor systems with decision systems based on reinforcement learning. One unavoidable consequence of active perception is that the agent's internal representation often confounds external world states. We call this phoenomenon Perceptual aliasing and show that it destabilizes existing reinforcement learning algorithms with respect to the optimal decision policy. We then describe a new decision system that overcomes these difficulties for a restricted class of decision problems. The system incorporates a perceptual subcycle within the overall decision cycle and uses a modified learning algorithm to suppress the effects of perceptual aliasing. The result is a control architecture that learns not only how to solve a task but also where to focus its visual attention in order to collect necessary sensory information.},
	language = {en},
	number = {1},
	urldate = {2023-08-13},
	journal = {Machine Learning},
	author = {Whitehead, Steven D. and Ballard, Dana H.},
	month = jul,
	year = {1991},
	keywords = {/unread, Reinforcement learning, deictic representations, hidden state, non-Markov decision problems, sensory-motor integration},
	pages = {45--83},
}

@article{choi2023Learning,
	title = {Learning quadrupedal locomotion on deformable terrain},
	volume = {8},
	url = {https://www.science.org/doi/abs/10.1126/scirobotics.ade2256},
	doi = {10.1126/scirobotics.ade2256},
	abstract = {Simulation-based reinforcement learning approaches are leading the next innovations in legged robot control. However, the resulting control policies are still not applicable on soft and deformable terrains, especially at high speed. The primary reason is that reinforcement learning approaches, in general, are not effective beyond the data distribution: The agent cannot perform well in environments that it has not experienced. To this end, we introduce a versatile and computationally efficient granular media model for reinforcement learning. Our model can be parameterized to represent diverse types of terrain from very soft beach sand to hard asphalt. In addition, we introduce an adaptive control architecture that can implicitly identify the terrain properties as the robot feels the terrain. The identified parameters are then used to boost the locomotion performance of the legged robot. We applied our techniques to the Raibo robot, a dynamic quadrupedal robot developed in-house. The trained networks demonstrated high-speed locomotion capabilities on deformable terrains: The robot was able to run on soft beach sand at 3.03 meters per second although the feet were completely buried in the sand during the stance phase. We also demonstrate its ability to generalize to different terrains by presenting running experiments on vinyl tile flooring, athletic track, grass, and a soft air mattress.},
	number = {74},
	urldate = {2023-08-13},
	journal = {Science Robotics},
	author = {Choi, Suyoung and Ji, Gwanghyeon and Park, Jeongsoo and Kim, Hyeongjun and Mun, Juhyeok and Lee, Jeong Hyun and Hwangbo, Jemin},
	month = jan,
	year = {2023},
	note = {Publisher: American Association for the Advancement of Science},
	keywords = {/unread},
	pages = {eade2256},
}

@article{lee2020Learning,
	title = {Learning quadrupedal locomotion over challenging terrain},
	volume = {5},
	url = {https://www.science.org/doi/full/10.1126/scirobotics.abc5986},
	doi = {10.1126/scirobotics.abc5986},
	abstract = {Legged locomotion can extend the operational domain of robots to some of the most challenging environments on Earth. However, conventional controllers for legged locomotion are based on elaborate state machines that explicitly trigger the execution of motion primitives and reflexes. These designs have increased in complexity but fallen short of the generality and robustness of animal locomotion. Here, we present a robust controller for blind quadrupedal locomotion in challenging natural environments. Our approach incorporates proprioceptive feedback in locomotion control and demonstrates zero-shot generalization from simulation to natural environments. The controller is trained by reinforcement learning in simulation. The controller is driven by a neural network policy that acts on a stream of proprioceptive signals. The controller retains its robustness under conditions that were never encountered during training: deformable terrains such as mud and snow, dynamic footholds such as rubble, and overground impediments such as thick vegetation and gushing water. The presented work indicates that robust locomotion in natural environments can be achieved by training in simple domains.},
	number = {47},
	urldate = {2023-10-05},
	journal = {Science Robotics},
	author = {Lee, Joonho and Hwangbo, Jemin and Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco},
	month = oct,
	year = {2020},
	note = {Publisher: American Association for the Advancement of Science},
	keywords = {/unread},
	pages = {eabc5986},
}

@article{miki2022Learning,
	title = {Learning robust perceptive locomotion for quadrupedal robots in the wild},
	volume = {7},
	issn = {2470-9476},
	url = {https://www.science.org/doi/10.1126/scirobotics.abk2822},
	doi = {10.1126/scirobotics.abk2822},
	abstract = {Legged robots that can operate autonomously in remote and hazardous environments will greatly increase opportunities for exploration into underexplored areas. Exteroceptive perception is crucial for fast and energy-efficient locomotion: Perceiving the terrain before making contact with it enables planning and adaptation of the gait ahead of time to maintain speed and stability. However, using exteroceptive perception robustly for locomotion has remained a grand challenge in robotics. Snow, vegetation, and water visually appear as obstacles on which the robot cannot step or are missing altogether due to high reflectance. In addition, depth perception can degrade due to difficult lighting, dust, fog, reflective or transparent surfaces, sensor occlusion, and more. For this reason, the most robust and general solutions to legged locomotion to date rely solely on proprioception. This severely limits locomotion speed because the robot has to physically feel out the terrain before adapting its gait accordingly. Here, we present a robust and general solution to integrating exteroceptive and proprioceptive perception for legged locomotion. We leverage an attention-based recurrent encoder that integrates proprioceptive and exteroceptive input. The encoder is trained end to end and learns to seamlessly combine the different perception modalities without resorting to heuristics. The result is a legged locomotion controller with high robustness and speed. The controller was tested in a variety of challenging natural and urban environments over multiple seasons and completed an hour-long hike in the Alps in the time recommended for human hikers.
          , 
            A legged locomotion controller achieves high robustness and speed in the wild by combining multimodal information.},
	language = {en},
	number = {62},
	urldate = {2022-12-07},
	journal = {Science Robotics},
	author = {Miki, Takahiro and Lee, Joonho and Hwangbo, Jemin and Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco},
	month = jan,
	year = {2022},
	note = {140 citations (Semantic Scholar/DOI) [2023-04-11]
27 citations (Crossref) [2022-12-07]},
	keywords = {/unread},
	pages = {eabk2822},
}

@misc{haarnoja2019Learning,
	title = {Learning to {Walk} via {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1812.11103},
	abstract = {Deep reinforcement learning (deep RL) holds the promise of automating the acquisition of complex controllers that can map sensory inputs directly to low-level actions. In the domain of robotic locomotion, deep RL could enable learning locomotion skills with minimal engineering and without an explicit model of the robot dynamics. Unfortunately, applying deep RL to real-world robotic tasks is exceptionally difficult, primarily due to poor sample complexity and sensitivity to hyperparameters. While hyperparameters can be easily tuned in simulated domains, tuning may be prohibitively expensive on physical systems, such as legged robots, that can be damaged through extensive trial-and-error learning. In this paper, we propose a sample-efficient deep RL algorithm based on maximum entropy RL that requires minimal per-task tuning and only a modest number of trials to learn neural network policies. We apply this method to learning walking gaits on a real-world Minitaur robot. Our method can acquire a stable gait from scratch directly in the real world in about two hours, without relying on any model or simulation, and the resulting policy is robust to moderate variations in the environment. We further show that our algorithm achieves state-of-the-art performance on simulated benchmarks with a single set of hyperparameters. Videos of training and the learned policy can be found on the project website.},
	urldate = {2023-06-15},
	publisher = {arXiv},
	author = {Haarnoja, Tuomas and Ha, Sehoon and Zhou, Aurick and Tan, Jie and Tucker, George and Levine, Sergey},
	month = jun,
	year = {2019},
	note = {arXiv:1812.11103 [cs, stat]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
}

@inproceedings{zhang2018Improved,
	title = {Improved {Adam} {Optimizer} for {Deep} {Neural} {Networks}},
	url = {https://ieeexplore.ieee.org/abstract/document/8624183},
	doi = {10.1109/IWQoS.2018.8624183},
	abstract = {Adaptive optimization algorithms, such as Adam and RMSprop, have witnessed better optimization performance than stochastic gradient descent (SGD) in some scenarios. However, recent studies show that they often lead to worse generalization performance than SGD, especially for training deep neural networks (DNNs). In this work, we identify the reasons that Adam generalizes worse than SGD, and develop a variant of Adam to eliminate the generalization gap. The proposed method, normalized direction-preserving Adam (ND-Adam), enables more precise control of the direction and step size for updating weight vectors, leading to significantly improved generalization performance. Following a similar rationale, we further improve the generalization performance in classification tasks by regularizing the softmax logits. By bridging the gap between SGD and Adam, we also hope to shed light on why certain optimization algorithms generalize better than others.},
	urldate = {2023-10-13},
	booktitle = {2018 {IEEE}/{ACM} 26th {International} {Symposium} on {Quality} of {Service} ({IWQoS})},
	author = {Zhang, Zijun},
	month = jun,
	year = {2018},
	note = {ISSN: 1548-615X},
	keywords = {/unread},
	pages = {1--2},
}

@incollection{zhang2000Introduction,
	address = {Boston, MA},
	series = {Nonconvex {Optimization} and {Its} {Applications}},
	title = {Introduction to {Artificial} {Neural} {Network}},
	isbn = {978-1-4757-3167-5},
	url = {https://doi.org/10.1007/978-1-4757-3167-5_5},
	abstract = {Artificial neural networks or simply “neural nets” go by many names such as connectionist models, parallel distributed processing models, and neuromorphic systems. Whatever terminology it may be, they all attempt to borrow the structure and running way of the biological nervous system based on our present understanding of it. Instead of performing a program consisting of instructions sequentially as in a von Neumann computer, artificial neural nets have their structures in dense interconnection of simple computational elements— the artificial neurons or simply “neurons”, and operate the massive computational elements in parallel to achieve high performance speed.},
	language = {en},
	urldate = {2023-08-13},
	booktitle = {Neural {Networks} in {Optimization}},
	publisher = {Springer US},
	author = {Zhang, Xiang-Sun},
	editor = {Zhang, Xiang-Sun},
	year = {2000},
	doi = {10.1007/978-1-4757-3167-5_5},
	keywords = {/unread},
	pages = {83--93},
}

@article{hwangbo2019Learning,
	title = {Learning agile and dynamic motor skills for legged robots},
	volume = {4},
	issn = {2470-9476},
	url = {https://www.science.org/doi/10.1126/scirobotics.aau5872},
	doi = {10.1126/scirobotics.aau5872},
	abstract = {A method for learning agile control policies uses simulated data to enable precise, efficient movements in a complex physical robot.
          , 
            Legged robots pose one of the greatest challenges in robotics. Dynamic and agile maneuvers of animals cannot be imitated by existing methods that are crafted by humans. A compelling alternative is reinforcement learning, which requires minimal craftsmanship and promotes the natural evolution of a control policy. However, so far, reinforcement learning research for legged robots is mainly limited to simulation, and only few and comparably simple examples have been deployed on real systems. The primary reason is that training with real robots, particularly with dynamically balancing systems, is complicated and expensive. In the present work, we introduce a method for training a neural network policy in simulation and transferring it to a state-of-the-art legged system, thereby leveraging fast, automated, and cost-effective data generation schemes. The approach is applied to the ANYmal robot, a sophisticated medium-dog–sized quadrupedal system. Using policies trained in simulation, the quadrupedal machine achieves locomotion skills that go beyond what had been achieved with prior methods: ANYmal is capable of precisely and energy-efficiently following high-level body velocity commands, running faster than before, and recovering from falling even in complex configurations.},
	language = {en},
	number = {26},
	urldate = {2023-04-24},
	journal = {Science Robotics},
	author = {Hwangbo, Jemin and Lee, Joonho and Dosovitskiy, Alexey and Bellicoso, Dario and Tsounis, Vassilios and Koltun, Vladlen and Hutter, Marco},
	month = jan,
	year = {2019},
	keywords = {/unread},
	pages = {eaau5872},
}

@article{fang2020Kinematics,
	title = {Kinematics of {Soft} {Robots} by {Geometric} {Computing}},
	volume = {36},
	issn = {1941-0468},
	url = {https://ieeexplore.ieee.org/document/9082704/authors#authors},
	doi = {10.1109/TRO.2020.2985583},
	abstract = {Robots fabricated with soft materials can provide higher flexibility and, thus, better safety while interacting in unpredictable situations. However, the usage of soft material makes it challenging to predict the deformation of a continuum body under actuation and, therefore, brings difficulty to the kinematic control of its movement. In this article, we present a geometry-based framework for computing the deformation of soft robots within the range of linear material elasticity. After formulating both manipulators and actuators as geometry elements, deformation can be efficiently computed by solving a constrained optimization problem. Because of its efficiency, forward and inverse kinematics for soft manipulators can be solved by an iterative algorithm with a low computational cost. Meanwhile, components with multiple materials can also be geometrically modeled in our framework with the help of a simple calibration. Numerical and physical experimental tests are conducted on soft manipulators driven by different actuators with large deformation to demonstrate the performance of our approach.},
	number = {4},
	urldate = {2023-10-12},
	journal = {IEEE Transactions on Robotics},
	author = {Fang, Guoxin and Matte, Christopher-Denny and Scharff, Rob B. N. and Kwok, Tsz-Ho and Wang, Charlie C. L.},
	month = aug,
	year = {2020},
	note = {Conference Name: IEEE Transactions on Robotics},
	keywords = {/unread},
	pages = {1272--1286},
}

@article{allen1994Kinematic,
	title = {Kinematic {Gait} {Analysis} of the {Trot} in {Healthy} {Mixed} {Breed} {Dogs}},
	volume = {07},
	copyright = {Schattauer GmbH},
	issn = {0932-0814, 2567-6911},
	url = {http://www.thieme-connect.de/DOI/DOI?10.1055/s-0038-1633088},
	doi = {10.1055/s-0038-1633088},
	abstract = {Computer aided kinematic and synchronized force plate gait analysis were used to characterize joint movement in 14 large mixed breed dogs at a trot. A curvilinear relationship of joint angle to time was described, for three forelimb and three hindlimb joints. Two peaks of maximum extension, one preceding the onset and at the end of stance phase were observed for the femorotibial, tarsus and cubital joints. The carpus, scapulohumeral and coxofemoral joint exhibited one peak of maximum extension. The variance in joint angle measurement was calculated for repeated trials for a given dog and for differences between dogs using a 2-factor repeated measures ANOVA. The mean variance for all joints except the carpal joint for trial repetition was 12.6 (degrees)2 (range, 2.6-23.9) and for differences between dogs 6.2 (degrees)2 (range, 1.0-11.3). The carpal joint exhibited greater variation with a mean variance, attributable to trial repetition, of 42.5 (degrees)2 (range, 39.4-44.3) and a variance between dogs of 52.4 (degrees)2 (range, 18.5-89.4).

 The results obtained would suggest that computer assisted kinematics is an accurate means of assessing joint angle movement in large mixed breed dogs with a low level of variance attributable to trial repetition and to differences between dogs, with the exception of the carpal joint. The sample of mixed breed dogs in this study is similar to dogs that would be seen in a clinical sample population. Our results suggest that computer assisted kinematics could be an important tool in providing objective information on gait, in clinical and research studies, using mixed breed dogs.

 This study describes the trot in 14 large mixed breed dogs using computer aided kinematic and force plate gait analysis techniques. Variances in fore and hindlimb joint angle measurements were deter-mined, for a given dog, by repeated trials and for differences between dogs. The measured variances were low in all joints except the corpus, despite diverse dog conformation in the study.},
	language = {en},
	number = {4},
	urldate = {2023-10-12},
	journal = {Veterinary and Comparative Orthopaedics and Traumatology},
	author = {Allen, K. and DeCamp, C. E. and Braden, T. D. and Balms, Michelle},
	year = {1994},
	note = {Publisher: Schattauer GmbH},
	keywords = {/unread, Mixed breed, dynamic joint angles, kinematic gait analysis, trot, variance},
	pages = {148--153},
}

@article{shao2022Learning,
	title = {Learning {Free} {Gait} {Transition} for {Quadruped} {Robots} {Via} {Phase}-{Guided} {Controller}},
	volume = {7},
	issn = {2377-3766},
	doi = {10.1109/LRA.2021.3136645},
	abstract = {Gaits and transitions are key components in legged locomotion. For legged robots, describing and reproducing gaits as well as transitions remain longstanding challenges. Reinforcement learning has become a powerful tool to formulate controllers for legged robots. Learning multiple gaits and transitions, nevertheless, is related to the multi-task learning problems. In this work, we present a novel framework for training a simple control policy for a quadruped robot to locomote in various gaits. Four independent phases are used as the interface between the gait generator and the control policy, which characterizes the movement of four feet. Guided by the phases, the quadruped robot is able to locomote according to the generated gaits, such as walk, trot, pacing and bounding, and to make transitions among those gaits. More general phases can be used to generate complex gaits, such as mixed rhythmic dancing. With the control policy, the Black Panther robot, a medium-dog-sized quadruped robot, can perform all learned motor skills while following the velocity commands smoothly and robustly in natural environment.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Shao, Yecheng and Jin, Yongbin and Liu, Xianwei and He, Weiyan and Wang, Hongtao and Yang, Wei},
	month = apr,
	year = {2022},
	note = {14 citations (Semantic Scholar/DOI) [2023-04-11]
Conference Name: IEEE Robotics and Automation Letters},
	keywords = {/unread, Foot, Legged locomotion, Oscillators, Quadrupedal robots, Reinforcement learning, Robots, Task analysis, Training, legged robots, machine learning for robot control},
	pages = {1230--1237},
}

@article{hyun2014High,
	title = {High speed trot-running: {Implementation} of a hierarchical controller using proprioceptive impedance control on the {MIT} {Cheetah}},
	copyright = {Creative Commons Attribution-Noncommercial-Share Alike},
	issn = {0278-3649},
	shorttitle = {High speed trot-running},
	url = {https://dspace.mit.edu/handle/1721.1/98270},
	abstract = {This paper presents implementation of a highly dynamic running gait with a hierarchical controller on the MIT Cheetah. The developed controller enables high-speed running of up to 6 m/s (Froude number of Fr ≈ 7.34) incorporating proprioceptive feedback and programmable virtual leg compliance of the MIT Cheetah. To achieve a stable and fast trot gait, we applied three control strategies: (a) programmable virtual leg compliance that provides instantaneous reflexes to external disturbance and facilitates the self-stabilizing shown in the passive dynamics of locomotion; (b) tunable stance-trajectory design, intended to adjust impulse at each foot-end in the stance phase in a high speed trot-running according to the equilibrium-point hypothesis; and (c) a gait-pattern modulation that imposes a desired cyclic gait-pattern taking cues from proprioceptive TD feedback. Based on three strategies, the controller is hierarchically structured. The control parameters for forward speeds, a specific gait-pattern, and desired leg trajectories are managed by a high-level controller. It consists of both a gait-pattern modulator with proprioceptive leg TD detection and a leg-trajectory generator using a Bèzier curve and a tunable amplitude sinusoidal wave. Instead of employing physical spring/dampers in the robot’s leg, the programmable virtual leg compliance is realized using proprioceptive impedance control in individual low-level leg controllers. 
To verify the developed controller, a robot dynamic simulator is constructed based on the model parameters of the MIT Cheetah. The controller parameters are tuned with the simulator to achieve self-stability, and then applied to the MIT Cheetah in an experimental environment. Using leg kinematics and applied motor current feedbacks, the MIT Cheetah achieved a stable trot-running gait in the sagittal plane.},
	language = {en\_US},
	urldate = {2023-07-06},
	journal = {Prof. Kim via Angie Locknar},
	author = {Hyun, D. J. and Seok, S. and Lee, J. and Kim, S.},
	month = aug,
	year = {2014},
	note = {Accepted: 2015-09-01T12:16:26Z
Publisher: Sage Publications},
	keywords = {/unread},
}

@article{ibarz2021How,
	title = {How to train your robot with deep reinforcement learning: lessons we have learned},
	volume = {40},
	issn = {0278-3649},
	shorttitle = {How to train your robot with deep reinforcement learning},
	url = {https://doi.org/10.1177/0278364920987859},
	doi = {10.1177/0278364920987859},
	abstract = {Deep reinforcement learning (RL) has emerged as a promising approach for autonomously acquiring complex behaviors from low-level sensor observations. Although a large portion of deep RL research has focused on applications in video games and simulated control, which does not connect with the constraints of learning in real environments, deep RL has also demonstrated promise in enabling physical robots to learn complex skills in the real world. At the same time, real-world robotics provides an appealing domain for evaluating such algorithms, as it connects directly to how humans learn: as an embodied agent in the real world. Learning to perceive and move in the real world presents numerous challenges, some of which are easier to address than others, and some of which are often not considered in RL research that focuses only on simulated domains. In this review article, we present a number of case studies involving robotic deep RL. Building off of these case studies, we discuss commonly perceived challenges in deep RL and how they have been addressed in these works. We also provide an overview of other outstanding challenges, many of which are unique to the real-world robotics setting and are not often the focus of mainstream RL research. Our goal is to provide a resource both for roboticists and machine learning researchers who are interested in furthering the progress of deep RL in the real world.},
	language = {en},
	number = {4-5},
	urldate = {2023-03-31},
	journal = {The International Journal of Robotics Research},
	author = {Ibarz, Julian and Tan, Jie and Finn, Chelsea and Kalakrishnan, Mrinal and Pastor, Peter and Levine, Sergey},
	month = apr,
	year = {2021},
	note = {182 citations (Semantic Scholar/DOI) [2023-04-11]
Publisher: SAGE Publications Ltd STM},
	keywords = {/unread},
	pages = {698--721},
}

@article{kober2010Imitation,
	title = {Imitation and {Reinforcement} {Learning}},
	volume = {17},
	issn = {1558-223X},
	url = {https://ieeexplore.ieee.org/abstract/document/5480345},
	doi = {10.1109/MRA.2010.936952},
	abstract = {In this article, we present both novel learning algorithms and experiments using the dynamical system MPs. As such, we describe this MP representation in a way that it is straightforward to reproduce. We review an appropriate imitation learning method, i.e., locally weighted regression, and show how this method can be used both for initializing RL tasks as well as for modifying the start-up phase in a rhythmic task. We also show our current best-suited RL algorithm for this framework, i.e., PoWER. We present two complex motor tasks, i.e., ball-in-a-cup and ball paddling, learned on a real, physical Barrett WAM, using the methods presented in this article. Of particular interest is the ball-paddling application, as it requires a combination of both rhythmic and discrete dynamical systems MPs during the start-up phase to achieve a particular task.},
	number = {2},
	urldate = {2023-09-29},
	journal = {IEEE Robotics \& Automation Magazine},
	author = {Kober, Jens and Peters, Jan},
	month = jun,
	year = {2010},
	note = {Conference Name: IEEE Robotics \& Automation Magazine},
	keywords = {/unread},
	pages = {55--62},
}

@article{li2013Humanoids,
	title = {Humanoids {Learning} to {Walk}: {A} {Natural} {CPG}-{Actor}-{Critic} {Architecture}},
	volume = {7},
	issn = {1662-5218},
	shorttitle = {Humanoids {Learning} to {Walk}},
	url = {https://www.frontiersin.org/articles/10.3389/fnbot.2013.00005},
	abstract = {The identification of learning mechanisms for locomotion has been the subject of much research for some time but many challenges remain. Dynamic systems theory (DST) offers a novel approach to humanoid learning through environmental interaction. Reinforcement learning (RL) has offered a promising method to adaptively link the dynamic system to the environment it interacts with via a reward-based value system. In this paper, we propose a model that integrates the above perspectives and applies it to the case of a humanoid (NAO) robot learning to walk the ability of which emerges from its value-based interaction with the environment. In the model, a simplified central pattern generator (CPG) architecture inspired by neuroscientific research and DST is integrated with an actor-critic approach to RL (cpg-actor-critic). In the cpg-actor-critic architecture, least-square-temporal-difference based learning converges to the optimal solution quickly by using natural gradient learning and balancing exploration and exploitation. Futhermore, rather than using a traditional (designer-specified) reward it uses a dynamic value function as a stability indicator that adapts to the environment. The results obtained are analyzed using a novel DST-based embodied cognition approach. Learning to walk, from this perspective, is a process of integrating levels of sensorimotor activity and value.},
	urldate = {2023-07-10},
	journal = {Frontiers in Neurorobotics},
	author = {LI, CAI and Lowe, Robert and Ziemke, Tom},
	year = {2013},
	keywords = {/unread},
}

@article{chen2001Implementation,
	title = {Implementation of omnidirectional crawl for a quadruped robot},
	volume = {15},
	issn = {0169-1864},
	url = {https://doi.org/10.1163/15685530152116218},
	doi = {10.1163/15685530152116218},
	abstract = {As a reptile animal crawls in a cluttered environment, so a quadruped robot should be able to crawl on an irregular ground profile with its static stability by adopting the straightgoing and standstill-turning free gaits. The generalized and explicit formulations for the automatic generation of straight-going gaits and various standstill-turning gaits are presented in this paper. The maximized stride for the straight-going gait and the maximum turning angle for the turning gait of a quadruped robot named TITAN-VIII in a gait cycle are discussed by considering the robot's mechanism constraints and the irregularities of the ground profile. The control algorithm, including control of the joint positions of the robot, is described to implement the desired walking path of the quadruped robot. The effectiveness of the proposed method is demonstrated through experimental result.},
	number = {2},
	urldate = {2023-07-08},
	journal = {Advanced Robotics},
	author = {Chen, Xuedong and Watanabe, Keigo and Kiguchi, Kazuo and Izumi, Kiyotaka},
	month = jan,
	year = {2001},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1163/15685530152116218},
	keywords = {/unread, GAIT CONTROL, GAIT GENERATION, OMNIDIRECTIONAL CRAWL, QUADRUPED ROBOT, STANDSTILL-TURNING GAIT, STRAIGHT-GOING GAIT},
	pages = {169--190},
}

@inproceedings{wang2021Hierarchical,
	title = {Hierarchical {Gait} {Generation} for {Modular} {Robots} {Using} {Deep} {Reinforcement} {Learning}},
	doi = {10.1109/ICM46511.2021.9385659},
	abstract = {Modular robots have the ability to perform versatile locomotion with a high diversity of morphologies. However, designing robust locomotion gaits for arbitrary robot morphologies remains exceptionally challenging. In this paper, a two-level hierarchical locomotion framework is presented for addressing modular robot locomotion tasks. The framework combines a central pattern generator controller (CPG) with a neural network trained by deep reinforcement learning. First, the low-level CPG controllers are learned by offline optimization and generate robust straight walking gaits. Second, a high-level neural network is then learned using deep reinforcement learning via trial-and-errors. The high-level learned controller can modulate the low-level CPG parameters based on online inputs including robot states and user commands. Simulation experiments are employed on a 3D modular robot. The results show that the proposed method achieves better overall performance than the baseline methods on different locomotion skills including straight walking, velocity tracking, and circular turning. Simulation results confirm the effectiveness and robustness of the proposed method.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Mechatronics} ({ICM})},
	author = {Wang, Jiayu and Hu, Chuxiong and Zhu, Yu},
	month = mar,
	year = {2021},
	keywords = {/unread, Legged locomotion, Morphology, Neural networks, Reinforcement learning, Robots, Robustness, Task analysis, central pattern generator, locomotion control, modular robot},
	pages = {1--6},
}

@article{bechtel2021Grounding,
	title = {Grounding cognition: heterarchical control mechanisms in biology},
	volume = {376},
	shorttitle = {Grounding cognition},
	url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0751},
	doi = {10.1098/rstb.2019.0751},
	abstract = {We advance an account that grounds cognition, specifically decision-making, in an activity all organisms as autonomous systems must perform to keep themselves viable—controlling their production mechanisms. Production mechanisms, as we characterize them, perform activities such as procuring resources from their environment, putting these resources to use to construct and repair the organism's body and moving through the environment. Given the variable nature of the environment and the continual degradation of the organism, these production mechanisms must be regulated by control mechanisms that select when a production is required and how it should be carried out. To operate on production mechanisms, control mechanisms need to procure information through measurement processes and evaluate possible actions. They are making decisions. In all organisms, these decisions are made by multiple different control mechanisms that are organized not hierarchically but heterarchically. In many cases, they employ internal models of features of the environment with which the organism must deal. Cognition, in the form of decision-making, is thus fundamental to living systems which must control their production mechanisms.

This article is part of the theme issue ‘Basal cognition: conceptual tools and the view from the single cell’.},
	number = {1820},
	urldate = {2023-07-06},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Bechtel, William and Bich, Leonardo},
	month = jan,
	year = {2021},
	note = {Publisher: Royal Society},
	keywords = {/unread, chemotaxis, circadian rhythms, control mechanisms, decision-making, production mechanisms},
	pages = {20190751},
}

@misc{openai2023GPT4,
	title = {{GPT}-4 {Technical} {Report}},
	url = {http://arxiv.org/abs/2303.08774},
	doi = {10.48550/arXiv.2303.08774},
	abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
	urldate = {2023-07-03},
	publisher = {arXiv},
	author = {OpenAI},
	month = mar,
	year = {2023},
	note = {arXiv:2303.08774 [cs]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{gangapurwala2020Guided,
	title = {Guided {Constrained} {Policy} {Optimization} for {Dynamic} {Quadrupedal} {Robot} {Locomotion}},
	volume = {5},
	issn = {2377-3766},
	url = {https://ieeexplore.ieee.org/abstract/document/9028178},
	doi = {10.1109/LRA.2020.2979656},
	abstract = {Deep reinforcement learning (RL) uses model-free techniques to optimize task-specific control policies. Despite having emerged as a promising approach for complex problems, RL is still hard to use reliably for real-world applications. Apart from challenges such as precise reward function tuning, inaccurate sensing and actuation, and non-deterministic response, existing RL methods do not guarantee behavior within required safety constraints that are crucial for real robot scenarios. In this regard, we introduce guided constrained policy optimization (GCPO), an RL framework based upon our implementation of constrained proximal policy optimization (CPPO) for tracking base velocity commands while following the defined constraints. We introduce schemes which encourage state recovery into constrained regions in case of constraint violations. We present experimental results of our training method and test it on the real ANYmal quadruped robot. We compare our approach against the unconstrained RL method and show that guided constrained RL offers faster convergence close to the desired optimum resulting in an optimal, yet physically feasible, robotic control behavior without the need for precise reward function tuning.},
	number = {2},
	urldate = {2023-11-12},
	journal = {IEEE Robotics and Automation Letters},
	author = {Gangapurwala, Siddhant and Mitchell, Alexander and Havoutis, Ioannis},
	month = apr,
	year = {2020},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {/unread},
	pages = {3642--3649},
}

@article{winkler2018Gait,
	title = {Gait and {Trajectory} {Optimization} for {Legged} {Systems} {Through} {Phase}-{Based} {End}-{Effector} {Parameterization}},
	volume = {3},
	issn = {2377-3766},
	url = {https://ieeexplore.ieee.org/abstract/document/8283570},
	doi = {10.1109/LRA.2018.2798285},
	abstract = {We present a single trajectory optimization formulation for legged locomotion that automatically determines the gait sequence, step timings, footholds, swing-leg motions, and six-dimensional body motion over nonflat terrain, without any additional modules. Our phase-based parameterization of feet motion and forces allows to optimize over the discrete gait sequence using only continuous decision variables. The system is represented using a simplified centroidal dynamics model that is influenced by the feet's location and forces. We explicitly enforce friction cone constraints, depending on the shape of the terrain. The nonlinear programming problem solver generates highly dynamic motion plans with full flight phases for a variety of legged systems with arbitrary morphologies in an efficient manner. We validate the feasibility of the generated plans in simulation and on the real quadruped robot ANYmal. Additionally, the entire solver software TOWR, which used to generate these motions is made freely available.},
	number = {3},
	urldate = {2023-11-11},
	journal = {IEEE Robotics and Automation Letters},
	author = {Winkler, Alexander W. and Bellicoso, C. Dario and Hutter, Marco and Buchli, Jonas},
	month = jul,
	year = {2018},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {/unread},
	pages = {1560--1567},
}

@article{li2016Gait,
	title = {Gait {Planning} and {Stability} {Control} of a {Quadruped} {Robot}},
	volume = {2016},
	issn = {1687-5265},
	url = {https://www.hindawi.com/journals/cin/2016/9853070/},
	doi = {10.1155/2016/9853070},
	abstract = {In order to realize smooth gait planning and stability control of a quadruped robot, a new controller algorithm based on CPG-ZMP (central pattern generator-zero moment point) is put forward in this paper. To generate smooth gait and shorten the adjusting time of the model oscillation system, a new CPG model controller and its gait switching strategy based on Wilson-Cowan model are presented in the paper. The control signals of knee-hip joints are obtained by the improved multi-DOF reduced order control theory. To realize stability control, the adaptive speed adjustment and gait switch are completed by the real-time computing of ZMP. Experiment results show that the quadruped robot’s gaits are efficiently generated and the gait switch is smooth in the CPG control algorithm. Meanwhile, the stability of robot’s movement is improved greatly with the CPG-ZMP algorithm. The algorithm in this paper has good practicability, which lays a foundation for the production of the robot prototype.},
	language = {en},
	urldate = {2023-05-16},
	journal = {Computational Intelligence and Neuroscience},
	author = {Li, Junmin and Wang, Jinge and Yang, Simon X. and Zhou, Kedong and Tang, Huijuan},
	month = apr,
	year = {2016},
	note = {Publisher: Hindawi},
	keywords = {/unread},
	pages = {e9853070},
}

@inproceedings{sun2022Formal,
	title = {Formal {Verification} of {Stochastic} {Systems} with {ReLU} {Neural} {Network} {Controllers}},
	url = {https://ieeexplore.ieee.org/abstract/document/9811866},
	doi = {10.1109/ICRA46639.2022.9811866},
	abstract = {In this work, we address the problem of formal safety verification for stochastic cyber-physical systems (CPS) equipped with ReLU neural network (NN) controllers. Our goal is to find the set of initial states from where, with a predetermined confidence, the system will not reach an unsafe configuration within a specified time horizon. Specifically, we consider discrete-time LTI systems with Gaussian noise, which we abstract by a suitable graph. Then, we formulate a Satisfiability Modulo Convex (SMC) problem to estimate upper bounds on the transition probabilities between nodes in the graph. Using this abstraction, we propose a method to compute tight bounds on the safety probabilities of nodes in this graph, despite possible over-approximations of the transition probabilities between these nodes. Additionally, using the proposed SMC formula, we devise a heuristic method to refine the abstraction of the system in order to further improve the estimated safety bounds. Finally, we corroborate the efficacy of the proposed method with simulation results considering a robot navigation example and comparison against a state-of-the-art verification scheme.},
	urldate = {2023-10-13},
	booktitle = {2022 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Sun, Shiqi and Zhang, Yan and Luo, Xusheng and Vlantis, Panagiotis and Pajic, Miroslav and Zavlanos, Michael M.},
	month = may,
	year = {2022},
	keywords = {/unread},
	pages = {6800--6806},
}

@inproceedings{lee2017FEMbased,
	title = {{FEM}-based soft robotic control framework for intracavitary navigation},
	url = {https://ieeexplore.ieee.org/abstract/document/8311828},
	doi = {10.1109/RCAR.2017.8311828},
	abstract = {Bio-inspired robotic structure composed of soft actuation units has attracted increasing research interests in its potential and capacity of complying with unstructured and dynamic environment, as well as providing safe interaction with human; however, this inevitably poses technical challenging to achieve steady, reliable control due to the remarkable non-linearity of its kinematics and dynamics. To resolve this challenge, we propose a novel control framework that can characterize the kinematics of a soft continuum robot through the hyper-elastic Finite-element modeling (FEM). This enables frequent updates of the Jacobian mapping from the user motion input to the end-effector's point of view. Experimental validation has been conducted to show the feasibility of controlling the soft robot for intracavitary path following. This could be the first success to demonstrate the perspectives of achieving stable, accurate and effective manipulation under large change of robot morphology without having to deduce its analytical model. It is anticipated to draw further extensive attention on resolving the bottleneck against the application of FEM, namely its intensive computation.},
	urldate = {2023-10-12},
	booktitle = {2017 {IEEE} {International} {Conference} on {Real}-time {Computing} and {Robotics} ({RCAR})},
	author = {Lee, Kit-Hang and Leong, Martin C. W. and Chow, Marco C. K. and Fu, Hing-Choi and Luk, Wayne and Sze, Kam-Yim and Yeung, Chung-Kwong and Kwok, Ka-Wai},
	month = jul,
	year = {2017},
	keywords = {/unread},
	pages = {11--16},
}

@article{sherstinsky2020Fundamentals,
	title = {Fundamentals of {Recurrent} {Neural} {Network} ({RNN}) and {Long} {Short}-{Term} {Memory} ({LSTM}) network},
	volume = {404},
	issn = {0167-2789},
	url = {https://www.sciencedirect.com/science/article/pii/S0167278919305974},
	doi = {10.1016/j.physd.2019.132306},
	abstract = {Because of their effectiveness in broad practical applications, LSTM networks have received a wealth of coverage in scientific journals, technical blogs, and implementation guides. However, in most articles, the inference formulas for the LSTM network and its parent, RNN, are stated axiomatically, while the training formulas are omitted altogether. In addition, the technique of “unrolling” an RNN is routinely presented without justification throughout the literature. The goal of this tutorial is to explain the essential RNN and LSTM fundamentals in a single document. Drawing from concepts in Signal Processing, we formally derive the canonical RNN formulation from differential equations. We then propose and prove a precise statement, which yields the RNN unrolling technique. We also review the difficulties with training the standard RNN and address them by transforming the RNN into the “Vanilla LSTM”1 1The nickname “Vanilla LSTM” symbolizes this model’s flexibility and generality (Greff et al., 2015). network through a series of logical arguments. We provide all equations pertaining to the LSTM system together with detailed descriptions of its constituent entities. Albeit unconventional, our choice of notation and the method for presenting the LSTM system emphasizes ease of understanding. As part of the analysis, we identify new opportunities to enrich the LSTM system and incorporate these extensions into the Vanilla LSTM network, producing the most general LSTM variant to date. The target reader has already been exposed to RNNs and LSTM networks through numerous available resources and is open to an alternative pedagogical approach. A Machine Learning practitioner seeking guidance for implementing our new augmented LSTM model in software for experimentation and research will find the insights and derivations in this treatise valuable as well.},
	urldate = {2023-10-13},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Sherstinsky, Alex},
	month = mar,
	year = {2020},
	keywords = {/unread, Convolutional input context windows, External input gate, LSTM, RNN, RNN unfolding/unrolling},
	pages = {132306},
}

@article{zhang2023Finding,
	title = {Finding {Critical} {Scenarios} for {Automated} {Driving} {Systems}: {A} {Systematic} {Mapping} {Study}},
	volume = {49},
	issn = {1939-3520},
	shorttitle = {Finding {Critical} {Scenarios} for {Automated} {Driving} {Systems}},
	doi = {10.1109/TSE.2022.3170122},
	abstract = {Scenario-based approaches have been receiving a huge amount of attention in research and engineering of automated driving systems. Due to the complexity and uncertainty of the driving environment, and the complexity of the driving task itself, the number of possible driving scenarios that an Automated Driving System or Advanced Driving-Assistance System may encounter is virtually infinite. Therefore it is essential to be able to reason about the identification of scenarios and in particular critical ones that may impose unacceptable risk if not considered. Critical scenarios are particularly important to support design, verification and validation efforts, and as a basis for a safety case. In this paper, we present the results of a systematic mapping study in the context of autonomous driving. The main contributions are: (i) introducing a comprehensive taxonomy for critical scenario identification methods; (ii) giving an overview of the state-of-the-art research based on the taxonomy encompassing 86 papers between 2017 and 2020; and (iii) identifying open issues and directions for further research. The provided taxonomy comprises three main perspectives encompassing the problem definition (the why), the solution (the methods to derive scenarios), and the assessment of the established scenarios. In addition, we discuss open research issues considering the perspectives of coverage, practicability, and scenario space explosion.},
	number = {3},
	journal = {IEEE Transactions on Software Engineering},
	author = {Zhang, Xinhai and Tao, Jianbo and Tan, Kaige and Törngren, Martin and Sánchez, José Manuel Gaspar and Ramli, Muhammad Rusyadi and Tao, Xin and Gyllenhammar, Magnus and Wotawa, Franz and Mohan, Naveen and Nica, Mihai and Felbinger, Hermann},
	month = mar,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Software Engineering},
	keywords = {/unread, Bibliographies, Complexity theory, Critical scenario, Roads, Systematics, Taxonomy, Terminology, Uncertainty, automated driving, systematic mapping study},
	pages = {991--1026},
}

@article{xu2019Gait,
	title = {Gait {Analysis} of {Quadruped} {Robot} {Using} the {Equivalent} {Mechanism} {Concept} {Based} on {Metamorphosis}},
	volume = {32},
	issn = {2192-8258},
	url = {https://doi.org/10.1186/s10033-019-0321-2},
	doi = {10.1186/s10033-019-0321-2},
	abstract = {The previous research regarding the gait planning of quadruped robot focuses on the sequence for lifting off and placing the feet, but neglects the influence of body height. However, body height affects gait performance significantly, such as in terms of the stride length and stability margin. We herein study the performance of a quadruped robot using the equivalent mechanism concept based on metamorphosis. Assuming the constraints between standing feet and the ground with hinges, the ground, standing legs and robot body are considered as a parallel mechanism, and each swing leg is regarded as a typical serial manipulator. The equivalent mechanism varies while the robot moves on the ground. One gait cycle is divided into several periods, including step forward stages and switching stages. There exists a specific equivalent mechanism corresponding to each gait period. The robot’s locomotion can be regarded as the motion of these series of equivalent mechanisms. The kinematics model and simplified model of the equivalent mechanism is established. A new definition of the multilegged robot stability margin, based on friction coefficient, is presented to evaluate the robot stability. The stable workspaces of the equivalent mechanism in the step forward stage of trotting gait under different friction coefficients are analyzed. The stride length of the robots is presented by analyzing the relationship between the stable workspaces of the equivalent mechanisms of two adjacent step forward stages in one gait cycle. The simulation results show that the stride length is larger with increasing friction coefficient. We herein propose a new method based on metamorphosis, and an equivalent mechanism to analyze the stability margin and stable workspace of the multilegged robot.},
	language = {en},
	number = {1},
	urldate = {2023-10-12},
	journal = {Chinese Journal of Mechanical Engineering},
	author = {Xu, Kun and Zi, Peijin and Ding, Xilun},
	month = feb,
	year = {2019},
	keywords = {/unread, Gait transference, Metamorphic mechanism, Metamorphosis, Quadruped robot, Stability, Stride length},
	pages = {8},
}

@article{akhtaruzzaman2016Gait,
	title = {Gait analysis: systems, technologies, and importance},
	volume = {16},
	issn = {0219-5194},
	shorttitle = {Gait analysis},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0219519416300039},
	doi = {10.1142/S0219519416300039},
	abstract = {Human gait is the identity of a person's style and quality of life. Reliable cognition of gait properties over time, continuous monitoring, accuracy of evaluation, and proper analysis of human gait characteristics have demonstrated their importance not only in clinical and medical studies, but also in the field of sports, rehabilitation, training, and robotics research. Focusing on walking gait, this study presents an overview on gait mechanisms, common technologies used in gait analysis, and importance of this particular field of research. Firstly, available technologies that involved in gait analysis are briefly introduced in this paper by concentrating on the usability and limitations of the systems. Secondly, key gait parameters and motion characteristics are elucidated from four angles of views; one: gait phases and gait properties; two: center of mass and center of pressure (CoM-CoP) tracking profile; three: Ground Reaction Force (GRF) and impact, and four: muscle activation. Thirdly, the study focuses on the clinical observations of gait patterns in diagnosing gait abnormalities of impaired patients. The presentation also shows the importance of gait analysis in sports to improve performance as well as to avoid risk of injuries of sports personnel. Significance of gait analysis in robotic research is also illustrated in this part where the study focuses on robot assisted systems and its possible applicability in clinical rehabilitation and sports training.},
	number = {07},
	urldate = {2023-10-12},
	journal = {Journal of Mechanics in Medicine and Biology},
	author = {Akhtaruzzaman, Md. and Shafie, Amir Akramin and Khan, Md. Raisuddin},
	month = nov,
	year = {2016},
	note = {Publisher: World Scientific Publishing Co.},
	keywords = {/unread, Gait analysis, gait characteristics, gait rehabilitation, gait training, human walking pattern, sports gait analysis},
	pages = {1630003},
}

@article{koval2022Experimental,
	title = {Experimental evaluation of autonomous map-based {Spot} navigation in confined environments},
	volume = {2},
	issn = {2667-3797},
	url = {https://www.sciencedirect.com/science/article/pii/S2667379722000018},
	doi = {10.1016/j.birob.2022.100035},
	abstract = {In this article, we address the task of experimental evaluation of autonomous map-based navigation of a Boston Dynamics Spot quadruped robot in confined environments equipped with the developed autonomy package that incorporates a 3D lidar, an IMU, and an onboard computer. For that, we propose an integrated software and hardware system that is considered as an enabler for robot localization and risk-aware path planning, based on the known map. The system design itself is modular and incorporates the perception capabilities required for autonomous navigation. The Spot robot first is utilized to build the offline map of the environment by utilizing the Google Cartographer simultaneous localization and mapping (SLAM) package. During the next step, the online environmental information from the autonomy package sensors and the offline map are provided to the onboard computer to localize the robot on the known map by utilizing means provided by Cartographer. Finally, the occupancy information is provided to the online grid-based path planner that generates risk-aware paths. The extensive experimental evaluation of the proposed system is performed in corridors and SubT environments.},
	number = {1},
	urldate = {2023-10-06},
	journal = {Biomimetic Intelligence and Robotics},
	author = {Koval, Anton and Karlsson, Samuel and Nikolakopoulos, George},
	month = mar,
	year = {2022},
	keywords = {/unread, 3D lidar, Autonomy package, Map-based navigation, Spot, SubT},
	pages = {100035},
}

@article{song2023Energy,
	title = {Energy consumption auditing based on a generative adversarial network for anomaly detection of robotic manipulators},
	volume = {149},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X2300287X},
	doi = {10.1016/j.future.2023.07.034},
	abstract = {This paper presents a generative adversarial network (GAN)-based energy auditing and anomaly detection framework for the health and security monitoring of robotic manipulators. The system features two key components: a side-channel measurement of the energy consumption and a GAN model to learn the data patterns during normal operations only. Anomalies in energy consumption during online testing are then discovered as outliers to the normal data by scrutinizing the anomaly score produced by the discriminator of the GAN model. This semi-supervised network circumvents the need for vast data labeling and exploits the overfitting during the training stage, hence magnifying the difference between the normal patterns learned in training and the unobserved abnormal energy profiles in testing. Moreover, considering the physical aspects of the robotic manipulator, a modified GAN architecture containing multiple discriminators to account for distinct contributions from individual joints/motors. A dynamic thresholding approach that continuously updates the statistical characteristics of the anomaly score is also developed to detect outliers and mitigate the effect of environmental variations during system operation. The proposed framework is tested on the custom dataset for performance evaluation. The results demonstrate the feasibility of the proposed method, especially for detecting physical attacks, which achieves an accuracy of approximately 0.93 in instant-level detection and over 0.84 in event-level detection.},
	language = {en},
	urldate = {2023-08-13},
	journal = {Future Generation Computer Systems},
	author = {Song, Ge and Hong, Seong Hyeon and Kyzer, Tristan and Wang, Yi},
	month = dec,
	year = {2023},
	keywords = {/unread, Anomaly detection, Cyber–physical attack, Energy auditing, Generative adversarial network, Robotic manipulator, Side-channel mechanism},
	pages = {376--389},
}

@inproceedings{kalakrishnan2010Fast,
	title = {Fast, robust quadruped locomotion over challenging terrain},
	doi = {10.1109/ROBOT.2010.5509805},
	abstract = {We present a control architecture for fast quadruped locomotion over rough terrain. We approach the problem by decomposing it into many sub-systems, in which we apply state-of-the-art learning, planning, optimization and control techniques to achieve robust, fast locomotion. Unique features of our control strategy include: (1) a system that learns optimal foothold choices from expert demonstration using terrain templates, (2) a body trajectory optimizer based on the Zero-Moment Point (ZMP) stability criterion, and (3) a floating-base inverse dynamics controller that, in conjunction with force control, allows for robust, compliant locomotion over unperceived obstacles. We evaluate the performance of our controller by testing it on the LittleDog quadruped robot, over a wide variety of rough terrain of varying difficulty levels. We demonstrate the generalization ability of this controller by presenting test results from an independent external test team on terrains that have never been shown to us.},
	booktitle = {2010 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Kalakrishnan, Mrinal and Buchli, Jonas and Pastor, Peter and Mistry, Michael and Schaal, Stefan},
	month = may,
	year = {2010},
	note = {ISSN: 1050-4729},
	keywords = {/unread, Foot, Force control, Leg, Legged locomotion, Mobile robots, Optimal control, Robust control, Robustness, Size control, Software testing},
	pages = {2665--2670},
}

@article{lang2012Exploration,
	title = {Exploration in {Relational} {Domains} for {Model}-based {Reinforcement} {Learning}},
	volume = {13},
	abstract = {A fundamental problem in reinforcement learning is balancing exploration and exploitation. We address this problem in the context of model-based reinforcement learning in large stochastic relational domains by developing relational extensions of the concepts of the E3 and R-MAX algorithms. Efﬁcient exploration in exponentially large state spaces needs to exploit the generalization of the learned model: what in a propositional setting would be considered a novel situation and worth exploration may in the relational setting be a well-known context in which exploitation is promising. To address this we introduce relational count functions which generalize the classical notion of state and action visitation counts. We provide guarantees on the exploration efﬁciency of our framework using count functions under the assumption that we had a relational KWIK learner and a near-optimal planner. We propose a concrete exploration algorithm which integrates a practically efﬁcient probabilistic rule learner and a relational planner (for which there are no guarantees, however) and employs the contexts of learned relational rules as features to model the novelty of states and actions. Our results in noisy 3D simulated robot manipulation problems and in domains of the international planning competition demonstrate that our approach is more effective than existing propositional and factored exploration techniques.},
	language = {en},
	journal = {Journal of Machine Learning Research},
	author = {Lang, Tobias and Toussaint, Marc and Kersting, Kristian},
	month = dec,
	year = {2012},
	keywords = {/unread},
	pages = {3725--3768},
}

@article{ji2022Development,
	title = {Development of a {3D} {Printed} {Multi}-{Axial} {Force} {Sensor}},
	url = {https://ebooks.iospress.nl/doi/10.3233/ATDE220178},
	doi = {10.3233/ATDE220178},
	urldate = {2022-10-14},
	journal = {SPS2022},
	author = {Ji, Qinglei and Fu, Shuo and Feng, Lei and Andrikopoulos, Georgios and Wang, Xi Vincent and Wang, Lihui},
	year = {2022},
	note = {0 citations (Crossref) [2022-12-07]
Publisher: IOS Press},
	keywords = {/unread},
	pages = {604--614},
}

@inproceedings{dicarlo2018Dynamic,
	title = {Dynamic {Locomotion} in the {MIT} {Cheetah} 3 {Through} {Convex} {Model}-{Predictive} {Control}},
	doi = {10.1109/IROS.2018.8594448},
	abstract = {This paper presents an implementation of model predictive control (MPC) to determine ground reaction forces for a torque-controlled quadruped robot. The robot dynamics are simplified to formulate the problem as convex optimization while still capturing the full 3D nature of the system. With the simplified model, ground reaction force planning problems are formulated for prediction horizons of up to 0.5 seconds, and are solved to optimality in under 1 ms at a rate of 20-30 Hz. Despite using a simplified model, the robot is capable of robust locomotion at a variety of speeds. Experimental results demonstrate control of gaits including stand, trot, flying-trot, pronk, bound, pace, a 3-legged gait, and a full 3D gallop. The robot achieved forward speeds of up to 3 m/s, lateral speeds up to 1 m/s, and angular speeds up to 180 deg/sec. Our approach is general enough to perform all these behaviors with the same set of gains and weights.},
	booktitle = {2018 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Di Carlo, Jared and Wensing, Patrick M. and Katz, Benjamin and Bledt, Gerardo and Kim, Sangbae},
	month = oct,
	year = {2018},
	note = {ISSN: 2153-0866},
	keywords = {/unread, Convex functions, Dynamics, Legged locomotion, Predictive control, Predictive models, Robot kinematics},
	pages = {1--9},
}

@article{wang2022Efficient,
	title = {Efficient learning of robust quadruped bounding using pretrained neural networks},
	volume = {4},
	issn = {2631-6315},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/csy2.12062},
	doi = {10.1049/csy2.12062},
	abstract = {Bounding is one of the important gaits in quadrupedal locomotion for negotiating obstacles. The authors proposed an effective approach that can learn robust bounding gaits more efficiently despite its large variation in dynamic body movements. The authors first pretrained the neural network (NN) based on data from a robot operated by conventional model-based controllers, and then further optimised the pretrained NN via deep reinforcement learning (DRL). In particular, the authors designed a reward function considering contact points and phases to enforce the gait symmetry and periodicity, which improved the bounding performance. The NN-based feedback controller was learned in the simulation and directly deployed on the real quadruped robot Jueying Mini successfully. A variety of environments are presented both indoors and outdoors with the authors’ approach. The authors’ approach shows efficient computing and good locomotion results by the Jueying Mini quadrupedal robot bounding over uneven terrain. The cover image is based on the Research Article Efficient learning of robust quadruped bounding using pretrained neural networks by Zhicheng Wang et al., https://doi.org/10.1049/csy2.12062.},
	language = {en},
	number = {4},
	urldate = {2023-03-27},
	journal = {IET Cyber-Systems and Robotics},
	author = {Wang, Zhicheng and Li, Anqiao and Zheng, Yixiao and Xie, Anhuan and Li, Zhibin and Wu, Jun and Zhu, Qiuguo},
	year = {2022},
	note = {0 citations (Semantic Scholar/DOI) [2023-04-11]
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1049/csy2.12062},
	keywords = {/unread, legged locomotion, reinforcement learning, robot learning},
	pages = {331--338},
}

@article{li2023Development,
	title = {Development and field evaluation of a robotic harvesting system for plucking high-quality tea},
	volume = {206},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169923000479},
	doi = {10.1016/j.compag.2023.107659},
	abstract = {The critical issue of the robotic harvesting high-quality tea is to realize tea shoot detection, plucking point localization, and motion planning. In addition, the accuracy and efficiency of the robotic plucking of high-quality tea in the field are essential. Therefore, a robotic harvesting system is proposed in this paper by combining deep learning, point cloud processing, and spatial path planning. First, the deep learning method and the compressed YOLOv3 network are used to quickly and accurately identify tea shoots. Second, an efficient point cloud processing-based 3D localization algorithm for high-quality tea plucking points was proposed. The genetic algorithm is then used to shorten the end-effector's motion path by optimizing the plucking sequences. Eventually, a harvester robot with a parallel manipulator was developed to conduct field plucking experiments and evaluate the effectiveness of the proposed harvesting system. All experimental results demonstrate that the success rates of detection, localization, and motion plucking are 85.16 \%, 78.90 \%, and 80.23 \%, respectively. Furthermore, the overall process harvesting success rate is 53.91 \%, and the average plucking time for a single shoot is 2.233 s. Therefore, the proposed harvesting approach can provide technical support for the precise and rapid harvesting of high-quality tea.},
	language = {en},
	urldate = {2023-07-03},
	journal = {Computers and Electronics in Agriculture},
	author = {Li, Yatao and Wu, Shunkai and He, Leiying and Tong, Junhua and Zhao, Runmao and Jia, Jiangming and Chen, Jianneng and Wu, Chuanyu},
	month = mar,
	year = {2023},
	keywords = {/unread, High-quality tea, Plucking sequence optimization, Point cloud process, Tea harvesting robots},
	pages = {107659},
}

@article{tan2024EdgeEnabled,
	title = {Edge-{Enabled} {Adaptive} {Shape} {Estimation} of 3-{D} {Printed} {Soft} {Actuators} {With} {Gaussian} {Processes} and {Unscented} {Kalman} {Filters}},
	volume = {71},
	issn = {1557-9948},
	url = {https://ieeexplore.ieee.org/abstract/document/10113847},
	doi = {10.1109/TIE.2023.3270505},
	abstract = {Soft actuators have the advantages of compliance and adaptability when working with vulnerable objects, but the deformation shape of the soft actuators is difficult to measure or estimate. Soft sensors made of highly flexible and responsive materials are promising new approaches to the shape estimation of soft actuators, but suffer from highly nonlinear, hysteresis, and time-variant properties. A nonlinear and adaptive state observer is essential for shape estimation from soft sensors. Current state estimation methods rely on complex nonlinear data-fitting models, and the robustness of the estimation methods is questionable. This study investigates the soft actuator dynamics and the soft sensor model as a stochastic process characterized by the Gaussian process (GP) model. The unscented Kalman filter is applied to the GP model for more reliable variance adjustment during the sequential state estimation process than conventional methods. In addition, a major limitation of the GP model is its computational complexity during online inference. To improve the real-time performance while guaranteeing accuracy, we introduce an edge server to decrease the onboard computational and memory overhead. The experiments showcase a significant improvement in estimation accuracy and real-time performance compared to baseline methods.},
	number = {3},
	urldate = {2023-10-01},
	journal = {IEEE Transactions on Industrial Electronics},
	author = {Tan, Kaige and Ji, Qinglei and Feng, Lei and Törngren, Martin},
	month = mar,
	year = {2024},
	note = {Conference Name: IEEE Transactions on Industrial Electronics},
	keywords = {/unread},
	pages = {3044--3054},
}

@article{biswal2021Development,
	title = {Development of quadruped walking robots: {A} review},
	volume = {12},
	issn = {2090-4479},
	shorttitle = {Development of quadruped walking robots},
	url = {https://www.sciencedirect.com/science/article/pii/S2090447920302501},
	doi = {10.1016/j.asej.2020.11.005},
	abstract = {Nowadays, design, development, and motion planning of a mobile robot explore research areas in the field of robotics. Mobile robots have an extensive area of applications in various fields like space exploration, military application, industrial use, and many more. Hence, the design and development of a mobile robot is a crucial part of the above application. Among all the mobile robot, the quadrupedal robot is a legged robot, which is superior to wheeled and tracked robot due to its potential to explore in all the terrain like the human and animal. In this paper, the survey concentrates on various design and development approaches for the quadrupedal robot, and environment perception techniques are discussed. Besides, Spot is one of the most advanced and intelligent quadrupedal robots. The performance of each quadruped robot and the future outline are provided in details.},
	language = {en},
	number = {2},
	urldate = {2022-11-16},
	journal = {Ain Shams Engineering Journal},
	author = {Biswal, Priyaranjan and Mohanty, Prases K.},
	month = jun,
	year = {2021},
	note = {67 citations (Semantic Scholar/DOI) [2023-04-11]
35 citations (Crossref) [2022-12-07]},
	keywords = {/unread, Actuator, Gait, Legged robot, Payload, Quadruped robot},
	pages = {2017--2031},
}

@inproceedings{hu2021Design,
	title = {Design of a {Quadruped} inspection {Robot} {Used} in {Substation}},
	volume = {4},
	doi = {10.1109/IMCEC51613.2021.9482003},
	abstract = {Nowadays, the substation inspection robot always uses wheeled chassis, which is suitable for running on relatively flat road. However, there are steps, stone road, stairs and other complex terrain in substation, so it is difficult to achieve full coverage of inspection area. In order to solve this problem, a prototype system of quadruped inspection robot is designed, and the hardware and software structure and design points are described in detail. In addition, the software system architecture based on B/S mode is also discussed briefly. Finally, the designed robot proposed in this paper is tested in a 500kV substation to verify the adaptability of the quadruped inspection robot to the complex terrain of the environment.},
	booktitle = {2021 {IEEE} 4th {Advanced} {Information} {Management}, {Communicates}, {Electronic} and {Automation} {Control} {Conference} ({IMCEC})},
	author = {Hu, Xuran and He, Feng and Xiao, Peng and Wang, Tao and Zhang, Decai and Zhou, Xingfu and Fan, Yan},
	month = jun,
	year = {2021},
	note = {ISSN: 2693-2776},
	keywords = {/unread, Inspection, Roads, Stairs, Substations, Temperature control, Temperature distribution, Temperature measurement, inspection, quadruped robot, substation},
	pages = {766--769},
}

@inproceedings{matl2021Deformable,
	title = {Deformable {Elasto}-{Plastic} {Object} {Shaping} using an {Elastic} {Hand} and {Model}-{Based} {Reinforcement} {Learning}},
	doi = {10.1109/IROS51168.2021.9636808},
	abstract = {Deformable solid objects such as clay or dough are prevalent in industrial and home environments. However, robotic manipulation of such objects has largely remained unexplored in literature due to the high complexity involved in representing and modeling their deformation. This work addresses the problem of shaping elasto-plastic dough by proposing to use a novel elastic end-effector to roll dough in a reinforcement learning framework. The transition model for the end-effector-to-dough interactions is learned from one hour of robot exploration, and doughs of different hydration levels are rolled out into varying lengths. Experimental results are encouraging, with the proposed framework accomplishing the task of rolling out dough into a specified length with 60\% fewer actions than a heuristic method. Furthermore, we show that estimating stiffness using the soft end-effector can be used to effectively initialize models, improving robot performance by approximately 40\% over incorrect model initialization.},
	booktitle = {2021 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Matl, Carolyn and Bajcsy, Ruzena},
	month = sep,
	year = {2021},
	note = {6 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2153-0866},
	keywords = {/unread, Deformable models, End effectors, Reinforcement learning, Service robots, Shape, Solid modeling, Solids},
	pages = {3955--3962},
}

@inproceedings{silver2014Deterministic,
	title = {Deterministic {Policy} {Gradient} {Algorithms}},
	url = {https://proceedings.mlr.press/v32/silver14.html},
	abstract = {In this paper we consider deterministic policy gradient algorithms for reinforcement learning with continuous actions. The deterministic policy gradient has a particularly appealing form: it is the expected gradient of the action-value function. This simple form means that the deterministic policy gradient can be estimated much more efficiently than the usual stochastic policy gradient. To ensure adequate exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic target policy from an exploratory behaviour policy. Deterministic policy gradient algorithms outperformed their stochastic counterparts in several benchmark problems, particularly in high-dimensional action spaces.},
	language = {en},
	urldate = {2023-07-11},
	booktitle = {Proceedings of the 31st {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
	month = jan,
	year = {2014},
	note = {ISSN: 1938-7228},
	keywords = {/unread},
	pages = {387--395},
}

@article{rus2015Design,
	title = {Design, fabrication and control of soft robots},
	volume = {521},
	copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14543},
	doi = {10.1038/nature14543},
	abstract = {Conventionally, engineers have employed rigid materials to fabricate precise, predictable robotic systems, which are easily modelled as rigid members connected at discrete joints. Natural systems, however, often match or exceed the performance of robotic systems with deformable bodies. Cephalopods, for example, achieve amazing feats of manipulation and locomotion without a skeleton; even vertebrates such as humans achieve dynamic gaits by storing elastic energy in their compliant bones and soft tissues. Inspired by nature, engineers have begun to explore the design and control of soft-bodied robots composed of compliant materials. This Review discusses recent developments in the emerging field of soft robotics.},
	language = {en},
	number = {7553},
	urldate = {2022-12-07},
	journal = {Nature},
	author = {Rus, Daniela and Tolley, Michael T.},
	month = may,
	year = {2015},
	note = {3251 citations (Semantic Scholar/DOI) [2023-04-11]
2961 citations (Crossref) [2022-12-07]
Number: 7553
Publisher: Nature Publishing Group},
	keywords = {/unread, Engineering, Technology},
	pages = {467--475},
}

@article{tsounis2020DeepGait,
	title = {{DeepGait}: {Planning} and {Control} of {Quadrupedal} {Gaits} {Using} {Deep} {Reinforcement} {Learning}},
	volume = {5},
	issn = {2377-3766},
	shorttitle = {{DeepGait}},
	url = {https://ieeexplore.ieee.org/abstract/document/9028188},
	doi = {10.1109/LRA.2020.2979660},
	abstract = {This letter addresses the problem of legged locomotion in non-flat terrain. As legged robots such as quadrupeds are to be deployed in terrains with geometries which are difficult to model and predict, the need arises to equip them with the capability to generalize well to unforeseen situations. In this work, we propose a novel technique for training neural-network policies for terrain-aware locomotion, which combines state-of-the-art methods for model-based motion planning and reinforcement learning. Our approach is centered on formulating Markov decision processes using the evaluation of dynamic feasibility criteria in place of physical simulation. We thus employ policy-gradient methods to independently train policies which respectively plan and execute foothold and base motions in 3D environments using both proprioceptive and exteroceptive measurements. We apply our method within a challenging suite of simulated terrain scenarios which contain features such as narrow bridges, gaps and stepping-stones, and train policies which succeed in locomoting effectively in all cases.},
	number = {2},
	urldate = {2023-11-11},
	journal = {IEEE Robotics and Automation Letters},
	author = {Tsounis, Vassilios and Alge, Mitja and Lee, Joonho and Farshidian, Farbod and Hutter, Marco},
	month = apr,
	year = {2020},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {/unread},
	pages = {3699--3706},
}

@misc{wu2022DayDreamer,
	title = {{DayDreamer}: {World} {Models} for {Physical} {Robot} {Learning}},
	shorttitle = {{DayDreamer}},
	url = {http://arxiv.org/abs/2206.14176},
	abstract = {To solve tasks in complex environments, robots need to learn from experience. Deep reinforcement learning is a common approach to robot learning but requires a large amount of trial and error to learn, limiting its deployment in the physical world. As a consequence, many advances in robot learning rely on simulators. On the other hand, learning inside of simulators fails to capture the complexity of the real world, is prone to simulator inaccuracies, and the resulting behaviors do not adapt to changes in the world. The Dreamer algorithm has recently shown great promise for learning from small amounts of interaction by planning within a learned world model, outperforming pure reinforcement learning in video games. Learning a world model to predict the outcomes of potential actions enables planning in imagination, reducing the amount of trial and error needed in the real environment. However, it is unknown whether Dreamer can facilitate faster learning on physical robots. In this paper, we apply Dreamer to 4 robots to learn online and directly in the real world, without simulators. Dreamer trains a quadruped robot to roll off its back, stand up, and walk from scratch and without resets in only 1 hour. We then push the robot and find that Dreamer adapts within 10 minutes to withstand perturbations or quickly roll over and stand back up. On two different robotic arms, Dreamer learns to pick and place multiple objects directly from camera images and sparse rewards, approaching human performance. On a wheeled robot, Dreamer learns to navigate to a goal position purely from camera images, automatically resolving ambiguity about the robot orientation. Using the same hyperparameters across all experiments, we find that Dreamer is capable of online learning in the real world, establishing a strong baseline. We release our infrastructure for future applications of world models to robot learning.},
	urldate = {2022-11-21},
	publisher = {arXiv},
	author = {Wu, Philipp and Escontrela, Alejandro and Hafner, Danijar and Goldberg, Ken and Abbeel, Pieter},
	month = jun,
	year = {2022},
	note = {27 citations (Semantic Scholar/arXiv) [2023-04-11]
arXiv:2206.14176 [cs]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics},
}

@article{rosolia2018DataDriven,
	title = {Data-{Driven} {Predictive} {Control} for {Autonomous} {Systems}},
	volume = {1},
	url = {https://doi.org/10.1146/annurev-control-060117-105215},
	doi = {10.1146/annurev-control-060117-105215},
	abstract = {In autonomous systems, the ability to make forecasts and cope with uncertain predictions is synonymous with intelligence. Model predictive control (MPC) is an established control methodology that systematically uses forecasts to compute real-time optimal control decisions. In MPC, at each time step an optimization problem is solved over a moving horizon. The objective is to find a control policy that minimizes a predicted performance index while satisfying operating constraints. Uncertainty in MPC is handled by optimizing over multiple uncertain forecasts. In this case, performance index and operating constraints take the form of functions defined over a probability space, and the resulting technique is called stochastic MPC. Our research over the past 10 years has focused on predictive control design methods that systematically handle uncertain forecasts in autonomous and semiautonomous systems. In the first part of this article, we present an overview of the approach we use, its main advantages, and its challenges. In the second part, we present our most recent results on data-driven predictive control. We show how to use data to efficiently formulate stochastic MPC problems and autonomously improve performance in repetitive tasks. The proposed framework is able to handle a large set of predicted scenarios in real time and learn from historical data.},
	number = {1},
	urldate = {2023-03-09},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Rosolia, Ugo and Zhang, Xiaojing and Borrelli, Francesco},
	year = {2018},
	note = {50 citations (Semantic Scholar/DOI) [2023-04-11]
\_eprint: https://doi.org/10.1146/annurev-control-060117-105215},
	keywords = {/unread, Data-driven control, Review},
	pages = {259--286},
}

@book{goodfellow2016Deep,
	title = {Deep learning},
	publisher = {MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
	keywords = {/unread},
}

@inproceedings{li2021Deep,
	title = {Deep {Convolution} and {Gated} {Recurrent} {Unit} {Network} for {Robot} {Perceptual} {Intelligent} {Recognition}},
	url = {https://ieeexplore.ieee.org/abstract/document/9408903},
	doi = {10.1109/ICSP51882.2021.9408903},
	abstract = {Intelligent prediction and pattern recognition (PR) classification technology based on deep learning has attracted widespread attention from scholars in the field because it does not rely on subjective human analysis and reasoning. In this paper, a variant of convolutional neural network and recurrent neural network (RNN) is constructed by combining feature engineering and deep learning. A convolution-gated recurrent unit network (i.e., CONV-GRU) is proposed by improving the network structure and optimization algorithm. The model has an accurate effect on the recognition of the contact surface of autonomous mobile robots, with an accuracy rate of 90\%. In addition, CONV-GRU also solves the over-fitting phenomenon of the benchmark model (RNN, LSTM, GRU). The research aims to solve the key problems of intelligent robot in tactile sensing, signal processing and intelligent computing technology.},
	urldate = {2023-10-13},
	booktitle = {2021 6th {International} {Conference} on {Intelligent} {Computing} and {Signal} {Processing} ({ICSP})},
	author = {Li, Ziheng and Zuo, Jiankai and Wu, Jiehong and Song, Yifan and Geng, Shenglin and Li, Junyi},
	month = apr,
	year = {2021},
	keywords = {/unread},
	pages = {792--795},
}

@article{wang2018Current,
	title = {Current {Researches} and {Future} {Development} {Trend} of {Intelligent} {Robot}: {A} {Review}},
	volume = {15},
	issn = {1751-8520},
	shorttitle = {Current {Researches} and {Future} {Development} {Trend} of {Intelligent} {Robot}},
	url = {https://doi.org/10.1007/s11633-018-1115-1},
	doi = {10.1007/s11633-018-1115-1},
	abstract = {With the advancing of industrialization and the advent of the information age, intelligent robots play an increasingly important role in intelligent manufacturing, intelligent transportation system, the Internet of things, medical health and intelligent services. Based on working experiences in and reviews on intelligent robot studies both in China and abroad, the authors summarized researches on key and leading technologies related to human-robot collaboration, driverless technology, emotion recognition, brain-computer interface, bionic software robot and cloud platform, big data network, etc. The development trend of intelligent robot was discussed, and reflections on and suggestions to intelligent robot development in China were proposed. The review is not only meant to overview leading technologies of intelligent robot all over the world, but also provide related theories, methods and technical guidance to the technological and industrial development of intelligent robot in China.},
	language = {en},
	number = {5},
	urldate = {2023-03-09},
	journal = {International Journal of Automation and Computing},
	author = {Wang, Tian-Miao and Tao, Yong and Liu, Hui},
	month = oct,
	year = {2018},
	note = {4 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread, Intelligent robot, big data network, brain-computer interface, driverless technology, emotion recognition, human-robot collaboration},
	pages = {525--546},
}

@article{arulkumaran2017Deep,
	title = {Deep {Reinforcement} {Learning}: {A} {Brief} {Survey}},
	volume = {34},
	issn = {1558-0792},
	shorttitle = {Deep {Reinforcement} {Learning}},
	doi = {10.1109/MSP.2017.2743240},
	abstract = {Deep reinforcement learning (DRL) is poised to revolutionize the field of artificial intelligence (AI) and represents a step toward building autonomous systems with a higher-level understanding of the visual world. Currently, deep learning is enabling reinforcement learning (RL) to scale to problems that were previously intractable, such as learning to play video games directly from pixels. DRL algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera inputs in the real world. In this survey, we begin with an introduction to the general field of RL, then progress to the main streams of value-based and policy-based methods. Our survey will cover central algorithms in deep RL, including the deep Q-network (DQN), trust region policy optimization (TRPO), and asynchronous advantage actor critic. In parallel, we highlight the unique advantages of deep neural networks, focusing on visual understanding via RL. To conclude, we describe several current areas of research within the field.},
	number = {6},
	journal = {IEEE Signal Processing Magazine},
	author = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
	month = nov,
	year = {2017},
	note = {1404 citations (Semantic Scholar/DOI) [2023-04-11]
1252 citations (Crossref) [2022-12-07]
Conference Name: IEEE Signal Processing Magazine},
	keywords = {/unread, Artificial intelligence, Learning (artificial intelligence), Machine learning, Neural networks, Signal processing algorithms, Visualization},
	pages = {26--38},
}

@article{neuhaus2011Comprehensive,
	title = {Comprehensive summary of the {Institute} for {Human} and {Machine} {Cognition}’s                 experience with {LittleDog}},
	volume = {30},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364910390538},
	doi = {10.1177/0278364910390538},
	abstract = {We discuss the main issues and challenges with quadrupedal locomotion over rough terrain in the context of the Defense Advanced Research Projects Agency’s Learning Locomotion program. We present our controller for the LittleDog platform, which allows for continuous transition between a static crawl gait and a dynamic trot gait depending on the roughness of the terrain. We provide detailed descriptions for some of our key algorithm components, such as a fast footstep planner for rough terrain, a body pose finder for a given support polygon, and a new type of parameterized gait. We present the results of our algorithm, which proved successful in the program, crossing all 10 terrain boards on the final test at an average speed of 11.2 cm/s. We conclude with a discussion on the applicability of this work for platforms other than LittleDog and in environments other than the Learning Locomotion designed tests.},
	language = {en},
	number = {2},
	urldate = {2023-07-11},
	journal = {The International Journal of Robotics Research},
	author = {Neuhaus, Peter D and Pratt, Jerry E and Johnson, Matthew J},
	month = feb,
	year = {2011},
	note = {Publisher: SAGE Publications Ltd STM},
	keywords = {/unread},
	pages = {216--235},
}

@inproceedings{bledt2018Contact,
	title = {Contact {Model} {Fusion} for {Event}-{Based} {Locomotion} in {Unstructured} {Terrains}},
	doi = {10.1109/ICRA.2018.8460904},
	abstract = {As legged robots are sent into unstructured environments, the ability to robustly manage contact transitions will be a critical skill. This paper introduces an approach to probabilistically fuse contact models, managing uncertainty in terrain geometry, dynamic modeling, and kinematics to improve the robustness of contact initiation at touchdown. A discrete-time extension of the generalized-momentum disturbance observer is presented to increase the accuracy of proprioceptive force control estimates. This information is fused with other contact priors under a framework of Kalman Filtering to increase robustness of the method. This approach results in accurate contact detection with 99.3 \% accuracy and a small 4-5ms delay. Using this new detector, an Event-Based Finite State Machine is implemented to deal with unexpected early and late contacts. This allows the robot to traverse cluttered environments by modifying the control actions for each individual leg based on the estimated contact state rather than adhering to a rigid time schedule regardless of actual contact state. Experiments with the MIT Cheetah 3 robot show the success of both the detection algorithm, as well as the Event-Based FSM while making unexpected contacts during trotting.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Bledt, Gerardo and Wensing, Patrick M. and Ingersoll, Sam and Kim, Sangbae},
	month = may,
	year = {2018},
	note = {ISSN: 2577-087X},
	keywords = {/unread, Disturbance observers, Force, Legged locomotion, Robot sensing systems, Robustness},
	pages = {4399--4406},
}

@article{wang2022Control,
	title = {Control {Strategies} for {Soft} {Robot} {Systems}},
	volume = {4},
	issn = {2640-4567},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aisy.202100165},
	doi = {10.1002/aisy.202100165},
	abstract = {Soft robots have recently attracted increased attention because their characteristics of low-cost fabrication, durability, and deformability make them uniquely suited for applications in bio-integrated systems. Being fundamentally different from traditional rigid robots, soft robots exhibit properties of infinite degrees of freedom (DOF) and nonlinear materials properties that require innovations in control systems. With the rapid development of materials science, robotics, and artificial intelligence, the diversification of actuator mechanisms and algorithms has enabled a wide range of unique control strategies. This review summarizes the basics of actuator mechanisms and control strategies, including open-loop control, closed-loop control, and autonomous control, and discusses their implementation from diversified perspectives. Control strategies are evaluated based on their compatibility with materials sets, application goals, and implementation route. The emerging directions are forecasted from the perspectives of interfacing between controller and actuator, underactuated control strategies, and implementation of artificial intelligence (AI).},
	language = {en},
	number = {5},
	urldate = {2022-12-07},
	journal = {Advanced Intelligent Systems},
	author = {Wang, Jue and Chortos, Alex},
	year = {2022},
	note = {15 citations (Semantic Scholar/DOI) [2023-04-11]
4 citations (Crossref) [2022-12-07]
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/aisy.202100165},
	keywords = {/unread, control strategies, soft actuators, soft robots, underactuated system},
	pages = {2100165},
}

@article{zhang2021Computer,
	title = {Computer vision-based tree trunk and branch identification and shaking points detection in {Dense}-{Foliage} canopy for automated harvesting of apples},
	volume = {38},
	copyright = {© 2020 Wiley Periodicals LLC},
	issn = {1556-4967},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21998},
	doi = {10.1002/rob.21998},
	abstract = {Fresh market apples are one of the high-value crops in the United States. Washington alone has produced two-thirds of the annual national production in the past 10 years. However, the availability of seasonal labor is increasingly uncertain. Shake-and-catch automated harvesting solutions have, therefore, become attractive for addressing this challenge. One of the significant challenges in applying this harvesting system is effectively positioning the end-effector at appropriate excitation locations. A computer vision system was used for automatically identifying appropriate locations. Convolutional neural networks (CNNs) were utilized to identify the tree trunks and branches for supporting the automated excitation locations determination. Three CNN architectures were employed: Deeplab v3+ ResNet-18, VGG-16, and VGG-19. Four pixel classes were predefined as branches, trunks, apples, and leaves to segment the canopies trained to simple, narrow, accessible, and productive tree architectures with varying foliage density. Results on Fuji cultivar showed that ResNet-18 outperformed the VGGs in identifying branches and trunks based on all three evaluation measures: per-class accuracy (PcA), intersection over union (IoU), and boundary-F1 score (BFScore). ResNet-18 achieved a PcA of 97\%, IoU of 0.69, and BFScore of 0.89. The ResNet-18 was further evaluated for its robustness with other test canopy images. When applied this method to one of the highest density cultivars of Scifresh, results showed it can achieve IoUs of 0.41 and 0.62 and BFScores of 0.71 and 0.86 for branches and trunks. Such identification result helped to get a 72\% of auto-determined shaking points being the “good” category identified by human experts.},
	language = {en},
	number = {3},
	urldate = {2023-10-13},
	journal = {Journal of Field Robotics},
	author = {Zhang, Xin and Karkee, Manoj and Zhang, Qin and Whiting, Matthew D.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/rob.21998},
	keywords = {/unread, automated detection, convolutional neural networks, deep learning, network generalization, semantic segmentation, shake-and-catch harvesting, trajectory estimation},
	pages = {476--493},
}

@article{ji2022Concurrent,
	title = {Concurrent {Training} of a {Control} {Policy} and a {State} {Estimator} for {Dynamic} and {Robust} {Legged} {Locomotion}},
	volume = {7},
	issn = {2377-3766},
	doi = {10.1109/LRA.2022.3151396},
	abstract = {In this letter, we propose a locomotion training framework where a control policy and a state estimator are trained concurrently. The framework consists of a policy network which outputs the desired joint positions and a state estimation network which outputs estimates of the robot’s states such as the base linear velocity, foot height, and contact probability. We exploit a fast simulation environment to train the networks and the trained networks are transferred to the real robot. The trained policy and state estimator are capable of traversing diverse terrains such as a hill, slippery plate, and bumpy road. We also demonstrate that the learned policy can run at up to 3.75 m/s on normal flat ground and 3.54 m/s on a slippery plate with the coefficient of friction of 0.22.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Ji, Gwanghyeon and Mun, Juhyeok and Kim, Hyeongjun and Hwangbo, Jemin},
	month = apr,
	year = {2022},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {/unread, History, Legged locomotion, Legged robots, Neural networks, Quadrupedal robots, Robots, Sensors, Training, reinforcement learning},
	pages = {4630--4637},
}

@phdthesis{thorapallimuralidharan2020Continuum,
	address = {Stockholm, Sweden},
	title = {Continuum {Actuator} {Based} {Soft} {Quadruped} {Robot}},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-286348},
	abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
	language = {eng},
	urldate = {2022-10-14},
	school = {KTH Royal Institute of Technology},
	author = {Thorapalli Muralidharan, Seshagopalan and Zhu, Ruihao},
	year = {2020},
	keywords = {/unread, Soft robot},
}

@phdthesis{jansson2021ClosedLoop,
	address = {Stockholm, Sweden},
	title = {Closed-{Loop} {Control} of a {3D} {Printed} {Soft} {Actuator} with {Soft} {Position} {Sensors}},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-304748},
	abstract = {This thesis performs closed-loop control of a 3D printed soft bending actuator with feedback from a 3D printed strain sensor. This process utilizes the Finite Element Method (FEM) to design a bello ...},
	language = {eng},
	urldate = {2022-12-12},
	school = {KTH Royal Institute of Technology},
	author = {Jansson, Jakob and Sjöberg, Mikael},
	year = {2021},
	keywords = {Closed loop control, Soft actuators},
}

@book{slotine1991Applied,
	address = {Englewood Cliffs, N.J},
	title = {Applied nonlinear control},
	isbn = {978-0-13-040890-7},
	language = {en},
	publisher = {Prentice Hall},
	author = {Slotine, J.-J. E. and Li, Weiping},
	year = {1991},
	keywords = {/unread, Nonlinear control theory},
}

@phdthesis{lagrelius2022Comparing,
	title = {Comparing {Four} {Modelling} {Methods} for the {Simulation} of a {Soft} {Quadruped} {Robot}},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-321098},
	abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
	language = {eng},
	urldate = {2022-11-16},
	school = {KTH Royal Institute of Technology},
	author = {Lagrelius, Karin},
	year = {2022},
	keywords = {Soft robot},
}

@inproceedings{duan2016Benchmarking,
	title = {Benchmarking {Deep} {Reinforcement} {Learning} for {Continuous} {Control}},
	url = {https://proceedings.mlr.press/v48/duan16.html},
	abstract = {Recently, researchers have made significant progress combining the advances in deep learning for learning feature representations with reinforcement learning. Some notable examples include training agents to play Atari games based on raw pixel data and to acquire advanced manipulation skills using raw sensory inputs. However, it has been difficult to quantify progress in the domain of continuous control due to the lack of a commonly adopted benchmark. In this work, we present a benchmark suite of continuous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, tasks with partial observations, and tasks with hierarchical structure. We report novel findings based on the systematic evaluation of a range of implemented reinforcement learning algorithms. Both the benchmark and reference implementations are released at https://github.com/rllab/rllab in order to facilitate experimental reproducibility and to encourage adoption by other researchers.},
	language = {en},
	urldate = {2023-07-11},
	booktitle = {Proceedings of {The} 33rd {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
	month = jun,
	year = {2016},
	note = {ISSN: 1938-7228},
	keywords = {/unread},
	pages = {1329--1338},
}

@article{sun2022Balance,
	title = {Balance {Control} of a {Quadruped} {Robot} {Based} on {Foot} {Fall} {Adjustment}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/12/5/2521},
	doi = {10.3390/app12052521},
	abstract = {To balance the diagonal gait of a quadruped robot, a dynamic balance control method is presented to improve the stability of the quadruped robot by adjusting its foot position. We set up a trunk-based coordinate system and a hip-based local coordinate system for the quadruped robot, established the kinematics equation of the robot, and designed a reasonable initial diagonal gait through the spring inverted pendulum model. The current trunk posture of the quadruped robot is obtained by collecting the data of its pitch and roll angle, and the foot position is predicted according to the current posture and initial gait of the quadruped robot. To reduce the impact of one leg landing on the ground and increase the stability of the quadruped robot, we adjust the landing point of the robot according to the landing time difference between the diagonal legs. The proposed method can adjust the body in such scenarios as planar walking and lateral impact resistance. It can reduce the disturbance during the robot motion and make the robot move smoothly. The validity of this method is verified by simulation experiments.},
	language = {en},
	number = {5},
	urldate = {2023-05-16},
	journal = {Applied Sciences},
	author = {Sun, Wenkai and Tian, Xiaojie and Song, Yong and Pang, Bao and Yuan, Xianfeng and Xu, Qingyang},
	month = jan,
	year = {2022},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {/unread, attitude feedback, diagonal gait, dynamic balance control, landing time difference, quadruped robot},
	pages = {2521},
}

@article{lutter2023Combining,
	title = {Combining physics and deep learning to learn continuous-time dynamics models},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/02783649231169492},
	doi = {10.1177/02783649231169492},
	abstract = {Deep learning has been widely used within learning algorithms for robotics. One disadvantage of deep networks is that these networks are black-box representations. Therefore, the learned approximations ignore the existing knowledge of physics or robotics. Especially for learning dynamics models, these black-box models are not desirable as the underlying principles are well understood and the standard deep networks can learn dynamics that violate these principles. To learn dynamics models with deep networks that guarantee physically plausible dynamics, we introduce physics-inspired deep networks that combine first principles from physics with deep learning. We incorporate Lagrangian mechanics within the model learning such that all approximated models adhere to the laws of physics and conserve energy. Deep Lagrangian Networks (DeLaN) parametrize the system energy using two networks. The parameters are obtained by minimizing the squared residual of the Euler?Lagrange differential equation. Therefore, the resulting model does not require specific knowledge of the individual system, is interpretable, and can be used as a forward, inverse, and energy model. Previously these properties were only obtained when using system identification techniques that require knowledge of the kinematic structure. We apply DeLaN to learning dynamics models and apply these models to control simulated and physical rigid body systems. The results show that the proposed approach obtains dynamics models that can be applied to physical systems for real-time control. Compared to standard deep networks, the physics-inspired models learn better models and capture the underlying structure of the dynamics.},
	language = {en},
	urldate = {2023-05-03},
	journal = {The International Journal of Robotics Research},
	author = {Lutter, Michael and Peters, Jan},
	month = apr,
	year = {2023},
	note = {Publisher: SAGE Publications Ltd STM},
	keywords = {/unread},
	pages = {02783649231169492},
}

@misc{wang2019Benchmarking,
	title = {Benchmarking {Model}-{Based} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1907.02057},
	doi = {10.48550/arXiv.1907.02057},
	abstract = {Model-based reinforcement learning (MBRL) is widely seen as having the potential to be significantly more sample efficient than model-free RL. However, research in model-based RL has not been very standardized. It is fairly common for authors to experiment with self-designed environments, and there are several separate lines of research, which are sometimes closed-sourced or not reproducible. Accordingly, it is an open question how these various existing MBRL algorithms perform relative to each other. To facilitate research in MBRL, in this paper we gather a wide collection of MBRL algorithms and propose over 18 benchmarking environments specially designed for MBRL. We benchmark these algorithms with unified problem settings, including noisy environments. Beyond cataloguing performance, we explore and unify the underlying algorithmic differences across MBRL algorithms. We characterize three key research challenges for future MBRL research: the dynamics bottleneck, the planning horizon dilemma, and the early-termination dilemma. Finally, to maximally facilitate future research on MBRL, we open-source our benchmark in http://www.cs.toronto.edu/{\textasciitilde}tingwuwang/mbrl.html.},
	urldate = {2023-02-28},
	publisher = {arXiv},
	author = {Wang, Tingwu and Bao, Xuchan and Clavera, Ignasi and Hoang, Jerrick and Wen, Yeming and Langlois, Eric and Zhang, Shunshi and Zhang, Guodong and Abbeel, Pieter and Ba, Jimmy},
	month = jul,
	year = {2019},
	note = {234 citations (Semantic Scholar/arXiv) [2023-04-11]
arXiv:1907.02057 [cs, stat]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
}

@article{annaswamy2023Adaptive,
	title = {Adaptive {Control} and {Intersections} with {Reinforcement} {Learning}},
	volume = {6},
	url = {https://doi.org/10.1146/annurev-control-062922-090153},
	doi = {10.1146/annurev-control-062922-090153},
	abstract = {This article provides an exposition of the field of adaptive control and its intersections with reinforcement learning. Adaptive control and reinforcement learning are two different methods that are both commonly employed for the control of uncertain systems. Historically, adaptive control has excelled at real-time control of systems with specific model structures through adaptive rules that learn the underlying parameters while providing strict guarantees on stability, asymptotic performance, and learning. Reinforcement learning methods are applicable to a broad class of systems and are able to produce near-optimal policies for highly complex control tasks. This is often enabled by significant offline training via simulation or the collection of large input-state datasets. This article attempts to compare adaptive control and reinforcement learning using a common framework. The problem statement in each field and highlights of their results are outlined. Two specific examples of dynamic systems are used to illustrate the details of the two methods, their advantages, and their deficiencies. The need for real-time control methods that leverage tools from both approaches is motivated through the lens of this common framework. Expected final online publication date for the Annual Review of Control, Robotics, and Autonomous Systems, Volume 14 is May 2023. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.},
	number = {1},
	urldate = {2023-03-09},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Annaswamy, Anuradha M.},
	year = {2023},
	note = {2 citations (Semantic Scholar/DOI) [2023-04-11]
\_eprint: https://doi.org/10.1146/annurev-control-062922-090153},
	keywords = {/unread, Review},
	pages = {null},
}

@inproceedings{liu2020Improved,
	title = {An {Improved} {Analysis} of {Stochastic} {Gradient} {Descent} with {Momentum}},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/d3f5d4de09ea19461dab00590df91e4f-Abstract.html},
	abstract = {SGD with momentum (SGDM) has been widely applied in many machine learning tasks, and it is often applied with dynamic stepsizes and momentum weights tuned in a stagewise manner. Despite of its empirical advantage over SGD, the role of momentum is still unclear in general since previous analyses on SGDM either provide worse convergence bounds than those of SGD, or assume Lipschitz or quadratic objectives, which fail to hold in practice. Furthermore, the role of dynamic parameters has not been addressed. In this work, we show that SGDM converges as fast as SGD for smooth objectives under both strongly convex and nonconvex settings. We also prove that multistage strategy is beneficial for SGDM compared to using fixed parameters. Finally, we verify these theoretical claims by numerical experiments.},
	urldate = {2023-10-13},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Liu, Yanli and Gao, Yuan and Yin, Wotao},
	year = {2020},
	keywords = {/unread},
	pages = {18261--18271},
}

@inproceedings{hutter2016ANYmal,
	title = {{ANYmal} - a highly mobile and dynamic quadrupedal robot},
	doi = {10.1109/IROS.2016.7758092},
	abstract = {This paper introduces ANYmal, a quadrupedal robot that features outstanding mobility and dynamic motion capability. Thanks to novel, compliant joint modules with integrated electronics, the 30 kg, 0.5 m tall robotic dog is torque controllable and very robust against impulsive loads during running or jumping. The presented machine was designed with a focus on outdoor suitability, simple maintenance, and user-friendly handling to enable future operation in real world scenarios. Performance tests with the joint actuators indicated a torque control bandwidth of more than 70 Hz, high disturbance rejection capability, as well as impact robustness when moving with maximal velocity. It is demonstrated in a series of experiments that ANYmal can execute walking gaits, dynamically trot at moderate speed, and is able to perform special maneuvers to stand up or crawl very steep stairs. Detailed measurements unveil that even full-speed running requires less than 280 W, resulting in an autonomy of more than 2 h.},
	booktitle = {2016 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Hutter, Marco and Gehring, Christian and Jud, Dominic and Lauber, Andreas and Bellicoso, C. Dario and Tsounis, Vassilios and Hwangbo, Jemin and Bodie, Karen and Fankhauser, Peter and Bloesch, Michael and Diethelm, Remo and Bachmann, Samuel and Melzer, Amir and Hoepflinger, Mark},
	month = oct,
	year = {2016},
	note = {ISSN: 2153-0866},
	keywords = {/unread, Actuators, Dynamics, Legged locomotion, Robot sensing systems, Torque},
	pages = {38--44},
}

@article{zhong2019Analysis,
	title = {Analysis and research of quadruped robot’s legs: {A} comprehensive review},
	volume = {16},
	issn = {1729-8806},
	shorttitle = {Analysis and research of quadruped robot’s legs},
	url = {https://doi.org/10.1177/1729881419844148},
	doi = {10.1177/1729881419844148},
	abstract = {As an important basic component of quadruped robots, mechanical legs provide the robots with excellent maneuverability and versatility, which determine the core application performance such as job adaptability, walking speed, and load capacity. A large number of robotics institutes for the last few decades have studied mechanical legs used by quadruped robots and published many research results. In this article, we collect these research results and classify them into three categories (prismatic legs, articulated legs, and redundant articulated legs) according to the degrees of freedom and then introduce and analyze them. On this basis, we summarize and study the design methods of the actuators and mechanical leg structures. Finally, we make some suggestions for the development of quadruped robot?s legs in the future. The motivation of this review is to summarize and analyze previous research efforts and provide useful guidance for future robotic designers to develop more efficient mechanical legs of quadruped robots.},
	language = {en},
	number = {3},
	urldate = {2023-02-27},
	journal = {International Journal of Advanced Robotic Systems},
	author = {Zhong, Yuhai and Wang, Runxiao and Feng, Huashan and Chen, Yasheng},
	month = may,
	year = {2019},
	note = {27 citations (Semantic Scholar/DOI) [2023-04-11]
Publisher: SAGE Publications},
	keywords = {/unread},
	pages = {1729881419844148},
}

@article{_knowledge_2021,
	title = {Knowledge {Graph} {Construction} {Method} via {Internet}-based {Collective} {Intelligence}},
	volume = {33},
	issn = {1000-9825},
	url = {http://www.jos.org.cn/josen/article/abstract/6313},
	doi = {10.13328/j.cnki.jos.006313},
	abstract = {Knowledge graph is a graph-based structural representation of knowledge. One of the key problems about knowledge graph in both research and practice is how to construct large-scale high-quality knowledge graphs. This paper presents an approach to construct knowledge graphs based on Internet-based human collective intelligence. The core of this approach is a continuously executing loop, called the EIF loop or EIFL, consisting of three activities: free exploration, automatic integration, and proactive feedback. In free exploration activity, each participant tries to construct an individual knowledge graph alone. In automatic integration activity, all participants’ current individual knowledge graphs are integrated in real-time into a collective knowledge graph. In proactive feedback activity, each participant is provided with personalized feedback information from the current collective knowledge graph, in order to improve the participant’s efficiency of constructing an individual knowledge graph. In particular, a hierarchical knowledge graph representation mechanism is proposed, a knowledge graph merging algorithm is designed driven by the goal of minimizing the collective knowledge graph’s general entropy, and two ways for context-dependent and context-independent information feedback are introduced, repectively. In order to investigate the feasibility of the proposed approach, three kinds of experiment are designed and carried out: (1) the merging experiment on simulated graphs with structural information only; (2) the merging experiment on real large-scaled knowledge graphs; (3) the construction experiment of knowledge graphs with different number of participants. The experimental results show that: (1) the proposed knowledge graph merging algorithm can find high-quality merging solutions of knowledge graphs by utilizing both structural information of knowledge graphs and semantic information of elements in knowledge graphs; (2) EIFL-based collective collaboration improves both the efficiency of participants in constructing individual knowledge graphs and the scale of the collective knowledge graph merged from individual knowledge graphs, and shows sound scalability with respect to the number of participants in knowledge graph construction.},
	language = {en},
	number = {7},
	urldate = {2024-04-08},
	journal = {Journal of Software},
	author = {蒋逸，张伟，王佩，张馨月，梅宏 and JIANG Yi, ZHANG Wei},
	month = aug,
	year = {2021},
	pages = {2646--2666},
}

@article{liang2022Symbiotic,
	title = {Symbiotic {Communications}: {Where} {Marconi} {Meets} {Darwin}},
	volume = {29},
	issn = {1558-0687},
	shorttitle = {Symbiotic {Communications}},
	url = {https://ieeexplore.ieee.org/abstract/document/9749195},
	doi = {10.1109/MWC.101.2100132},
	abstract = {With the proliferation of wireless applications, the electromagnetic (EM) space is becoming more and more crowded and complex. This makes it a challenging task to accommodate the growing number of radio systems with limited radio resources. In this article, by considering the EM space as a radio ecosystem, and leveraging the analogy to the natural ecosystem in biology, a novel symbiotic communication (SC) paradigm is proposed through which the relevant radio systems, called symbiotic radios (SRs), in a radio ecosystem form a symbiotic relationship (e.g., mutualistic symbiosis) through intelligent resource/service exchange. Radio resources include, for example, spectrum, energy, and infrastructure, while typical radio services are communicating, relaying, and computing. The symbiotic relationship can be realized via either symbiotic coevolution or symbiotic synthesis. In symbiotic coevolution, each SR is empowered with an evolutionary cycle alongside the multi-agent learning, while in symbiotic synthesis, the SRs ingeniously optimize their operating parameters and transmission protocols by solving a multi-objective optimization problem. Promisingly, the proposed SC paradigm breaks the boundary of radio systems, thus providing us with a fresh perspective on radio resource management and new guidelines to design future wireless communication systems.},
	number = {1},
	urldate = {2024-03-14},
	journal = {IEEE Wireless Communications},
	author = {Liang, Ying-Chang and Long, Ruizhe and Zhang, Qianqian and Niyato, Dusit},
	month = feb,
	year = {2022},
	note = {Conference Name: IEEE Wireless Communications},
	keywords = {/unread, Biology, Ecosystems, Electromagnetics, Protocols, Resource management, Symbiosis, Task analysis},
	pages = {144--150},
}

@inproceedings{ma2018SparsetoDense,
	title = {Sparse-to-{Dense}: {Depth} {Prediction} from {Sparse} {Depth} {Samples} and a {Single} {Image}},
	shorttitle = {Sparse-to-{Dense}},
	url = {https://ieeexplore.ieee.org/abstract/document/8460184},
	doi = {10.1109/ICRA.2018.8460184},
	abstract = {We consider the problem of dense depth prediction from a sparse set of depth measurements and a single RGB image. Since depth estimation from monocular images alone is inherently ambiguous and unreliable, to attain a higher level of robustness and accuracy, we introduce additional sparse depth samples, which are either acquired with a low-resolution depth sensor or computed via visual Simultaneous Localization and Mapping (SLAM) algorithms. We propose the use of a single deep regression network to learn directly from the RGB-D raw data, and explore the impact of number of depth samples on prediction accuracy. Our experiments show that, compared to using only RGB images, the addition of 100 spatially random depth samples reduces the prediction root-mean-square error by 50\% on the NYU-Depth-v2 indoor dataset. It also boosts the percentage of reliable prediction from 59 \% to 92 \% on the KITTI dataset. We demonstrate two applications of the proposed algorithm: a plug-in module in SLAM to convert sparse maps to dense maps, and super-resolution for LiDARs. Software22https://github.com/fangchangma/sparse-to-dense and video demonstration33https://www.youtube.com/watch?v=vNIIT\_M7×7Y are publicly available.},
	urldate = {2024-04-02},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Ma, Fangchang and Karaman, Sertac},
	month = may,
	year = {2018},
	note = {ISSN: 2577-087X},
	keywords = {Estimation, Image reconstruction, Laser radar, Prediction algorithms, Simultaneous localization and mapping, Training},
	pages = {4796--4803},
}

@article{chang2020Spatial,
	title = {Spatial {Attention} {Fusion} for {Obstacle} {Detection} {Using} {MmWave} {Radar} and {Vision} {Sensor}},
	volume = {20},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/4/956},
	doi = {10.3390/s20040956},
	abstract = {For autonomous driving, it is important to detect obstacles in all scales accurately for safety consideration. In this paper, we propose a new spatial attention fusion (SAF) method for obstacle detection using mmWave radar and vision sensor, where the sparsity of radar points are considered in the proposed SAF. The proposed fusion method can be embedded in the feature-extraction stage, which leverages the features of mmWave radar and vision sensor effectively. Based on the SAF, an attention weight matrix is generated to fuse the vision features, which is different from the concatenation fusion and element-wise add fusion. Moreover, the proposed SAF can be trained by an end-to-end manner incorporated with the recent deep learning object detection framework. In addition, we build a generation model, which converts radar points to radar images for neural network training. Numerical results suggest that the newly developed fusion method achieves superior performance in public benchmarking. In addition, the source code will be released in the GitHub.},
	language = {en},
	number = {4},
	urldate = {2024-04-02},
	journal = {Sensors},
	author = {Chang, Shuo and Zhang, Yifan and Zhang, Fan and Zhao, Xiaotong and Huang, Sai and Feng, Zhiyong and Wei, Zhiqing},
	month = jan,
	year = {2020},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {autonomous driving, mmWave radar, obstacle detection, spatial attention fusion, vision},
	pages = {956},
}

@misc{chen2022Cooperative,
	title = {Cooperative {Task} and {Motion} {Planning} for {Multi}-{Arm} {Assembly} {Systems}},
	url = {http://arxiv.org/abs/2203.02475},
	doi = {10.48550/arXiv.2203.02475},
	abstract = {Multi-robot assembly systems are becoming increasingly appealing in manufacturing due to their ability to automatically, flexibly, and quickly construct desired structural designs. However, effectively planning for these systems in a manner that ensures each robot is simultaneously productive, and not idle, is challenging due to (1) the close proximity that the robots must operate in to manipulate the structure and (2) the inherent structural partial orderings on when each part can be installed. In this paper, we present a task and motion planning framework that jointly plans safe, low-makespan plans for a team of robots to assemble complex spatial structures. Our framework takes a hierarchical approach that, at the high level, uses Mixed-integer Linear Programs to compute an abstract plan comprised of an allocation of robots to tasks subject to precedence constraints and, at the low level, builds on a state-of-the-art algorithm for Multi-Agent Path Finding to plan collision-free robot motions that realize this abstract plan. Critical to our approach is the inclusion of certain collision constraints and movement durations during high-level planning, which better informs the search for abstract plans that are likely to be both feasible and low-makespan while keeping the search tractable. We demonstrate our planning system on several challenging assembly domains with several (sometimes heterogeneous) robots with grippers or suction plates for assembling structures with up to 23 objects involving Lego bricks, bars, plates, or irregularly shaped blocks.},
	urldate = {2024-04-03},
	publisher = {arXiv},
	author = {Chen, Jingkai and Li, Jiaoyang and Huang, Yijiang and Garrett, Caelan and Sun, Dawei and Fan, Chuchu and Hofmann, Andreas and Mueller, Caitlin and Koenig, Sven and Williams, Brian C.},
	month = mar,
	year = {2022},
	note = {arXiv:2203.02475 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@article{yin2021Modeling,
	title = {Modeling, learning, perception, and control methods for deformable object manipulation},
	volume = {6},
	url = {https://www.science.org/doi/full/10.1126/scirobotics.abd8803},
	doi = {10.1126/scirobotics.abd8803},
	abstract = {Perceiving and handling deformable objects is an integral part of everyday life for humans. Automating tasks such as food handling, garment sorting, or assistive dressing requires open problems of modeling, perceiving, planning, and control to be solved. Recent advances in data-driven approaches, together with classical control and planning, can provide viable solutions to these open challenges. In addition, with the development of better simulation environments, we can generate and study scenarios that allow for benchmarking of various approaches and gain better understanding of what theoretical developments need to be made and how practical systems can be implemented and evaluated to provide flexible, scalable, and robust solutions. To this end, we survey more than 100 relevant studies in this area and use it as the basis to discuss open problems. We adopt a learning perspective to unify the discussion over analytical and data-driven approaches, addressing how to use and integrate model priors and task data in perceiving and manipulating a variety of deformable objects.},
	number = {54},
	urldate = {2024-03-28},
	journal = {Science Robotics},
	author = {Yin, Hang and Varava, Anastasia and Kragic, Danica},
	month = may,
	year = {2021},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eabd8803},
}

@article{tsurumine2019Deep,
	title = {Deep reinforcement learning with smooth policy update: {Application} to robotic cloth manipulation},
	volume = {112},
	issn = {0921-8890},
	shorttitle = {Deep reinforcement learning with smooth policy update},
	url = {https://www.sciencedirect.com/science/article/pii/S0921889018303245},
	doi = {10.1016/j.robot.2018.11.004},
	abstract = {Deep Reinforcement Learning (DRL), which can learn complex policies with high-dimensional observations as inputs, e.g., images, has been successfully applied to various tasks. Therefore, it may be suitable to apply them for robots to learn and perform daily activities like washing and folding clothes, cooking, and cleaning since such tasks are difficult for non-DRL methods that often require either (1) direct access to state variables or (2) well-designed hand-engineered features extracted from sensory inputs. However, applying DRL to real robots remains very challenging because conventional DRL algorithms require a huge number of training samples for learning, which is arduous in real robots. To alleviate this dilemma, in this paper, we propose two sample efficient DRL algorithms: Deep P-Network (DPN) and Dueling Deep P-Network (DDPN). The core idea is to combine the nature of smooth policy update with the capability of automatic feature extraction in deep neural networks to enhance the sample efficiency and learning stability with fewer samples. The proposed methods were first investigated by a robot-arm reaching task in the simulation that compared previous DRL methods and applied to two real robotic cloth manipulation tasks: (1) flipping a handkerchief and (2) folding a t-shirt with a limited number of samples. All the results suggest that our method outperformed the previous DRL methods.},
	urldate = {2024-03-28},
	journal = {Robotics and Autonomous Systems},
	author = {Tsurumine, Yoshihisa and Cui, Yunduan and Uchibe, Eiji and Matsubara, Takamitsu},
	month = feb,
	year = {2019},
	keywords = {Deep reinforcement learning, Dynamic policy programming, Robotic cloth manipulation},
	pages = {72--83},
}

@article{foerster2018Counterfactual,
	title = {Counterfactual {Multi}-{Agent} {Policy} {Gradients}},
	volume = {32},
	copyright = {Copyright (c)},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/11794},
	doi = {10.1609/aaai.v32i1.11794},
	abstract = {Many real-world problems, such as network packet routing and the coordination of autonomous vehicles, are naturally modelled as cooperative multi-agent systems. There is a great need for new reinforcement learning methods that can efficiently learn decentralised policies for such systems. To this end, we propose a new multi-agent actor-critic method called counterfactual multi-agent (COMA) policy gradients. COMA uses a centralised critic to estimate the Q-function and decentralised actors to optimise the agents' policies. In addition, to address the challenges of multi-agent credit assignment, it uses a counterfactual baseline that marginalises out a single agent's action, while keeping the other agents' actions fixed. COMA also uses a critic representation that allows the counterfactual baseline to be computed efficiently in a single forward pass. We evaluate COMA in the testbed of StarCraft unit micromanagement, using a decentralised variant with significant partial observability. COMA significantly improves average performance over other multi-agent actor-critic methods in this setting, and the best performing agents are competitive with state-of-the-art centralised controllers that get access to the full state.},
	language = {en},
	number = {1},
	urldate = {2024-03-15},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
	month = apr,
	year = {2018},
	note = {Number: 1},
	keywords = {/unread, actor­critic},
}

@misc{korber2021Comparing,
	title = {Comparing {Popular} {Simulation} {Environments} in the {Scope} of {Robotics} and {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/2103.04616},
	abstract = {This letter compares the performance of four different, popular simulation environments for robotics and reinforcement learning (RL) through a series of benchmarks. The benchmarked scenarios are designed carefully with current industrial applications in mind. Given the need to run simulations as fast as possible to reduce the real-world training time of the RL agents, the comparison includes not only different simulation environments but also different hardware configurations, ranging from an entry-level notebook up to a dual CPU high performance server. We show that the chosen simulation environments benefit the most from single core performance. Yet, using a multi core system, multiple simulations could be run in parallel to increase the performance.},
	urldate = {2024-03-20},
	publisher = {arXiv},
	author = {Körber, Marian and Lange, Johann and Rediske, Stephan and Steinmann, Simon and Glück, Roland},
	month = mar,
	year = {2021},
	note = {arXiv:2103.04616 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics},
}

@misc{korber2021Comparinga,
	title = {Comparing {Popular} {Simulation} {Environments} in the {Scope} of {Robotics} and {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/2103.04616},
	doi = {10.48550/arXiv.2103.04616},
	abstract = {This letter compares the performance of four different, popular simulation environments for robotics and reinforcement learning (RL) through a series of benchmarks. The benchmarked scenarios are designed carefully with current industrial applications in mind. Given the need to run simulations as fast as possible to reduce the real-world training time of the RL agents, the comparison includes not only different simulation environments but also different hardware configurations, ranging from an entry-level notebook up to a dual CPU high performance server. We show that the chosen simulation environments benefit the most from single core performance. Yet, using a multi core system, multiple simulations could be run in parallel to increase the performance.},
	urldate = {2024-03-27},
	publisher = {arXiv},
	author = {Körber, Marian and Lange, Johann and Rediske, Stephan and Steinmann, Simon and Glück, Roland},
	month = mar,
	year = {2021},
	note = {arXiv:2103.04616 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics},
}

@article{zhou2024Reactive,
	title = {Reactive human–robot collaborative manipulation of deformable linear objects using a new topological latent control model},
	volume = {88},
	issn = {0736-5845},
	url = {https://www.sciencedirect.com/science/article/pii/S0736584524000139},
	doi = {10.1016/j.rcim.2024.102727},
	abstract = {Real-time reactive manipulation of deformable linear objects is a challenging task that requires robots to quickly and adaptively respond to changes in the object’s deformed shape that result from external forces. In this paper, a novel approach is proposed for real-time reactive deformable linear object manipulation in the context of human–robot collaboration. The proposed approach combines a topological latent representation and a fixed-time sliding mode controller to enable seamless interaction between humans and robots. The introduced topological control model offers a framework for controlling the dynamic shape of deformable objects. By leveraging the topological representation, our approach captures the connectivity and structure of the objects’ shapes within a latent space. This enables improved generalization and performance when handling complex deformable shapes. A fixed-time sliding mode controller ensures that the object is manipulated in real-time, while also ensuring that it remains accurate and stable during the manipulation process. To validate our proposed framework, we first conduct motor-robot experiments to simulate fixed human interaction processes, enabling straightforward comparisons with other approaches. We then follow up with human–robot experiments to demonstrate the effectiveness of our approach.},
	urldate = {2024-03-20},
	journal = {Robotics and Computer-Integrated Manufacturing},
	author = {Zhou, Peng and Zheng, Pai and Qi, Jiaming and Li, Chengxi and Lee, Hoi-Yin and Duan, Anqing and Lu, Liang and Li, Zhongxuan and Hu, Luyin and Navarro-Alarcon, David},
	month = aug,
	year = {2024},
	keywords = {Deformable linear objects, Human–robot collaboration, Latent control model, Reactive manipulation},
	pages = {102727},
}

@misc{ding2022SafetyCritical,
	title = {Safety-{Critical} {Optimal} {Control} for {Robotic} {Manipulators} in {A} {Cluttered} {Environment}},
	url = {http://arxiv.org/abs/2211.04944},
	doi = {10.48550/arXiv.2211.04944},
	abstract = {Designing safety-critical control for robotic manipulators is challenging, especially in a cluttered environment. First, the actual trajectory of a manipulator might deviate from the planned one due to the complex collision environments and non-trivial dynamics, leading to collision; Second, the feasible space for the manipulator is hard to obtain since the explicit distance functions between collision meshes are unknown. By analyzing the relationship between the safe set and the controlled invariant set, this paper proposes a data-driven control barrier function (CBF) construction method, which extracts CBF from distance samples. Specifically, the CBF guarantees the controlled invariant property for considering the system dynamics. The data-driven method samples the distance function and determines the safe set. Then, the CBF is synthesized based on the safe set by a scenario-based sum of square (SOS) program. Unlike most existing linearization based approaches, our method reserves the volume of the feasible space for planning without approximation, which helps find a solution in a cluttered environment. The control law is obtained by solving a CBF-based quadratic program in real time, which works as a safe filter for the desired planning-based controller. Moreover, our method guarantees safety with the proven probabilistic result. Our method is validated on a 7-DOF manipulator in both real and virtual cluttered environments. The experiments show that the manipulator is able to execute tasks where the clearance between obstacles is in millimeters.},
	urldate = {2023-11-23},
	publisher = {arXiv},
	author = {Ding, Xuda and Wang, Han and Ren, Yi and Zheng, Yu and Chen, Cailian and He, Jianping},
	month = nov,
	year = {2022},
	note = {arXiv:2211.04944 [cs, eess]},
	keywords = {/unread, Computer Science - Robotics, Electrical Engineering and Systems Science - Systems and Control},
}

@phdthesis{yang2021Manyagent,
	type = {Doctoral},
	title = {Many-agent {Reinforcement} {Learning}},
	copyright = {open},
	url = {https://discovery.ucl.ac.uk/id/eprint/10124273/},
	abstract = {Multi-agent reinforcement learning (RL) solves the problem of how each agent should behave optimally in a stochastic environment in which multiple agents are learning simultaneously. It is an interdisciplinary domain with a long history that lies in the joint area of psychology, control theory, game theory, reinforcement learning, and deep learning. Following the remarkable success of the AlphaGO series in single-agent RL, 2019 was a booming year that witnessed significant advances in multi-agent RL techniques; impressive breakthroughs have been made on developing AIs that outperform humans on many challenging tasks, especially multi-player video games. Nonetheless, one of the key challenges of multi-agent RL techniques is the scalability; it is still non-trivial to design efficient learning algorithms that can solve tasks including far more than two agents (\$N {\textbackslash}gg 2\$), which I name by {\textbackslash}emph\{many-agent reinforcement learning\} (MARL{\textbackslash}footnote\{I use the world of ``MARL" to denote multi-agent reinforcement learning with a particular focus on the cases of many agents; otherwise, it is denoted as ``Multi-Agent RL" by default.\}) problems. In this thesis, I contribute to tackling MARL problems from four aspects. Firstly, I offer a self-contained overview of multi-agent RL techniques from a game-theoretical perspective. This overview fills the research gap that most of the existing work either fails to cover the recent advances since 2010 or does not pay adequate attention to game theory, which I believe is the cornerstone to solving many-agent learning problems. Secondly, I develop a tractable policy evaluation algorithm -- \${\textbackslash}alpha{\textasciicircum}{\textbackslash}alpha\$-Rank -- in many-agent systems. The critical advantage of \${\textbackslash}alpha{\textasciicircum}{\textbackslash}alpha\$-Rank is that it can compute the solution concept of \${\textbackslash}alpha\$-Rank tractably in multi-player general-sum games with no need to store the entire pay-off matrix. This is in contrast to classic solution concepts such as Nash equilibrium which is known to be \$PPAD\$-hard in even two-player cases. \${\textbackslash}alpha{\textasciicircum}{\textbackslash}alpha\$-Rank allows us, for the first time, to practically conduct large-scale multi-agent evaluations. Thirdly, I introduce a scalable policy learning algorithm -- mean-field MARL -- in many-agent systems. The mean-field MARL method takes advantage of the mean-field approximation from physics, and it is the first provably convergent algorithm that tries to break the curse of dimensionality for MARL tasks. With the proposed algorithm, I report the first result of solving the Ising model and multi-agent battle games through a MARL approach. Fourthly, I investigate the many-agent learning problem in open-ended meta-games (i.e., the game of a game in the policy space). Specifically, I focus on modelling the behavioural diversity in meta-games, and developing algorithms that guarantee to enlarge diversity during training. The proposed metric based on determinantal point processes serves as the first mathematically rigorous definition for diversity. Importantly, the diversity-aware learning algorithms beat the existing state-of-the-art game solvers in terms of exploitability by a large margin. On top of the algorithmic developments, I also contribute two real-world applications of MARL techniques. Specifically, I demonstrate the great potential of applying MARL to study the emergent population dynamics in nature, and model diverse and realistic interactions in autonomous driving. Both applications embody the prospect that MARL techniques could achieve huge impacts in the real physical world, outside of purely video games.},
	language = {eng},
	urldate = {2024-03-27},
	school = {UCL (University College London)},
	author = {Yang, Yaodong},
	month = mar,
	year = {2021},
	note = {Conference Name: UCL (University College London)
Meeting Name: UCL (University College London)
Publication Title: Doctoral thesis, UCL (University College London).},
}

@misc{liu2024Maximum,
	title = {Maximum {Entropy} {Heterogeneous}-{Agent} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/2306.10715},
	doi = {10.48550/arXiv.2306.10715},
	abstract = {Multi-agent reinforcement learning (MARL) has been shown effective for cooperative games in recent years. However, existing state-of-the-art methods face challenges related to sample complexity, training instability, and the risk of converging to a suboptimal Nash Equilibrium. In this paper, we propose a unified framework for learning {\textbackslash}emph\{stochastic\} policies to resolve these issues. We embed cooperative MARL problems into probabilistic graphical models, from which we derive the maximum entropy (MaxEnt) objective for MARL. Based on the MaxEnt framework, we propose Heterogeneous-Agent Soft Actor-Critic (HASAC) algorithm. Theoretically, we prove the monotonic improvement and convergence to quantal response equilibrium (QRE) properties of HASAC. Furthermore, we generalize a unified template for MaxEnt algorithmic design named Maximum Entropy Heterogeneous-Agent Mirror Learning (MEHAML), which provides any induced method with the same guarantees as HASAC. We evaluate HASAC on six benchmarks: Bi-DexHands, Multi-Agent MuJoCo, StarCraft Multi-Agent Challenge, Google Research Football, Multi-Agent Particle Environment, and Light Aircraft Game. Results show that HASAC consistently outperforms strong baselines, exhibiting better sample efficiency, robustness, and sufficient exploration.},
	urldate = {2024-03-27},
	publisher = {arXiv},
	author = {Liu, Jiarong and Zhong, Yifan and Hu, Siyi and Fu, Haobo and Fu, Qiang and Chang, Xiaojun and Yang, Yaodong},
	month = mar,
	year = {2024},
	note = {arXiv:2306.10715 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@article{nguyen2020Deep,
	title = {Deep {Reinforcement} {Learning} for {Multiagent} {Systems}: {A} {Review} of {Challenges}, {Solutions}, and {Applications}},
	volume = {50},
	issn = {2168-2275},
	shorttitle = {Deep {Reinforcement} {Learning} for {Multiagent} {Systems}},
	url = {https://ieeexplore.ieee.org/abstract/document/9043893/authors#authors},
	doi = {10.1109/TCYB.2020.2977374},
	abstract = {Reinforcement learning (RL) algorithms have been around for decades and employed to solve various sequential decision-making problems. These algorithms, however, have faced great challenges when dealing with high-dimensional environments. The recent development of deep learning has enabled RL methods to drive optimal policies for sophisticated and capable agents, which can perform efficiently in these challenging environments. This article addresses an important aspect of deep RL related to situations that require multiple agents to communicate and cooperate to solve complex tasks. A survey of different approaches to problems related to multiagent deep RL (MADRL) is presented, including nonstationarity, partial observability, continuous state and action spaces, multiagent training schemes, and multiagent transfer learning. The merits and demerits of the reviewed methods will be analyzed and discussed with their corresponding applications explored. It is envisaged that this review provides insights about various MADRL methods and can lead to the future development of more robust and highly useful multiagent learning methods for solving real-world problems.},
	number = {9},
	urldate = {2024-03-20},
	journal = {IEEE Transactions on Cybernetics},
	author = {Nguyen, Thanh Thi and Nguyen, Ngoc Duy and Nahavandi, Saeid},
	month = sep,
	year = {2020},
	note = {Conference Name: IEEE Transactions on Cybernetics},
	keywords = {/unread, Continuous action space, Deep learning, Dynamic programming, Games, Mathematical model, Observability, Reinforcement learning, Robots, deep learning, deep reinforcement learning (RL), multiagent, nonstationary, partial observability, review, robotics, survey},
	pages = {3826--3839},
}

@inproceedings{jiang2018Learning,
	title = {Learning {Attentional} {Communication} for {Multi}-{Agent} {Cooperation}},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper/2018/hash/6a8018b3a00b69c008601b8becae392b-Abstract.html},
	abstract = {Communication could potentially be an effective way for multi-agent cooperation. However, information sharing among all agents or in predefined communication architectures that existing methods adopt can be problematic. When there is a large number of agents, agents cannot differentiate valuable information that helps cooperative decision making from globally shared information. Therefore, communication barely helps, and could even impair the learning of multi-agent cooperation. Predefined communication architectures, on the other hand, restrict communication among agents and thus restrain potential cooperation. To tackle these difficulties, in this paper, we propose an attentional communication model that learns when communication is needed and how to integrate shared information for cooperative decision making. Our model leads to efficient and effective communication for large-scale multi-agent cooperation. Empirically, we show the strength of our model in a variety of cooperative scenarios, where agents are able to develop more coordinated and sophisticated strategies than existing methods.},
	urldate = {2024-03-20},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Jiang, Jiechuan and Lu, Zongqing},
	year = {2018},
	keywords = {/unread},
}

@article{chen2023BiDexHands,
	title = {Bi-{DexHands}: {Towards} {Human}-{Level} {Bimanual} {Dexterous} {Manipulation}},
	issn = {1939-3539},
	shorttitle = {Bi-{DexHands}},
	url = {https://ieeexplore.ieee.org/document/10343126},
	doi = {10.1109/TPAMI.2023.3339515},
	abstract = {Achieving human-level dexterity in robotics remains a critical open problem. Even simple dexterous manipulation tasks pose significant difficulties due to the high number of degrees of freedom and the need for cooperation among heterogeneous agents (e.g., finger joints). While some researchers have utilized reinforcement learning (RL) to control a single hand in manipulating objects, tasks that require coordinated bimanual cooperation are still under-explored due to the fewer suitable environments, which can result in difficulties and sub-optimal performance. To address these challenges, we introduce Bi-DexHands, a simulator with two dexterous hands featuring 20 bimanual manipulation tasks and thousands of target objects, designed to match various levels of human motor skills based on cognitive science research. We developed Bi-DexHands in Issac Gym, enabling highly efficient RL training at over 30,000 frames per second using a single NVIDIA RTX 3090. Based on Bi-DexHands, we present a comprehensive evaluation of popular RL algorithms in different settings, including single-agent/multi-agent RL, offline RL, multi-task RL, and meta RL. Our findings show that on-policy algorithms, such as PPO, can master simple manipulation tasks that correspond to those of 48-month-old babies, such as catching a flying object or opening a bottle. Furthermore, multi-agent RL can improve the ability to perform manipulations that require skilled bimanual cooperation, such as lifting a pot or stacking blocks. Despite achieving success in individual tasks, current RL algorithms struggle to learn multiple manipulation skills in most multi-task and few-shot learning scenarios. This highlights the need for further research and development within the RL community. Our source code, documentation, and demo video are available on GitHub at https://github.com/PKU-MARL/DexterousHands.},
	urldate = {2024-03-20},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Chen, Yuanpei and Geng, Yiran and Zhong, Fangwei and Ji, Jiaming and Jiang, Jiechuang and Lu, Zongqing and Dong, Hao and Yang, Yaodong},
	year = {2023},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Benchmark testing, Dexterous Manipulation, Grasping, Multitasking, Reinforcement Learning, Reinforcement learning, Robot kinematics, Robots, Simulation, Task analysis},
	pages = {1--15},
}

@article{hernandez-leal2019Survey,
	title = {A {Survey} and {Critique} of {Multiagent} {Deep} {Reinforcement} {Learning}},
	volume = {33},
	issn = {1387-2532, 1573-7454},
	url = {http://arxiv.org/abs/1810.05587},
	doi = {10.1007/s10458-019-09421-1},
	abstract = {Deep reinforcement learning (RL) has achieved outstanding results in recent years. This has led to a dramatic increase in the number of applications and methods. Recent works have explored learning beyond single-agent scenarios and have considered multiagent learning (MAL) scenarios. Initial results report successes in complex multiagent domains, although there are several challenges to be addressed. The primary goal of this article is to provide a clear overview of current multiagent deep reinforcement learning (MDRL) literature. Additionally, we complement the overview with a broader analysis: (i) we revisit previous key components, originally presented in MAL and RL, and highlight how they have been adapted to multiagent deep reinforcement learning settings. (ii) We provide general guidelines to new practitioners in the area: describing lessons learned from MDRL works, pointing to recent benchmarks, and outlining open avenues of research. (iii) We take a more critical tone raising practical challenges of MDRL (e.g., implementation and computational demands). We expect this article will help unify and motivate future research to take advantage of the abundant literature that exists (e.g., RL and MAL) in a joint effort to promote fruitful research in the multiagent community.},
	number = {6},
	urldate = {2024-03-20},
	journal = {Autonomous Agents and Multi-Agent Systems},
	author = {Hernandez-Leal, Pablo and Kartal, Bilal and Taylor, Matthew E.},
	month = nov,
	year = {2019},
	note = {arXiv:1810.05587 [cs]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
	pages = {750--797},
}

@article{JMLR:v25:23-0488,
	title = {Heterogeneous-agent reinforcement learning},
	volume = {25},
	url = {http://jmlr.org/papers/v25/23-0488.html},
	number = {32},
	journal = {Journal of Machine Learning Research},
	author = {Zhong, Yifan and Kuba, Jakub Grudzien and Feng, Xidong and Hu, Siyi and Ji, Jiaming and Yang, Yaodong},
	year = {2024},
	keywords = {/unread},
	pages = {1--67},
}

@article{sacco2021Sustainable,
	title = {Sustainable {Task} {Offloading} in {UAV} {Networks} via {Multi}-{Agent} {Reinforcement} {Learning}},
	volume = {70},
	issn = {1939-9359},
	url = {https://ieeexplore.ieee.org/abstract/document/9409695},
	doi = {10.1109/TVT.2021.3074304},
	abstract = {The recent growth of IoT devices, along with edge computing, has revealed many opportunities for novel applications. Among them, Unmanned Aerial Vehicles (UAVs), which are deployed for surveillance and environmental monitoring, are attracting increasing attention. In this context, typical solutions must deal with events that may change the state of the network, providing a service that continuously maintains a high level of performance. In this paper, we address this problem by proposing a distributed architecture that leverages a Multi-Agent Reinforcement Learning (MARL) technique to dynamically offload tasks from UAVs to the edge cloud. Nodes of the system co-operate to jointly minimize the overall latency perceived by the user and the energy usage on UAVs by continuously learning from the environment the best action, which entails the decision of offloading and, in this case, the best transmission technology, i.e., Wi-Fi or cellular. Results validate our distributed architecture and show the effectiveness of the approach in reaching the above targets.},
	number = {5},
	urldate = {2024-02-26},
	journal = {IEEE Transactions on Vehicular Technology},
	author = {Sacco, Alessio and Esposito, Flavio and Marchetto, Guido and Montuschi, Paolo},
	month = may,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Vehicular Technology},
	keywords = {/unread, Approximation algorithms, Cloud computing, Drones, Edge computing, Markov processes, Reinforcement learning, Task analysis, UAV, multi-agent reinforcement learning, task offloading},
	pages = {5003--5015},
}

@incollection{zhang2021MultiAgent,
	address = {Cham},
	series = {Studies in {Systems}, {Decision} and {Control}},
	title = {Multi-{Agent} {Reinforcement} {Learning}: {A} {Selective} {Overview} of {Theories} and {Algorithms}},
	isbn = {978-3-030-60990-0},
	shorttitle = {Multi-{Agent} {Reinforcement} {Learning}},
	url = {https://doi.org/10.1007/978-3-030-60990-0_12},
	abstract = {Recent years have witnessed significant advances in reinforcement learning (RL), which has registered tremendous success in solving various sequential decision-making problems in machine learning. Most of the successful RL applications, e.g., the games of Go and Poker, robotics, and autonomous driving, involve the participation of more than one single agent, which naturally fall into the realm of multi-agent RL (MARL), a domain with a relatively long history, and has recently re-emerged due to advances in single-agent RL techniques. Though empirically successful, theoretical foundations for MARL are relatively lacking in the literature. In this chapter, we provide a selective overview of MARL, with focus on algorithms backed by theoretical analysis. More specifically, we review the theoretical results of MARL algorithms mainly within two representative frameworks, Markov/stochastic games and extensive-form games, in accordance with the types of tasks they address, i.e., fully cooperative, fully competitive, and a mix of the two. We also introduce several significant but challenging applications of these algorithms. Orthogonal to the existing reviews on MARL, we highlight several new angles and taxonomies of MARL theory, including learning in extensive-form games, decentralized MARL with networked agents, MARL in the mean-field regime, (non-)convergence of policy-based methods for learning in games, etc. Some of the new angles extrapolate from our own research endeavors and interests. Our overall goal with this chapter is, beyond providing an assessment of the current state of the field on the mark, to identify fruitful future research directions on theoretical studies of MARL. We expect this chapter to serve as continuing stimulus for researchers interested in working on this exciting while challenging topic.},
	language = {en},
	urldate = {2024-02-23},
	booktitle = {Handbook of {Reinforcement} {Learning} and {Control}},
	publisher = {Springer International Publishing},
	author = {Zhang, Kaiqing and Yang, Zhuoran and Başar, Tamer},
	editor = {Vamvoudakis, Kyriakos G. and Wan, Yan and Lewis, Frank L. and Cansever, Derya},
	year = {2021},
	doi = {10.1007/978-3-030-60990-0_12},
	keywords = {/unread},
	pages = {321--384},
}

@inproceedings{zhang2018Fully,
	title = {Fully {Decentralized} {Multi}-{Agent} {Reinforcement} {Learning} with {Networked} {Agents}},
	url = {https://proceedings.mlr.press/v80/zhang18n.html},
	abstract = {We consider the fully decentralized multi-agent reinforcement learning (MARL) problem, where the agents are connected via a time-varying and possibly sparse communication network. Specifically, we assume that the reward functions of the agents might correspond to different tasks, and are only known to the corresponding agent. Moreover, each agent makes individual decisions based on both the information observed locally and the messages received from its neighbors over the network. To maximize the globally averaged return over the network, we propose two fully decentralized actor-critic algorithms, which are applicable to large-scale MARL problems in an online fashion. Convergence guarantees are provided when the value functions are approximated within the class of linear functions. Our work appears to be the first theoretical study of fully decentralized MARL algorithms for networked agents that use function approximation.},
	language = {en},
	urldate = {2024-02-23},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Zhang, Kaiqing and Yang, Zhuoran and Liu, Han and Zhang, Tong and Basar, Tamer},
	month = jul,
	year = {2018},
	note = {ISSN: 2640-3498},
	keywords = {/unread},
	pages = {5872--5881},
}

@article{eguchi2006Study,
	title = {A study of evolutionary multiagent models based on symbiosis},
	volume = {36},
	issn = {1941-0492},
	url = {https://ieeexplore.ieee.org/abstract/document/1580628},
	doi = {10.1109/TSMCB.2005.856720},
	abstract = {Multiagent Systems with Symbiotic Learning and Evolution (Masbiole) has been proposed and studied, which is a new methodology of Multiagent Systems (MAS) based on symbiosis in the ecosystem. Masbiole employs a method of symbiotic learning and evolution where agents can learn or evolve according to their symbiotic relations toward others, i.e., considering the benefits/losses of both itself and an opponent. As a result, Masbiole can escape from Nash Equilibria and obtain better performances than conventional MAS where agents consider only their own benefits. This paper focuses on the evolutionary model of Masbiole, and its characteristics are examined especially with an emphasis on the behaviors of agents obtained by symbiotic evolution. In the simulations, two ideas suitable for the effective analysis of such behaviors are introduced; "Match Type Tile-world (MTT)" and "Genetic Network Programming (GNP)". MTT is a virtual model where tile-world is improved so that agents can behave considering their symbiotic relations. GNP is a newly developed evolutionary computation which has the directed graph type gene structure and enables to analyze the decision making mechanism of agents easily. Simulation results show that Masbiole can obtain various kinds of behaviors and better performances than conventional MAS in MTT by evolution.},
	number = {1},
	urldate = {2024-01-30},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	author = {Eguchi, T. and Hirasawa, K. and Hu, J. and Ota, N.},
	month = feb,
	year = {2006},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	keywords = {/unread, Analytical models, Centralized control, Computational modeling, Decision making, Economic indicators, Ecosystems, Evolution (biology), Evolutionary computation, Multiagent systems, Symbiosis, multiagent systems, symbiosis, tile-world},
	pages = {179--193},
}

@article{mabu2015Reinforcement,
	title = {Reinforcement {Learning} with {Symbiotic} {Relationships} for {Multiagent} {Environments}.},
	volume = {2},
	url = {https://alife-robotics.co.jp/members2015/icarob/data/papers/GS/GS3-2.pdf},
	number = {1},
	urldate = {2024-01-30},
	journal = {J. Robotics Netw. Artif. Life},
	author = {Mabu, Shingo and Obayashi, Masanao and Kuremoto, Takashi},
	year = {2015},
	keywords = {/unread},
	pages = {40--45},
}

@article{zhao2021MultiUAV,
	title = {Multi-{UAV} {Trajectory} {Planning} for {Energy}-{Efficient} {Content} {Coverage}: {A} {Decentralized} {Learning}-{Based} {Approach}},
	volume = {39},
	issn = {1558-0008},
	shorttitle = {Multi-{UAV} {Trajectory} {Planning} for {Energy}-{Efficient} {Content} {Coverage}},
	url = {https://ieeexplore.ieee.org/abstract/document/9454514},
	doi = {10.1109/JSAC.2021.3088669},
	abstract = {In next-generation wireless networks, high-mobility unmanned aerial vehicles (UAVs) are promising to provide content coverage, where users can receive sufficient requested content within a given time. However, trajectory planning for multiple UAVs to provide content coverage is challenging since 1) UAVs cannot provide content coverage for all users due to the limited energy and caching storage, and 2) the trajectory planning of UAV is coupled with each other. Moreover, the complete information based trajectory planning methods are unusable since UAVs cannot obtain prior information on the rapidly changing environment. In this paper, we investigate the multi-UAV trajectory planning for energy-efficient content coverage. We first formulate an energy efficiency maximization problem considering recharging scheduling, which aims to reduce the total length of trajectories of UAVs under the quality of service (QoS) constraints. To settle environment uncertainty, the trajectory planning problem is modeled as two coupled multi-agent stochastic games, whose equilibrium constitute the optimal trajectory. To obtain the equilibrium, we propose a decentralized reinforcement learning algorithm, which can decouple the two games. We prove that the proposed algorithm can converge to the optimal solution of the Bellman equation with a higher rate compared to the centralized one. Moreover, simulation results show that the energy efficiency of the proposed algorithm is smaller than 5\% compared the optimal, which is obtained with the prior information of environments.},
	number = {10},
	urldate = {2024-02-26},
	journal = {IEEE Journal on Selected Areas in Communications},
	author = {Zhao, Chenxi and Liu, Junyu and Sheng, Min and Teng, Wei and Zheng, Yang and Li, Jiandong},
	month = oct,
	year = {2021},
	note = {Conference Name: IEEE Journal on Selected Areas in Communications},
	keywords = {/unread, Games, Quality of service, Throughput, Trajectory, Trajectory planning, UAV networks, Unmanned aerial vehicles, Wireless networks, content coverage, decentralized learning, energy efficiency, multi-UAV trajectory planning},
	pages = {3193--3207},
}

@inproceedings{ritz2021Sustainable,
	title = {A {Sustainable} {Ecosystem} through {Emergent} {Cooperation} in {Multi}-{Agent} {Reinforcement} {Learning}},
	url = {https://dx.doi.org/10.1162/isal_a_00399},
	doi = {10.1162/isal_a_00399},
	abstract = {Abstract. This paper considers sustainable and cooperative behavior in multi-agent systems. In the proposed predator-prey simulation, multiple selfish predators can learn to act sustainably by maintaining a herd of reproducing prey and further hunt cooperatively for long term benefit. Since the predators face starvation pressure, the scenario can also turn in a tragedy of the commons if selfish individuals decide to greedily hunt down the prey population before their conspecifics do, ultimately leading to extinction of prey and predators. This paper uses Multi-Agent Reinforcement Learning to overcome a collapse of the simulated ecosystem, analyzes the impact factors over multiple dimensions and proposes suitable metrics. We show that up to three predators are able to learn sustainable behavior in form of collective herding under starvation pressure. Complex cooperation in form of group hunting emerges between the predators as their speed is handicapped and the prey is given more degrees of freedom to escape. The implementation of environment and reinforcement learning pipeline is available online.},
	language = {en},
	urldate = {2024-01-30},
	publisher = {MIT Press},
	author = {Ritz, Fabian and Ratke, Daniel and Phan, Thomy and Belzner, Lenz and Linnhoff-Popien, Claudia},
	month = jul,
	year = {2021},
	keywords = {/unread},
}

@article{liang2020Symbiotic,
	title = {Symbiotic {Radio}: {Cognitive} {Backscattering} {Communications} for {Future} {Wireless} {Networks}},
	volume = {6},
	issn = {2332-7731},
	shorttitle = {Symbiotic {Radio}},
	url = {https://ieeexplore.ieee.org/abstract/document/9193946},
	doi = {10.1109/TCCN.2020.3023139},
	abstract = {The heterogenous wireless services and exponentially growing traffic call for novel spectrum- and energy-efficient wireless communication technologies. Recently, a new technique, called symbiotic radio (SR), is proposed to exploit the benefits and address the drawbacks of cognitive radio (CR) and ambient backscattering communications (AmBC), leading to mutualism spectrum sharing and highly reliable backscattering communications. In particular, the secondary transmitter (STx) in SR transmits messages to the secondary receiver (SRx) over the RF signals originating from the primary transmitter (PTx) based on cognitive backscattering communications, thus the secondary system shares not only the radio spectrum, but also the power, and infrastructure with the primary system. In return, the secondary transmission provides beneficial multipath diversity to the primary system, therefore the two systems form mutualism spectrum sharing. More importantly, joint decoding is exploited at SRx to achieve highly reliable backscattering communications. In this article, to exploit the full potential of SR, we provide a systematic view for SR and address three fundamental tasks in SR: (1) enhancing the backscattering link via active load; (2) achieving highly reliable communications through joint decoding; and (3) capturing PTx's RF signals using reconfigurable intelligent surfaces. Emerging applications, design challenges and open research problems will also be discussed.},
	number = {4},
	urldate = {2024-03-14},
	journal = {IEEE Transactions on Cognitive Communications and Networking},
	author = {Liang, Ying-Chang and Zhang, Qianqian and Larsson, Erik G. and Li, Geoffrey Ye},
	month = dec,
	year = {2020},
	note = {Conference Name: IEEE Transactions on Cognitive Communications and Networking},
	keywords = {/unread, Backscatter, RF signals, Radio transmitters, Receivers, Reliability, Symbiosis, Symbiotic radio, Wireless communication, ambient backscattering communications, cognitive radio, energy efficiency, joint decoding, large intelligent antennas, reconfigurable intelligent surfaces, spectrum efficiency, spectrum management},
	pages = {1242--1255},
}

@article{caccavale2000Taskspace,
	title = {Task-space regulation of cooperative manipulators},
	volume = {36},
	issn = {0005-1098},
	url = {https://www.sciencedirect.com/science/article/pii/S0005109899002150},
	doi = {10.1016/S0005-1098(99)00215-0},
	abstract = {In this paper a new task-space regulation scheme for a system of two cooperative manipulators tightly grasping a rigid object is proposed. The control architecture is based on individual task-space regulators for the two manipulators. In order to overcome problems arising from representation singularities, the unit quaternion is used to describe the orientation of relevant frames. To avoid steady-state internal stresses at the held object, kinetostatic filtering of the control action is introduced together with internal force feedback. Also, the performance of the control scheme is analyzed in the presence of a class of modeling uncertainties. The equilibria of the closed-loop system are then explicitly computed and asymptotic stability is proven via Lyapunov-like analysis.},
	number = {6},
	urldate = {2023-11-23},
	journal = {Automatica},
	author = {Caccavale, F. and Chiacchio, P. and Chiaverini, S.},
	month = jun,
	year = {2000},
	keywords = {/unread, Equilibrium, Manipulators, Regulation, Robot control, Stability},
	pages = {879--887},
}

@article{nguyen2021Swarm,
	title = {Swarm intelligence-based green optimization framework for sustainable transportation},
	volume = {71},
	issn = {2210-6707},
	url = {https://www.sciencedirect.com/science/article/pii/S2210670721002328},
	doi = {10.1016/j.scs.2021.102947},
	abstract = {Traffic congestion is one of the most critical issues in developing sustainable transportation in smart cities. As the Internet of Things evolves, connected vehicle technology has arisen as an essential research topic in smart, sustainable transportation. This study investigates a decentralized green traffic optimization framework by pushing swarm intelligence into connected vehicles to mitigate traffic congestion. We present a dynamic traffic routing method based on ant species’ swarm intelligence for connected vehicles so that they can communicate with each other and their surrounding environment via digital pheromones to perform routing decision-making in a decentralized manner. Traditional pheromones attract other vehicles to move to the optimal path, which will soon be congested if many vehicles travel on that path concurrently. To overcome this limitation, we propose the concept of repelling pheromone, which generates a repulsive force among vehicles so that their travel paths are distributed throughout a road network, resulting in a congestion-free road network. The proposed method is validated in the Simulation of Urban Mobility platform. Simulation findings reveal that the proposed method outperforms baseline methods in mitigating traffic congestion, reducing average fuel consumption and emissions by 13–19\% and the average trip duration by 19–28\%.},
	urldate = {2024-02-05},
	journal = {Sustainable Cities and Society},
	author = {Nguyen, Tri-Hai and Jung, Jason J.},
	month = aug,
	year = {2021},
	keywords = {/unread, Congestion mitigation, Connected vehicle, Green optimization, Repelling pheromone, Sustainable transportation, Swarm intelligence},
	pages = {102947},
}

@article{elhoseny2020Swarm,
	title = {Swarm intelligence–based energy efficient clustering with multihop routing protocol for sustainable wireless sensor networks},
	volume = {16},
	issn = {1550-1329},
	url = {https://doi.org/10.1177/1550147720949133},
	doi = {10.1177/1550147720949133},
	abstract = {Wireless sensor network is a hot research topic with massive applications in different domains. Generally, wireless sensor network comprises hundreds to thousands of sensor nodes, which communicate with one another by the use of radio signals. Some of the challenges exist in the design of wireless sensor network are restricted computation power, storage, battery and transmission bandwidth. To resolve these issues, clustering and routing processes have been presented. Clustering and routing processes are considered as an optimization problem in wireless sensor network which can be resolved by the use of swarm intelligence–based approaches. This article presents a novel swarm intelligence–based clustering and multihop routing protocol for wireless sensor network. Initially, improved particle swarm optimization technique is applied for choosing the cluster heads and organizes the clusters proficiently. Then, the grey wolf optimization algorithm–based routing process takes place to select the optimal paths in the network. The presented improved particle swarm optimization–grey wolf optimization approach incorporates the benefits of both the clustering and routing processes which leads to maximum energy efficiency and network lifetime. The proposed model is simulated under an extension set of experimentation, and the results are validated under several measures. The obtained experimental outcome demonstrated the superior characteristics of the improved particle swarm optimization–grey wolf optimization technique under all the test cases.},
	language = {en},
	number = {9},
	urldate = {2024-02-05},
	journal = {International Journal of Distributed Sensor Networks},
	author = {Elhoseny, Mohamed and Rajan, R Sundar and Hammoudeh, Mohammad and Shankar, K and Aldabbas, Omar},
	month = sep,
	year = {2020},
	note = {Publisher: SAGE Publications},
	keywords = {/unread},
	pages = {1550147720949133},
}

@inproceedings{vasic2013Safety,
	title = {Safety issues in human-robot interactions},
	doi = {10.1109/ICRA.2013.6630576},
	abstract = {Safety is an important consideration in human-robot interactions (HRI). Robots can perform powerful movements that can cause hazards to humans surrounding them. To prevent accidents, it is important to identify sources of potential harm, to determine which of the persons in the robot's vicinity may be in greatest peril and to assess the type of injuries the robot may cause to this person. This survey starts with a review of the safety issues in industrial settings, where robots manipulate dangerous tools and move with extreme rapidity and force. We then move to covering issues related to the growing numbers of autonomous mobile robots that operate in crowded (human-inhabited) environments. We discuss the potential benefits of fully autonomous cars on safety on roads and for pedestrians. Lastly, we cover safety issues related to assistive robots.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Vasic, Milos and Billard, Aude},
	month = may,
	year = {2013},
	note = {ISSN: 1050-4729},
	keywords = {/unread, Accidents, Hazards, Injuries, Robot sensing systems, Service robots},
	pages = {197--204},
}

@article{verginis2018Robust,
	title = {Robust {Distributed} {Control} {Protocols} for {Large} {Vehicular} {Platoons} {With} {Prescribed} {Transient} and {Steady}-{State} {Performance}},
	volume = {26},
	issn = {1558-0865},
	url = {https://ieeexplore.ieee.org/abstract/document/7843675},
	doi = {10.1109/TCST.2017.2658180},
	abstract = {In this brief, we study the longitudinal control problem for a platoon of vehicles with unknown nonlinear dynamics under both the predecessor-following and the bidirectional control architectures. The proposed control protocols are fully distributed in the sense that each vehicle utilizes feedback from its relative position with respect to its preceding and following vehicles as well as its own velocity, which can all be easily acquired by onboard sensors. Moreover, no previous knowledge of model nonlinearities/disturbances is incorporated in the control design, enhancing in that way the robustness of the overall closed-loop system against model imperfections. Additionally, certain designer-specified performance functions determine the transient and steady-state response, thus preventing connectivity breaks due to sensor limitations as well as intervehicular collisions. Finally, extensive simulation studies and a real-time experiment conducted with mobile robots clarify the proposed control protocols and verify their effectiveness.},
	number = {1},
	urldate = {2024-02-12},
	journal = {IEEE Transactions on Control Systems Technology},
	author = {Verginis, Christos K. and Bechlioulis, Charalampos P. and Dimarogonas, Dimos V. and Kyriakopoulos, Kostas J.},
	month = jan,
	year = {2018},
	note = {Conference Name: IEEE Transactions on Control Systems Technology},
	keywords = {/unread, Computer architecture, Decentralized control, Platoon, Prescribed Performance, Protocols, Robustness, Sensors, Steady-state, Transient analysis},
	pages = {299--304},
}

@article{gong2015Realtime,
	title = {Real-time {GIS} data model and sensor web service platform for environmental data management},
	volume = {14},
	issn = {1476-072X},
	url = {https://doi.org/10.1186/1476-072X-14-2},
	doi = {10.1186/1476-072X-14-2},
	abstract = {Effective environmental data management is meaningful for human health. In the past, environmental data management involved developing a specific environmental data management system, but this method often lacks real-time data retrieving and sharing/interoperating capability. With the development of information technology, a Geospatial Service Web method is proposed that can be employed for environmental data management. The purpose of this study is to determine a method to realize environmental data management under the Geospatial Service Web framework.},
	number = {1},
	urldate = {2023-08-27},
	journal = {International Journal of Health Geographics},
	author = {Gong, Jianya and Geng, Jing and Chen, Zeqiang},
	month = jan,
	year = {2015},
	keywords = {/unread, Environmental data management, Real-time GIS data model, Sensor Web service platform},
	pages = {2},
}

@inproceedings{bano2019Radio,
	title = {Radio {Controlled} {Beach} {Cleaning} {Bot}},
	doi = {10.1109/ICETAS48360.2019.9117269},
	abstract = {The pollution, now a days occurring on beaches, is increasing day by day due to some scathing events taking place such as flood or solid litter left behind by the public. This litter, when present in a large quantity of small pieces, appears to be more hazardous for the animals, both inside and outside of the water. Cleaning this litter requires a large no. of labors that add to the cost. To overcome this obstacle, there have been many systems designed on a larger scale, each differing in quantity and type of litter as well as the structure. A system that can work efficiently in coastal environment and is cost effective, reducing human effort and wastage of time, is still the need of the present day. Our project is one suitable method to reticulate this issue. The prototype of RC beach cleaning bot is designed and fabricated for this purpose. It comprises of filtration mechanism and driving mechanism. The filtration mechanism consists of a system used for the separation of sand and litter of small size (i.e. plastic pieces, glass pieces, cans, cigarette butts etc.) using vibration mechanism. Whereas, the driving mechanism remotely controls the motion of the robot via Bluetooth module that will send and receive signals with the help of a transceiver. This type of system works significantly for the environment in best economic way.},
	booktitle = {2019 {IEEE} 6th {International} {Conference} on {Engineering} {Technologies} and {Applied} {Sciences} ({ICETAS})},
	author = {Bano, Nasreen and Amin, Amina and Boghani, Hussain and Tariq, Hiba and Bakhtawar, Saba and Waggan, Illyas and Younas, Tanzila},
	month = dec,
	year = {2019},
	keywords = {/unread, Pollution, beach cleaning bot, beaches, hazardous, solid litter},
	pages = {1--6},
}

@inproceedings{corke2005Networked,
	address = {Berlin, Heidelberg},
	series = {Springer {Tracts} in {Advanced} {Robotics}},
	title = {Networked {Robots}: {Flying} {Robot} {Navigation} {Using} a {Sensor} {Net}},
	isbn = {978-3-540-31508-7},
	shorttitle = {Networked {Robots}},
	doi = {10.1007/11008941_25},
	abstract = {This paper introduces the application of a sensor network to navigate a flying robot. We have developed distributed algorithms and efficient geographic routing techniques to incrementally guide one or more robots to points of interest based on sensor gradient fields, or along paths defined in terms of Cartesian coordinates. The robot itself is an integral part of the localization process which establishes the positions of sensors which are not known a priori. We use this system in a large-scale outdoor experiment with Mote sensors to guide an autonomous helicopter along a path encoded in the network.},
	language = {en},
	booktitle = {Robotics {Research}. {The} {Eleventh} {International} {Symposium}},
	publisher = {Springer},
	author = {Corke, Peter and Peterson, Ron and Rus, Daniela},
	editor = {Dario, Paolo and Chatila, Raja},
	year = {2005},
	keywords = {/unread, Mobile Node, Mobile Robot, Mote Sensor, Sensor Network, Sensor Node},
	pages = {234--243},
}

@article{ye2023MutualInformation,
	title = {Mutual-{Information} {Regularized} {Multi}-{Agent} {Policy} {Iteration}},
	volume = {36},
	url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/0799492e7be38b66d10ead5e8809616d-Abstract-Conference.html},
	language = {en},
	urldate = {2024-02-23},
	journal = {Annual Conference on Neural Information Processing Systems},
	author = {Ye, Deheng and Lu, Zongqing},
	month = dec,
	year = {2023},
	keywords = {/unread},
}

@incollection{malhotra2023Optimal,
	title = {Optimal {Solar} {Charging} {Enabled} {Autonomous} {Cleaning} {Robot}},
	copyright = {© 2023 Scrivener Publishing LLC},
	isbn = {978-1-394-19373-8},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781394193738.ch33},
	abstract = {The progress of various fields of robotics improves people's quality time and their environment. Garbage is a major problem in worldwide attenuation. Developing waste collector robots is currently a field of research on efficient solutions to the present-day problem of unclean surroundings which degrade the environment. Due to the difficulties faced in keeping the surroundings clean manually, this project proposes a solution by developing an autonomous robot with the additional feature of solar charging for its batteries. Solar photovoltaic advancements using a renewable source of energy have become prominent in today's world due to the scarcity of energy resources globally. The robot will draw out energy from the solar-powered batteries needed to run its mechanical and electrical components to perform the cleaning task efficiently. The power output of the solar batteries is optimized using Maximum Power Point Tracking (MPPT) Algorithm for efficient power management for the robot.},
	language = {en},
	urldate = {2023-08-27},
	booktitle = {Integrated {Green} {Energy} {Solutions} {Volume} 2},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Malhotra, Aastha and Darshan, Anagha and Girdhar, Naman and Das, Prantika and Bhojwani, Rohan and Anantha Krishnan, V. and Gnana Swathika, O.v.},
	year = {2023},
	doi = {10.1002/9781394193738.ch33},
	note = {Section: 33
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781394193738.ch33},
	keywords = {/unread, Autonomous, ESP32, Node-RED, P\&O algorithm, RCNN, rack and pinion, solar battery charger},
	pages = {231--247},
}

@inproceedings{ichimura2018Performance,
	title = {Performance {Evaluation} of a {Beach} {Cleaning} {Robot} “{Hirottaro} 3” in an {Actual} {Working} {Environment}},
	abstract = {We have been developing a compact beach cleaning robot ”Hirottaro 3”. In order to collect small refuse effectively on a sandy surface, the robot was equipped with a mechanism that collected items as if humans clean a floor with a broom and dustpan. Furthermore, the robot was capable of traveling autonomously on the sandy beach that had insufficient natural landmarks by self-localization using poles and a scanning range finder. This paper reports the performance evaluation of refuse collection and autonomous navigation on the sandy beach.},
	booktitle = {2018 18th {International} {Conference} on {Control}, {Automation} and {Systems} ({ICCAS})},
	author = {Ichimura, Tomoyasu and Nakajima, Shin-ichi},
	month = oct,
	year = {2018},
	keywords = {/unread, Automation, Autonomous robots, Beach cleaning robot, Cleaning, Performance evaluation, Reliability, Waste materials, autonomous navigation, refuse collection, scanning range finder, self-localization},
	pages = {825--828},
}

@inproceedings{lowe2017MultiAgent,
	title = {Multi-{Agent} {Actor}-{Critic} for {Mixed} {Cooperative}-{Competitive} {Environments}},
	volume = {30},
	url = {https://papers.nips.cc/paper_files/paper/2017/hash/68a9750337a418a86fe06c1991a1d64c-Abstract.html},
	abstract = {We explore deep reinforcement learning methods for multi-agent domains. We begin by analyzing the difficulty of traditional algorithms in the multi-agent case: Q-learning is challenged by an inherent non-stationarity of the environment, while policy gradient suffers from a variance that increases as the number of agents grows. We then present an adaptation of actor-critic methods that considers action policies of other agents and is able to successfully learn policies that require complex multi-agent coordination. Additionally, we introduce a training regimen utilizing an ensemble of policies for each agent that leads to more robust multi-agent policies. We show the strength of our approach compared to existing methods in cooperative as well as competitive scenarios, where agent populations are able to discover various physical and informational coordination strategies.},
	urldate = {2024-02-19},
	booktitle = {Annual {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Lowe, Ryan and WU, YI and Tamar, Aviv and Harb, Jean and Pieter Abbeel, OpenAI and Mordatch, Igor},
	year = {2017},
	keywords = {/unread},
}

@article{kraemer2016Multiagent,
	title = {Multi-agent reinforcement learning as a rehearsal for decentralized planning},
	volume = {190},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231216000783},
	doi = {10.1016/j.neucom.2016.01.031},
	abstract = {Decentralized partially observable Markov decision processes (Dec-POMDPs) are a powerful tool for modeling multi-agent planning and decision-making under uncertainty. Prevalent Dec-POMDP solution techniques require centralized computation given full knowledge of the underlying model. Multi-agent reinforcement learning (MARL) based approaches have been recently proposed for distributed solution of Dec-POMDPs without full prior knowledge of the model, but these methods assume that conditions during learning and policy execution are identical. In some practical scenarios this may not be the case. We propose a novel MARL approach in which agents are allowed to rehearse with information that will not be available during policy execution. The key is for the agents to learn policies that do not explicitly rely on these rehearsal features. We also establish a weak convergence result for our algorithm, RLaR, demonstrating that RLaR converges in probability when certain conditions are met. We show experimentally that incorporating rehearsal features can enhance the learning rate compared to non-rehearsal-based learners, and demonstrate fast, (near) optimal performance on many existing benchmark Dec-POMDP problems. We also compare RLaR against an existing approximate Dec-POMDP solver which, like RLaR, does not assume a priori knowledge of the model. While RLaR׳s policy representation is not as scalable, we show that RLaR produces higher quality policies for most problems and horizons studied.},
	urldate = {2024-02-19},
	journal = {Neurocomputing},
	author = {Kraemer, Landon and Banerjee, Bikramjit},
	month = may,
	year = {2016},
	keywords = {/unread, Decentralized planning, Multi-agent reinforcement learning},
	pages = {82--94},
}

@inproceedings{christen2023Learning,
	title = {Learning {Human}-to-{Robot} {Handovers} {From} {Point} {Clouds}},
	url = {https://openaccess.thecvf.com/content/CVPR2023/html/Christen_Learning_Human-to-Robot_Handovers_From_Point_Clouds_CVPR_2023_paper.html},
	language = {en},
	urldate = {2024-02-26},
	author = {Christen, Sammy and Yang, Wei and Pérez-D’Arpino, Claudia and Hilliges, Otmar and Fox, Dieter and Chao, Yu-Wei},
	year = {2023},
	keywords = {/unread},
	pages = {9654--9664},
}

@article{wang2022Distributed,
	title = {Distributed {Reinforcement} {Learning} for {Robot} {Teams}: a {Review}},
	volume = {3},
	issn = {2662-4087},
	shorttitle = {Distributed {Reinforcement} {Learning} for {Robot} {Teams}},
	url = {https://doi.org/10.1007/s43154-022-00091-8},
	doi = {10.1007/s43154-022-00091-8},
	abstract = {Recent advances in sensing, actuation, and computation have opened the door to multi-robot systems consisting of hundreds/thousands of robots, with promising applications to automated manufacturing, disaster relief, harvesting, last-mile delivery, port/airport operations, or search and rescue. The community has leveraged model-free multi-agent reinforcement learning (MARL) to devise efficient, scalable controllers for multi-robot systems (MRS). This review aims to provide an analysis of the state-of-the-art in distributed MARL for multi-robot cooperation.},
	language = {en},
	number = {4},
	urldate = {2024-02-26},
	journal = {Current Robotics Reports},
	author = {Wang, Yutong and Damani, Mehul and Wang, Pamela and Cao, Yuhong and Sartoretti, Guillaume},
	month = dec,
	year = {2022},
	keywords = {/unread, Communication learning, Cooperation, Mixed cooperative-competitive settings, Motion planning, Multi-robot systems, Reinforcement learning},
	pages = {239--257},
}

@article{tang2022Learning,
	title = {Learning to {Coordinate} for a {Worker}-{Station} {Multi}-{Robot} {System} in {Planar} {Coverage} {Tasks}},
	volume = {7},
	issn = {2377-3766},
	url = {https://ieeexplore.ieee.org/document/9918029},
	doi = {10.1109/LRA.2022.3214446},
	abstract = {For massive large-scale tasks, a multi-robot system (MRS) can effectively improve efficiency by utilizing each robot's different capabilities, mobility, and functionality. In this letter, we focus on the multi-robot coverage path planning (mCPP) problem in large-scale planar areas with random dynamic interferers in the environment, where the robots have limited resources. We introduce a worker-station MRS consisting of multiple workers with limited resources for actual work, and one station with enough resources for resource replenishment. We aim to solve the mCPP problem for the worker-station MRS by formulating it as a fully cooperative multi-agent reinforcement learning problem. Then we propose an end-to-end decentralized online planning method, which simultaneously solves coverage planning for workers and rendezvous planning for station. Our method manages to reduce the influence of random dynamic interferers on planning, while the robots can avoid collisions with them. We conduct simulation and real robot experiments, and the comparison results show that our method has competitive performance in solving the mCPP problem for worker-station MRS in metric of task finish time.},
	number = {4},
	urldate = {2024-03-07},
	journal = {IEEE Robotics and Automation Letters},
	author = {Tang, Jingtao and Gao, Yuan and Lam, Tin Lun},
	month = oct,
	year = {2022},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {/unread, Collision avoidance, Multi-robot systems, Planning, Robot kinematics, Robots, Synchronization, Task analysis, planning, reinforcement learning, scheduling and coordination},
	pages = {12315--12322},
}

@article{joon2021Design,
	title = {Design of {Autonomous} {Mobile} {Robot} for {Cleaning} in the {Environment} with {Obstacles}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/11/17/8076},
	doi = {10.3390/app11178076},
	abstract = {This paper describes the design and development of a cleaning robot, using adaptive manufacturing technology and its use with a control algorithm for which there is a stability proof. The authors’ goal was to fill the gap between theory and practical implementation based on available low-cost components. Adaptive manufacturing was chosen to cut down the cost of manufacturing the robot. Practical verification of the effectiveness of the control algorithm was achieved with the experiments. The robot comprises mainly three assemblies, a four-wheel-drive platform, a four-degrees-of-freedom robotic arm, and a vacuum system. The inlet pipe of the vacuum system was attached to the end effector of the robotic arm, which makes the robot more flexible to clean uneven areas, such as skirting on floors. The robot was equipped with a LIDAR sensor and web camera, giving the opportunity to develop more complex methods. A low-level proportional–integral–derivative (PID) speed controller was implemented, and a high-level controller that uses artificial potential functions to generate repulsive components, which avoids collision with obstacles. Robot operating system (ROS) was installed in the robot’s on-board system. With the help of the ROS node, the high-level controller generates control signals for the low-level controller.},
	language = {en},
	number = {17},
	urldate = {2023-08-27},
	journal = {Applied Sciences},
	author = {Joon, Arpit and Kowalczyk, Wojciech},
	month = jan,
	year = {2021},
	note = {Number: 17
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {/unread, 3D printing, LIDAR sensor, ROS, artificial potential function, cleaning robot, four-wheel drive, high-level obstacle avoidance controller, low-level PID controller, robotic arm, vacuum system},
	pages = {8076},
}

@inproceedings{ichimura2016Development,
	title = {Development of an autonomous beach cleaning robot “{Hirottaro}”},
	doi = {10.1109/ICMA.2016.7558676},
	abstract = {This paper discusses the development of a small beach cleaning robot. The paper discusses two aspects of the robot: the refuse collection mechanism and the autonomous navigation system. In order to enable effective collection of refuse from a sandy surface, we developed a mechanism that mimics cleaning of a floor using a broom and dustpan. To identify its own position, the robot was equipped with a scanning range finder, which measured the position of two poles placed at the corners of the designated work area. The navigation system calculated the position and orientation of the robot using the sensor information and corrected any errors in the path.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Mechatronics} and {Automation}},
	author = {Ichimura, Tomoyasu and Nakajima, Shin-ichi},
	month = aug,
	year = {2016},
	note = {ISSN: 2152-744X},
	keywords = {/unread, Automation, Beach cleaning robot, Conferences, Erbium, Mechatronics, Navigation, Robots, Waste materials, autonomous navigation, scanning range finder, self-localization},
	pages = {868--872},
}

@article{govindan2019Designing,
	title = {Designing a sustainable supply chain network integrated with vehicle routing: {A} comparison of hybrid swarm intelligence metaheuristics},
	volume = {110},
	issn = {0305-0548},
	shorttitle = {Designing a sustainable supply chain network integrated with vehicle routing},
	url = {https://www.sciencedirect.com/science/article/pii/S0305054818302995},
	doi = {10.1016/j.cor.2018.11.013},
	abstract = {Recently, a growing concern with sustainability has become a consideration in business operations. However, there is a lack of mathematical models that quantify environmental effects and, in particular, social impacts of supply chains because of the inherently subjective nature of these aspects. To fill this gap, this paper models a distribution network in which the triple bottom lines of sustainability are captured. Different impacts of the network on the stakeholders, including company owners, workers, consumers and society, are considered as whole. In the current model, a multi-product vehicle routing problem with time windows (MPVRPTW) as an operational decision is integrated with strategic decisions related to the network design. To solve this model, three hybrid swarm intelligence techniques (particle swarm optimization (PSO), electromagnetism mechanism algorithm (EMA), and artificial bee colony (ABC)) are proposed, and each is hybridized with variable neighborhood search (VNS) are proposed. Because metaheuristic methods are sensitive to input parameters, response surface methodology (RSM) with the multi-objective decision making (MODM) approach is applied for tuning the parameters. The proposed approaches are compared with the hybrid of genetic algorithm (GA) and VNS as the benchmark algorithm. A fair comparison is conducted by employing six metrics to evaluate the quality of the Pareto frontier obtained by the algorithms on the test problems. According to the results, the predominance of EMA is enhanced by VNS local search.},
	urldate = {2024-02-05},
	journal = {Computers \& Operations Research},
	author = {Govindan, Kannan and Jafarian, Ahmad and Nourbakhsh, Vahid},
	month = oct,
	year = {2019},
	keywords = {/unread, Corporate social responsibility, Environmental management, Multiple-objective optimization, Sustainable supply chain network, Swarm intelligence algorithms, Vehicle routing problem},
	pages = {220--235},
}

@article{kotaro2003Coevolution,
	title = {Co-evolution of {Hetero} {Multiagent} {Systems} using {Genetic} {Network} {Programming}},
	volume = {123},
	issn = {0385-4221},
	url = {http://www.scopus.com/inward/record.url?scp=65449117213&partnerID=8YFLogxK},
	doi = {10.1541/ieejeiss.123.544},
	abstract = {Recently, many methods of evolutionary computation such as Genetic Algorithm(GA) and Genetic Programming(GP) have been developed as a basic tool for modeling and optimizing complex systems. GA has the genome of string structure, while the genome in GP is of tree structure. In this paper, a new evolutionary method named Genetic Network Programming(GNP), whose genome has network structure is applied to multiagent sysytems. Hetero Multiagent Sysytems with GNP are studied, where each agent of the same group has its own GNP program in order to build the adaptive agents against changing environments. Specifically, the comparison between Hetero Multiagent Systems and conventional Homo Multiagent Sysytems is carried out in simulations on ants behaviors.},
	number = {3},
	urldate = {2024-02-23},
	journal = {IEEJ Transactions on Electronics, Information and Systems},
	author = {Kotaro, Hirasawa and Masafumi, Okubo and Jinglu, Hu and Junichi, Murata and Yuko, Matsuya},
	month = jan,
	year = {2003},
	keywords = {/unread},
	pages = {544--551},
}

@inproceedings{verginis2018Communicationbased,
	title = {Communication-based {Decentralized} {Cooperative} {Object} {Transportation} {Using} {Nonlinear} {Model} {Predictive} {Control}},
	url = {https://ieeexplore.ieee.org/abstract/document/8550305},
	doi = {10.23919/ECC.2018.8550305},
	abstract = {This paper addresses the problem of cooperative transportation of an object rigidly grasped by N robotic agents. We propose a decentralized Nonlinear Model Predictive Control (NMPC) scheme that guarantees the navigation of the object to a desired pose in a bounded workspace with obstacles, while complying with certain input saturations of the agents. The control scheme is based on inter-agent communication and is decentralized in the sense that each agent calculates its own control signal. Moreover, the proposed methodology ensures that the agents do not collide with each other or with workspace obstacles as well as that they do not pass through singular configurations. Finally, simulation results illustrate the validity and efficiency of the proposed method.},
	urldate = {2024-02-12},
	booktitle = {2018 {European} {Control} {Conference} ({ECC})},
	author = {Verginis, Christos K. and Nikou, Alexandros and Dimarogonas, Dimos V.},
	month = jun,
	year = {2018},
	keywords = {/unread, Ellipsoids, End effectors, Jacobian matrices, Kinematics, Task analysis},
	pages = {733--738},
}

@inproceedings{laha2021Coordinated,
	title = {Coordinated {Motion} {Generation} and {Object} {Placement}: {A} {Reactive} {Planning} and {Landing} {Approach}},
	shorttitle = {Coordinated {Motion} {Generation} and {Object} {Placement}},
	url = {https://ieeexplore.ieee.org/abstract/document/9636652/references#references},
	doi = {10.1109/IROS51168.2021.9636652},
	abstract = {Similar to human work, robotic tasks sometimes require two hands to be accomplished. This requires coordinated motion planning and control. While fulfilling the task in a coordinated manner is already a big challenge, the task at hand becomes even harder when obstacles are introduced in the environment that need to be avoided. Furthermore in the case of dynamic environments, contacts cannot be avoided all the time, even with robust planning. In addition to geometric constraints, bimanual systems need to be able to detect and react to contacts during task execution. To this aim, we integrate a vector-field based planning scheme, that is able to avoid obstacles, with contact detection and reactive control methods based on contact wrench estimation such as admittance control. We also fuse the real contact forces into the planner directly together with the circular repulsive fields. The resulting planner-controller combination is capable of obstacle avoidance planning as well as reaction control in the case of unforeseen contacts that can also be used in situations where the manipulation needs to be guided by the environment such as landing control in only roughly known environments. We evaluate our approach on the torque-controlled Kobo bimanual set-up and also perform rigorous simulation studies.},
	urldate = {2023-11-23},
	booktitle = {2021 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Laha, Riddhiman and Vorndamme, Jonathan and Figueredo, Luis F.C. and Qu, Zheng and Swikir, Abdalla and Jähne, Christoph and Haddadin, Sami},
	month = sep,
	year = {2021},
	note = {ISSN: 2153-0866},
	keywords = {/unread},
	pages = {9401--9407},
}

@inproceedings{k.a2023Deep,
	title = {Deep {Learning} based {Beach} {Cleaning} {Robot}},
	doi = {10.1109/ICAAIC56838.2023.10141099},
	abstract = {Robots are now more autonomous and effective than ever because to the quick development of digital technologies. Future advancements in robotics could change how people and robots interact. Robots will likely carry out a range of tasks in public areas. Robots could significantly enhance our quality of life and add to the atmosphere, capacity for creativity, and safety of public spaces. However, as this tendency advances, there is a danger that robots will negatively alter public areas and social relationships. This research study investigates how public policy may both improve opportunities brought about by the presence of robots in public spaces and lessen the risks of unfavorable consequences by analyzing prior methods to utilizing and controlling disruptive technology. Robots are effective in waste management also. By using object detection robots could clean the wastes automatically and efficiently by making the surroundings clean.},
	booktitle = {2023 2nd {International} {Conference} on {Applied} {Artificial} {Intelligence} and {Computing} ({ICAAIC})},
	author = {K.A, Joseph and C, Joshua Sony and M, Lakshmi Rajkumar and P.S, Syam Krishna and Francis, Ambily and Babu, Anju},
	month = may,
	year = {2023},
	keywords = {/unread, Index Tenns-Robotics, Indexes, Object detection, Organisms, Pollution, Public policy, Safety, Single Shot Detection, Waste management},
	pages = {427--433},
}

@inproceedings{tsiamis2015Cooperative,
	title = {Cooperative manipulation exploiting only implicit communication},
	url = {https://ieeexplore.ieee.org/abstract/document/7353473},
	doi = {10.1109/IROS.2015.7353473},
	abstract = {This paper addresses the problem of cooperative object manipulation with the coordination relying solely on implicit communication. We consider a decentralized leader-follower architecture where the leading robot, that has exclusive knowledge of the object's desired trajectory, tries to achieve the desired tracking behavior via an impedance control law. On the other hand, the follower estimates the leader's desired motion via a novel prescribed performance estimation law, that drives the estimation error to an arbitrarily small residual set, and implements a similar impedance control law. Both control schemes adopt feedback linearization as well as load sharing among the robots according to their specific payload capabilities. The feedback relies exclusively on each robot's force/torque, position as well as velocity measurements and apart from a few commonly predetermined constant parameters, no explicit data is exchanged on-line among the robots, thus reducing the required communication bandwidth and increasing robustness. Finally, a comparative simulation study clarifies the proposed method and verifies its efficiency.},
	urldate = {2024-02-13},
	booktitle = {2015 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Tsiamis, Anastasios and Verginis, Christos K. and Bechlioulis, Charalampos P. and Kyriakopoulos, Kostas J.},
	month = sep,
	year = {2015},
	keywords = {/unread, Dynamics, Impedance, Manipulators, Robot kinematics, Robot sensing systems, Trajectory},
	pages = {864--869},
}

@article{gao2023Asymmetric,
	title = {Asymmetric {Self}-{Play}-{Enabled} {Intelligent} {Heterogeneous} {Multirobot} {Catching} {System} {Using} {Deep} {Multiagent} {Reinforcement} {Learning}},
	volume = {39},
	issn = {1941-0468},
	url = {https://ieeexplore.ieee.org/document/10101687/citations?tabFilter=papers#citations},
	doi = {10.1109/TRO.2023.3257541},
	abstract = {Aiming to develop a more robust and intelligent heterogeneous system for adversarial catching in security and rescue tasks, in this article, we discuss the specialities of applying asymmetric self-play and curriculum learning techniques to deal with the increasing heterogeneity and number of different robots in modern heterogeneous multirobot systems (HMRS). Our method, based on actor-critic multiagent reinforcement learning, provides a framework that can enable cooperative behaviors among heterogeneous multirobot teams. This leads to the development of an HMRS for complex catching scenarios that involve several robot teams and real-world constraints. We conduct simulated experiments to evaluate different mechanisms' influence on our method's performance, and real-world experiments to assess our system's performance in complex real-world catching problems. In addition, a bridging study is conducted to compare our method with a state-of-the-art method called S2M2 in heterogeneous catching problems, and our method performs better in adversarial settings. As a result, we show that the proposed framework, through fusing asymmetric self-play and curriculum learning during training, is able to successfully complete the HMRS catching task under realistic constraints in both simulation and the real world, thus providing a direction for future large-scale intelligent security \& rescue HMRS.},
	number = {4},
	urldate = {2024-03-07},
	journal = {IEEE Transactions on Robotics},
	author = {Gao, Yuan and Chen, Junfeng and Chen, Xi and Wang, Chongyang and Hu, Junjie and Deng, Fuqin and Lam, Tin Lun},
	month = aug,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Robotics},
	keywords = {/unread, Asymmetric self-play, Heuristic algorithms, Mathematical models, Multi-robot systems, Planning, Robots, Task analysis, Training, catching systems, heterogeneous multirobot system (HMRS), reinforcement learning (RL)},
	pages = {2603--2622},
}

@article{nunes2017Taxonomy,
	series = {Special {Issue} on {New} {Research} {Frontiers} for {Intelligent} {Autonomous} {Systems}},
	title = {A taxonomy for task allocation problems with temporal and ordering constraints},
	volume = {90},
	issn = {0921-8890},
	url = {https://www.sciencedirect.com/science/article/pii/S0921889016306157},
	doi = {10.1016/j.robot.2016.10.008},
	abstract = {Previous work on assigning tasks to robots has proposed extensive categorizations of allocation of tasks with and without constraints. The main contribution of this paper is a specific categorization of problems that have temporal and ordering constraints. We propose a novel taxonomy that emphasizes the differences between temporal and ordering constraints, and organizes the current literature according to the nature of those constraints. We summarize widely used models and methods from the task allocation literature and related areas, such as vehicle routing and scheduling problems, showing similarities and differences.},
	urldate = {2023-11-23},
	journal = {Robotics and Autonomous Systems},
	author = {Nunes, Ernesto and Manner, Marie and Mitiche, Hakim and Gini, Maria},
	month = apr,
	year = {2017},
	keywords = {/unread, Multi-robot coordination, Task allocation, Taxonomy, Temporal constraints, Time-extended assignments},
	pages = {55--70},
}

@article{zhang2023SpiralPropulsion,
	title = {A {Spiral}-{Propulsion} {Amphibious} {Intelligent} {Robot} for {Land} {Garbage} {Cleaning} and {Sea} {Garbage} {Cleaning}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/11/8/1482},
	doi = {10.3390/jmse11081482},
	abstract = {To address the issue of current garbage cleanup vessels being limited to performing garbage cleaning operations in the ocean, without the capability of transferring the garbage from the ocean to the land, this paper presents a spiral-propulsion amphibious intelligent robot for land garbage cleaning and sea garbage cleaning. The design solution is as follows. A mechanical structure based on a spiral drum is proposed. The interior of the spiral drum is hollow, providing buoyancy, allowing the robot to travel both on marshy, tidal flats and on the water surface, in conjunction with underwater thrusters. Additionally, a mechanical-arm shovel is designed, which achieves two-degrees-of-freedom movement through a spiral spline guide and servo, facilitating garbage collection. Our experimental results demonstrated that the robot exhibits excellent maneuverability in marine environments and on beach, marsh, and tidal flat areas, and that it collects garbage effectively.},
	language = {en},
	number = {8},
	urldate = {2023-08-27},
	journal = {Journal of Marine Science and Engineering},
	author = {Zhang, Yanghai and Huang, Zan and Chen, Changlin and Wu, Xiangyu and Xie, Shuhang and Zhou, Huizhan and Gou, Yihui and Gu, Liuxin and Ma, Mengchao},
	month = aug,
	year = {2023},
	note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {/unread, amphibious, garbage-cleaning robot, spiral propulsion, waste shovel},
	pages = {1482},
}

@inproceedings{varghese2022Binman,
	title = {Binman: {An} {Autonomous} {Beach} {Cleaning} {Robot}},
	shorttitle = {Binman},
	doi = {10.1109/MysuruCon55714.2022.9972499},
	abstract = {Pollution on beaches increasing day by day. The major wastes that are collected from beaches include liquor bottles, cigarettes, and plastic bottles. Out of these, plastic bottles were the major ones. These wastes ended up in the sea if they didn’t collect properly destroying the aquatic life. Manual collection of this waste will result in health problems for the workers. So, there is a need for a machine that will collect this waste and dispose of it with minimum human intervention and cause zero-carbon footage. This paper discusses the design and simulation of a beach cleaning robot named Binman which includes discussions on the overall structure of the robot, motor, and battery selection, and implementation of GPS waypoint navigation using ROS framework.},
	booktitle = {2022 {IEEE} 2nd {Mysore} {Sub} {Section} {International} {Conference} ({MysuruCon})},
	author = {Varghese, Denny and Mohan, Ashish},
	month = oct,
	year = {2022},
	keywords = {/unread, Ardupilot, Batteries, Cleaning, GPS waypoint navigation, Manuals, Navigation, Plastic products, Pollution, Robots, autonomous, beach cleaning robot, green solution, hazardous, robot operating system, robotics, waste collection},
	pages = {1--5},
}

@inproceedings{priya2019Beach,
	title = {Beach {Cleaning} {Bot} {Based} {On} {Region} {Monitoring}},
	doi = {10.1109/ICCPEIC45300.2019.9082368},
	abstract = {This paper discusses about the development of beach cleaning bot. The paper focuses on two main aspects: conveyor belt mechanism and region monitoring system. In order to remove the waste from the sandy surface, we developed the conveyor belt mechanism. To identify the waste the bot was equipped with pi camera module this helps the bot to continuously monitor the sandy surface. Region monitoring is based on object detection (image processing) which is used to detect the waste and respond accordingly. For object detection process Tensorflow and OpenCV software are used.},
	booktitle = {2019 {International} {Conference} on {Computation} of {Power}, {Energy}, {Information} and {Communication} ({ICCPEIC})},
	author = {Priya, J. Shalini and Balaji, K.T and Thangappan, Saikrish and Yuva Sudhakaran, G},
	month = mar,
	year = {2019},
	note = {ISSN: 2576-9065},
	keywords = {/unread, beach cleaning bot, conveyor belt mechanism, pi camera., region monitoring system},
	pages = {1--4},
}

@article{gerkey2004Formal,
	title = {A {Formal} {Analysis} and {Taxonomy} of {Task} {Allocation} in {Multi}-{Robot} {Systems}},
	volume = {23},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364904045564},
	doi = {10.1177/0278364904045564},
	abstract = {Despite more than a decade of experimental work in multi-robot systems, important theoretical aspects of multi-robot coordination mechanisms have, to date, been largely untreated. To address this issue, we focus on the problem of multi-robot task allocation (MRTA). Most work on MRTA has been ad hoc and empirical, with many coordination architectures having been proposed and validated in a proof-of-concept fashion, but infrequently analyzed. With the goal of bringing objective grounding to this important area of research, we present a formal study of MRTA problems. A domain-independent taxonomy of MRTA problems is given, and it is shown how many such problems can be viewed as instances of other, well-studied, optimization problems. We demonstrate how relevant theory from operations research and combinatorial optimization can be used for analysis and greater understanding of existing approaches to task allocation, and to show how the same theory can be used in the synthesis of new approaches.},
	language = {en},
	number = {9},
	urldate = {2023-11-23},
	journal = {The International Journal of Robotics Research},
	author = {Gerkey, Brian P. and Matarić, Maja J.},
	month = sep,
	year = {2004},
	note = {Publisher: SAGE Publications Ltd STM},
	keywords = {/unread},
	pages = {939--954},
}

@article{korsah2013Comprehensive,
	title = {A comprehensive taxonomy for multi-robot task allocation},
	volume = {32},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364913496484},
	doi = {10.1177/0278364913496484},
	abstract = {Task allocation is an important aspect of many multi-robot systems. The features and complexity of multi-robot task allocation (MRTA) problems are dictated by the requirements of the particular domain under consideration. These problems can range from those involving instantaneous distribution of simple, independent tasks among members of a homogenous team, to those requiring the time-extended scheduling of complex interrelated multi-step tasks for members of a heterogenous team related by several constraints. The existing widely used taxonomy for task allocation in multi-robot systems was designed for problems with independent tasks and does not deal with problems with interrelated utilities and constraints. While that taxonomy was a ground-breaking contribution to the MRTA literature, a survey of recent work in MRTA reveals that it is no longer a sufficient taxonomy, due to the increasing importance of interrelated utilities and constraints in realistic MRTA problems under consideration. Thus, in this paper, we present a new, comprehensive taxonomy, iTax, that explicitly takes into consideration the issues of interrelated utilities and constraints. Our taxonomy maps categories of MRTA problems to existing mathematical models from combinatorial optimization and operations research, and hence draws important parallels between robotics and these fields.},
	language = {en},
	number = {12},
	urldate = {2023-11-23},
	journal = {The International Journal of Robotics Research},
	author = {Korsah, G. Ayorkor and Stentz, Anthony and Dias, M. Bernardine},
	month = oct,
	year = {2013},
	note = {Publisher: SAGE Publications Ltd STM},
	keywords = {/unread},
	pages = {1495--1512},
}

@article{alatise2020Review,
	title = {A {Review} on {Challenges} of {Autonomous} {Mobile} {Robot} and {Sensor} {Fusion} {Methods}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.2975643},
	abstract = {Autonomous mobile robots are becoming more prominent in recent time because of their relevance and applications to the world today. Their ability to navigate in an environment without a need for physical or electro-mechanical guidance devices has made it more promising and useful. The use of autonomous mobile robots is emerging in different sectors such as companies, industries, hospital, institutions, agriculture and homes to improve services and daily activities. Due to technology advancement, the demand for mobile robot has increased due to the task they perform and services they render such as carrying heavy objects, monitoring, search and rescue missions, etc. Various studies have been carried out by researchers on the importance of mobile robot, its applications and challenges. This survey paper unravels the current literatures, the challenges mobile robot is being faced with. A comprehensive study on devices/sensors and prevalent sensor fusion techniques developed for tackling issues like localization, estimation and navigation in mobile robot are presented as well in which they are organised according to relevance, strengths and weaknesses. The study therefore gives good direction for further investigation on developing methods to deal with the discrepancies faced with autonomous mobile robot.},
	journal = {IEEE Access},
	author = {Alatise, Mary B. and Hancke, Gerhard P.},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {/unread, Autonomous mobile robot, Mobile robots, Navigation, Robot kinematics, Robot sensing systems, Task analysis, Wheels, devices, estimation, localization, navigation, sensor fusion},
	pages = {39830--39846},
}

@misc{noauthor_addon_nodate,
	title = {Addon {Item}},
	keywords = {/unread},
}

@misc{noauthor_study_nodate,
	title = {A study of evolutionary multiagent models based on symbiosis {\textbar} {IEEE} {Journals} \& {Magazine} {\textbar} {IEEE} {Xplore}},
	url = {https://ieeexplore.ieee.org/abstract/document/1580628},
	urldate = {2024-01-30},
	keywords = {/unread},
}

@misc{noauthor_jmse_nodate,
	title = {{JMSE} {\textbar} {Free} {Full}-{Text} {\textbar} {A} {Spiral}-{Propulsion} {Amphibious} {Intelligent} {Robot} for {Land} {Garbage} {Cleaning} and {Sea} {Garbage} {Cleaning}},
	url = {https://www.mdpi.com/2077-1312/11/8/1482},
	urldate = {2023-08-27},
	keywords = {/unread},
}

@misc{noauthor_quadrupedal_nodate,
	title = {Quadrupedal {Locomotion}: {An} {Introduction} to the {Control} of {Four}-legged {Robots} {\textbar} {SpringerLink}},
	url = {https://link.springer.com/book/10.1007/1-84628-307-8},
	urldate = {2023-07-08},
	keywords = {/unread},
}

@inproceedings{meng2016ReviewQuadrupedRobots,
	title = {A review of quadruped robots and environment perception},
	doi = {10.1109/ChiCC.2016.7554355},
	abstract = {As legged robots are suitable to be used in unstructured environments, it becomes a popular field of research nowadays. In this paper, the development of quadruped robots is summarized. And several typical and recent robot systems are addressed in details, such as HyQ series, StarlETH, ANYmal, MIT Cheetah and BigDog, etc. Furthermore, some key techniques of environment perception for quadruped robots, including sensors, feature extraction and identification, mapping and SLAM, are also discussed. Finally, future researches of quadruped robots in environment perception are given.},
	booktitle = {2016 35th {Chinese} {Control} {Conference} ({CCC})},
	author = {Meng, Xiangrui and Wang, Shuo and Cao, Zhiqiang and Zhang, Leijie},
	month = jul,
	year = {2016},
	note = {2 citations (Semantic Scholar/DOI) [2023-04-11]
10 citations (Crossref) [2022-12-07]
ISSN: 1934-1768},
	keywords = {/unread, Legged locomotion, Navigation, Pneumatic systems, Quadruped robot, Robot sensing systems, environment perception, feature extraction, mapping and SLAM, sensors},
	pages = {6350--6356},
}

@article{brunke2022SafeLearningRobotics,
	title = {Safe {Learning} in {Robotics}: {From} {Learning}-{Based} {Control} to {Safe} {Reinforcement} {Learning}},
	volume = {5},
	shorttitle = {Safe {Learning} in {Robotics}},
	url = {https://doi.org/10.1146/annurev-control-042920-020211},
	doi = {10.1146/annurev-control-042920-020211},
	abstract = {The last half decade has seen a steep rise in the number of contributions on safe learning methods for real-world robotic deployments from both the control and reinforcement learning communities. This article provides a concise but holistic review of the recent advances made in using machine learning to achieve safe decision-making under uncertainties, with a focus on unifying the language and frameworks used in control theory and reinforcement learning research. It includes learning-based control approaches that safely improve performance by learning the uncertain dynamics, reinforcement learning approaches that encourage safety or robustness, and methods that can formally certify the safety of a learned control policy. As data- and learning-based robot control methods continue to gain traction, researchers must understand when and how to best leverage them in real-world scenarios where safety is imperative, such as when operating in close proximityto humans. We highlight some of the open challenges that will drive the field of robot learning in the coming years, and emphasize the need for realistic physics-based benchmarks to facilitate fair comparisons between control and reinforcement learning approaches.},
	number = {1},
	urldate = {2022-12-12},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Brunke, Lukas and Greeff, Melissa and Hall, Adam W. and Yuan, Zhaocong and Zhou, Siqi and Panerati, Jacopo and Schoellig, Angela P.},
	year = {2022},
	note = {121 citations (Semantic Scholar/DOI) [2023-04-11]
\_eprint: https://doi.org/10.1146/annurev-control-042920-020211},
	keywords = {/unread, Review, adaptive control, benchmarks, learning-based control, machine learning, model predictive control, robot learning, robotics, robust control, safe learning, safe reinforcement learning},
	pages = {411--444},
}

@article{borenstein_real-time_1989,
	title = {Real-time obstacle avoidance for fast mobile robots},
	volume = {19},
	issn = {2168-2909},
	doi = {10.1109/21.44033},
	abstract = {A real-time obstacle avoidance approach for mobile robots has been developed and implemented. It permits the detection of unknown obstacles simultaneously with the steering of the mobile robot to avoid collisions and advance toward the target. The novelty of this approach, entitled the virtual force field method, lies in the integration of two known concepts: certainty grids for obstacle representation and potential fields for navigation. This combination is especially suitable for the accommodation of inaccurate sensor data as well as for sensor fusion and makes possible continuous motion of the robot with stopping in front of obstacles. This navigation algorithm also takes into account the dynamic behavior of a fast mobile robot and solves the local minimum trap problem. Experimental results from a mobile robot running at a maximum speed of 0.78 m/s demonstrate the power of the algorithm.{\textless}{\textgreater}},
	number = {5},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics},
	author = {Borenstein, J. and Koren, Y.},
	month = sep,
	year = {1989},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics},
	keywords = {/unread, Cleaning, Collision avoidance, Force sensors, Intelligent control, Mobile robots, Navigation, Path planning, Resumes, Robot sensing systems, Sensor fusion},
	pages = {1179--1187},
}

@misc{noauthor_research_nodate,
	title = {Research of mammal bionic quadruped robots: {A} review},
	shorttitle = {Research of mammal bionic quadruped robots},
	url = {https://ieeexplore.ieee.org/abstract/document/6070476/},
	abstract = {This paper focuses on the mammal bionic quadruped robots. The main challenge in this field is how to design the highly dynamical and high payload quadruped robots. This paper firstly introduces the history of bionic quadruped robots, particularly the landmark quadruped robots. Then the state-of-the art of drive mode for quadruped robots is reviewed. Subsequently, the development trend of quadruped robots is described. Based on the state-of-the art of quadruped robots, the technical difficulties of bionic quadruped robots are briefly reviewed. And the hydraulic quadruped robot developed in Shandong University is introduced. Finally, the summary and future work of the quadruped robots is given.},
	language = {en-US},
	urldate = {2023-05-16},
	keywords = {/unread},
}

@misc{noauthor_addon_nodate-1,
	title = {Addon {Item}},
	keywords = {/unread},
}

@misc{fuD4RLDatasetsDeep2021,
	title = {{D4RL}: {Datasets} for {Deep} {Data}-{Driven} {Reinforcement} {Learning}},
	shorttitle = {{D4RL}},
	url = {http://arxiv.org/abs/2004.07219},
	abstract = {The offline reinforcement learning (RL) setting (also known as full batch RL), where a policy is learned from a static dataset, is compelling as progress enables RL methods to take advantage of large, previously-collected datasets, much like how the rise of large datasets has fueled results in supervised learning. However, existing online RL benchmarks are not tailored towards the offline setting and existing offline RL benchmarks are restricted to data generated by partially-trained agents, making progress in offline RL difficult to measure. In this work, we introduce benchmarks specifically designed for the offline setting, guided by key properties of datasets relevant to real-world applications of offline RL. With a focus on dataset collection, examples of such properties include: datasets generated via hand-designed controllers and human demonstrators, multitask datasets where an agent performs different tasks in the same environment, and datasets collected with mixtures of policies. By moving beyond simple benchmark tasks and data collected by partially-trained RL agents, we reveal important and unappreciated deficiencies of existing algorithms. To facilitate research, we have released our benchmark tasks and datasets with a comprehensive evaluation of existing algorithms, an evaluation protocol, and open-source examples. This serves as a common starting point for the community to identify shortcomings in existing offline RL methods and a collaborative route for progress in this emerging area.},
	urldate = {2023-04-21},
	publisher = {arXiv},
	author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
	month = feb,
	year = {2021},
	note = {arXiv:2004.07219 [cs, stat]},
	keywords = {/unread, Computer Science - Machine Learning, Statistics - Machine Learning},
}
