
@phdthesis{hwangboSimulationRealWorld2018,
	type = {Doctoral {Thesis}},
	title = {Simulation to {Real} {World}: {Learn} to {Control} {Legged} {Robots}},
	copyright = {http://rightsstatements.org/page/InC-NC/1.0/},
	shorttitle = {Simulation to {Real} {World}},
	url = {https://www.research-collection.ethz.ch/handle/20.500.11850/326129},
	abstract = {This thesis addresses both control and design aspects of legged robots. Regarding control, I propose two learning-based control approaches that make a legged robot run faster, more energy-efficiently, and more robustly than ever before. This is possible thanks to an effective modeling technique and a simulation tool, both of which are developed in this thesis. Furthermore, the proposed approaches significantly reduce the laborious process of controller design, which hinders the practicality of prior methods. Only by defining a cost function and initialization/termination strategies, natural behaviors that are realizable on the robot arise. Regarding design, I propose a cable-pulley-based efficient transmission concept which is realized as a single-legged hopping system. The constructed system exhibits remarkable efficiency and power while having a simple structure. Although these two contributions seem disconnected, they cannot be addressed separately. Both control and design aspects of robotics should complement each other to create a great legged machine. A great control algorithm exploits the dynamics of the hardware, and well-designed hardware accounts for the characteristics of existing control approaches.  Prior control approaches for controlling legged systems are highly tailored for a specific task; as a result, a complex control architecture has to be designed for every new task. Such arduous workflow and the complexity have deterred the advancement of legged robotics. This is the primary issue that this thesis addresses with new learning-based control approaches.  Reinforcement learning approaches promote a natural discovery of behaviors through a high-level cost function, unlike the prior approaches that hand-code each behavior. However, they have limited success on real robots due to their extensive data requirements. With the approach proposed in this thesis, a policy trained in a simulated environment can be seamlessly transferred to a real robotic system. Consequently, a development process of a control policy can be automated. The enormous complexity of control algorithms is now managed by a parameterized function -- a deep neural network -- relieving humans from the cognitive labor.  The proposed approaches are also uncompromising in performance: a sampling-based search can often find an effective solution near the global optimum even in some highly non-convex problems. The resulting behavior is thus highly performant with respect to the cost function. In addition, the training is performed using a very detailed physics model of the system, whereas many of the prior control methods are based on highly approximated models. Consequently, the performance of the proposed approaches on the real robot is likely to be higher.  As the core of the proposed approaches for control relied heavily on simulation, they can be greatly aided by a high-performance physics simulator. With a new novel numerical optimization scheme, a rigid-body simulator was developed in this thesis. The simulator solves a rigid-body contact problem faster, more stably, and more accurately compared to previous approaches. This simulator ensures the computational practicality and the transferability of the proposed control approaches.  One of the proposed approaches for control was tested on ANYmal, a dog-sized versatile quadrupedal robot. Without any modification, tuning or filtering, the trained policies manifest highly agile and complex behaviors: ANYmal precisely follows random combinations of command velocities, balances under high external perturbations, runs faster than ever before, and recovers itself from a fall. This proves the effectiveness of the proposed approaches for simulation and control, respectively.  This thesis also introduces an ambitious new legged robotic platform: Capler-Leg. Capler-Leg is equipped with nearly frictionless cable-driven transmission systems, thereby increasing the energy efficiency and the power output. Through comprehensive evaluations, I observed unmatched results. A robot that weighs only about 4 kg outputs more than 4 kW of instantaneous power, while recuperating more than 97 \% of kinematic energy back to the battery. It is a promising approach for constructing high performance legged robots.  The contributions of this thesis are key technologies for advancing legged robotics. It is my firm belief that further efforts in the outlined directions will soon make legged robots meaningfully aid humans in multiple domains.},
	language = {en},
	urldate = {2023-04-26},
	school = {ETH Zurich},
	author = {Hwangbo, Je Min},
	year = {2018},
	doi = {10.3929/ethz-b-000326129},
	note = {Accepted: 2020-04-01T08:06:46Z},
	keywords = {/unread},
}

@article{songEnergyConsumptionAuditing2023,
	title = {Energy consumption auditing based on a generative adversarial network for anomaly detection of robotic manipulators},
	volume = {149},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X2300287X},
	doi = {10.1016/j.future.2023.07.034},
	abstract = {This paper presents a generative adversarial network (GAN)-based energy auditing and anomaly detection framework for the health and security monitoring of robotic manipulators. The system features two key components: a side-channel measurement of the energy consumption and a GAN model to learn the data patterns during normal operations only. Anomalies in energy consumption during online testing are then discovered as outliers to the normal data by scrutinizing the anomaly score produced by the discriminator of the GAN model. This semi-supervised network circumvents the need for vast data labeling and exploits the overfitting during the training stage, hence magnifying the difference between the normal patterns learned in training and the unobserved abnormal energy profiles in testing. Moreover, considering the physical aspects of the robotic manipulator, a modified GAN architecture containing multiple discriminators to account for distinct contributions from individual joints/motors. A dynamic thresholding approach that continuously updates the statistical characteristics of the anomaly score is also developed to detect outliers and mitigate the effect of environmental variations during system operation. The proposed framework is tested on the custom dataset for performance evaluation. The results demonstrate the feasibility of the proposed method, especially for detecting physical attacks, which achieves an accuracy of approximately 0.93 in instant-level detection and over 0.84 in event-level detection.},
	language = {en},
	urldate = {2023-08-13},
	journal = {Future Generation Computer Systems},
	author = {Song, Ge and Hong, Seong Hyeon and Kyzer, Tristan and Wang, Yi},
	month = dec,
	year = {2023},
	keywords = {/unread, Anomaly detection, Cyber–physical attack, Energy auditing, Generative adversarial network, Robotic manipulator, Side-channel mechanism},
	pages = {376--389},
}

@misc{liptonCriticalReviewRecurrent2015,
	title = {A {Critical} {Review} of {Recurrent} {Neural} {Networks} for {Sequence} {Learning}},
	url = {http://arxiv.org/abs/1506.00019},
	doi = {10.48550/arXiv.1506.00019},
	abstract = {Countless learning tasks require dealing with sequential data. Image captioning, speech synthesis, and music generation all require that a model produce outputs that are sequences. In other domains, such as time series prediction, video analysis, and musical information retrieval, a model must learn from inputs that are sequences. Interactive tasks, such as translating natural language, engaging in dialogue, and controlling a robot, often demand both capabilities. Recurrent neural networks (RNNs) are connectionist models that capture the dynamics of sequences via cycles in the network of nodes. Unlike standard feedforward neural networks, recurrent networks retain a state that can represent information from an arbitrarily long context window. Although recurrent neural networks have traditionally been difficult to train, and often contain millions of parameters, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful large-scale learning with them. In recent years, systems based on long short-term memory (LSTM) and bidirectional (BRNN) architectures have demonstrated ground-breaking performance on tasks as varied as image captioning, language translation, and handwriting recognition. In this survey, we review and synthesize the research that over the past three decades first yielded and then made practical these powerful learning models. When appropriate, we reconcile conflicting notation and nomenclature. Our goal is to provide a self-contained explication of the state of the art together with a historical perspective and references to primary research.},
	urldate = {2023-08-13},
	publisher = {arXiv},
	author = {Lipton, Zachary C. and Berkowitz, John and Elkan, Charles},
	month = oct,
	year = {2015},
	note = {arXiv:1506.00019 [cs]},
	keywords = {/unread, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{albawiUnderstandingConvolutionalNeural2017,
	title = {Understanding of a convolutional neural network},
	doi = {10.1109/ICEngTechnol.2017.8308186},
	abstract = {The term Deep Learning or Deep Neural Network refers to Artificial Neural Networks (ANN) with multi layers. Over the last few decades, it has been considered to be one of the most powerful tools, and has become very popular in the literature as it is able to handle a huge amount of data. The interest in having deeper hidden layers has recently begun to surpass classical methods performance in different fields; especially in pattern recognition. One of the most popular deep neural networks is the Convolutional Neural Network (CNN). It take this name from mathematical linear operation between matrixes called convolution. CNN have multiple layers; including convolutional layer, non-linearity layer, pooling layer and fully-connected layer. The convolutional and fully-connected layers have parameters but pooling and non-linearity layers don't have parameters. The CNN has an excellent performance in machine learning problems. Specially the applications that deal with image data, such as largest image classification data set (Image Net), computer vision, and in natural language processing (NLP) and the results achieved were very amazing. In this paper we will explain and define all the elements and important issues related to CNN, and how these elements work. In addition, we will also state the parameters that effect CNN efficiency. This paper assumes that the readers have adequate knowledge about both machine learning and artificial neural network.},
	booktitle = {2017 {International} {Conference} on {Engineering} and {Technology} ({ICET})},
	author = {Albawi, Saad and Mohammed, Tareq Abed and Al-Zawi, Saad},
	month = aug,
	year = {2017},
	keywords = {/unread, Convolution, Convolutional neural networks, Feature extraction, Image edge detection, Image recognition, Neurons, artificial neural networks, computer vision, convolutional neural networks, deep learning, machine learning},
	pages = {1--6},
}

@article{hopfieldNeuralNetworksPhysical1982,
	title = {Neural networks and physical systems with emergent collective computational abilities.},
	volume = {79},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.79.8.2554},
	doi = {10.1073/pnas.79.8.2554},
	abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
	number = {8},
	urldate = {2023-08-13},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Hopfield, J J},
	month = apr,
	year = {1982},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	keywords = {/unread},
	pages = {2554--2558},
}

@article{chenElectrochemicalMemristorBasedArtificialNeurons,
	title = {Electrochemical-{Memristor}-{Based} {Artificial} {Neurons} and {Synapses}—{Fundamentals}, {Applications}, and {Challenges}},
	volume = {n/a},
	copyright = {© 2023 The Authors. Advanced Materials published by Wiley-VCH GmbH},
	issn = {1521-4095},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/adma.202301924},
	doi = {10.1002/adma.202301924},
	abstract = {Artificial neurons and synapses are considered essential for the progress of the future brain-inspired computing, based on beyond von Neumann architectures. Here, a discussion on the common electrochemical fundamentals of biological and artificial cells is provided, focusing on their similarities with the redox-based memristive devices. The driving forces behind the functionalities and the ways to control them by an electrochemical-materials approach are presented. Factors such as the chemical symmetry of the electrodes, doping of the solid electrolyte, concentration gradients, and excess surface energy are discussed as essential to understand, predict, and design artificial neurons and synapses. A variety of two- and three-terminal memristive devices and memristive architectures are presented and their application for solving various problems is shown. The work provides an overview of the current understandings on the complex processes of neural signal generation and transmission in both biological and artificial cells and presents the state-of-the-art applications, including signal transmission between biological and artificial cells. This example is showcasing the possibility for creating bioelectronic interfaces and integrating artificial circuits in biological systems. Prospectives and challenges of the modern technology toward low-power, high-information-density circuits are highlighted.},
	language = {en},
	number = {n/a},
	urldate = {2023-08-13},
	journal = {Advanced Materials},
	author = {Chen, Shaochuan and Zhang, Teng and Tappertzhofen, Stefan and Yang, Yuchao and Valov, Ilia},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/adma.202301924},
	keywords = {/unread, artificial neurons and synapses, brain-inspired computing, memristors, nanoionics},
	pages = {2301924},
}

@incollection{zouOverviewArtificialNeural2009,
	address = {Totowa, NJ},
	series = {Methods in {Molecular} {Biology}™},
	title = {Overview of {Artificial} {Neural} {Networks}},
	isbn = {978-1-60327-101-1},
	url = {https://doi.org/10.1007/978-1-60327-101-1_2},
	abstract = {The artificial neural network (ANN), or simply neural network, is a machine learning method evolved from the idea of simulating the human brain. The data explosion in modern drug discovery research requires sophisticated analysis methods to uncover the hidden causal relationships between single or multiple responses and a large set of properties. The ANN is one of many versatile tools to meet the demand in drug discovery modeling. Compared to a traditional regression approach, the ANN is capable of modeling complex nonlinear relationships. The ANN also has excellent fault tolerance and is fast and highly scalable with parallel processing. This chapter introduces the background of ANN development and outlines the basic concepts crucially important for understanding more sophisticated ANN. Several commonly used learning methods and network setups are discussed briefly at the end of the chapter.},
	language = {en},
	urldate = {2023-08-13},
	booktitle = {Artificial {Neural} {Networks}: {Methods} and {Applications}},
	publisher = {Humana Press},
	author = {Zou, Jinming and Han, Yi and So, Sung-Sau},
	editor = {Livingstone, David J.},
	year = {2009},
	doi = {10.1007/978-1-60327-101-1_2},
	keywords = {/unread, Hopfield network, Kohonen network, Transfer function, perceptron, supervised learning, unsupervised learning},
	pages = {14--22},
}

@incollection{zhangIntroductionArtificialNeural2000,
	address = {Boston, MA},
	series = {Nonconvex {Optimization} and {Its} {Applications}},
	title = {Introduction to {Artificial} {Neural} {Network}},
	isbn = {978-1-4757-3167-5},
	url = {https://doi.org/10.1007/978-1-4757-3167-5_5},
	abstract = {Artificial neural networks or simply “neural nets” go by many names such as connectionist models, parallel distributed processing models, and neuromorphic systems. Whatever terminology it may be, they all attempt to borrow the structure and running way of the biological nervous system based on our present understanding of it. Instead of performing a program consisting of instructions sequentially as in a von Neumann computer, artificial neural nets have their structures in dense interconnection of simple computational elements— the artificial neurons or simply “neurons”, and operate the massive computational elements in parallel to achieve high performance speed.},
	language = {en},
	urldate = {2023-08-13},
	booktitle = {Neural {Networks} in {Optimization}},
	publisher = {Springer US},
	author = {Zhang, Xiang-Sun},
	editor = {Zhang, Xiang-Sun},
	year = {2000},
	doi = {10.1007/978-1-4757-3167-5_5},
	keywords = {/unread},
	pages = {83--93},
}

@article{choiLearningQuadrupedalLocomotion2023,
	title = {Learning quadrupedal locomotion on deformable terrain},
	volume = {8},
	url = {https://www.science.org/doi/abs/10.1126/scirobotics.ade2256},
	doi = {10.1126/scirobotics.ade2256},
	abstract = {Simulation-based reinforcement learning approaches are leading the next innovations in legged robot control. However, the resulting control policies are still not applicable on soft and deformable terrains, especially at high speed. The primary reason is that reinforcement learning approaches, in general, are not effective beyond the data distribution: The agent cannot perform well in environments that it has not experienced. To this end, we introduce a versatile and computationally efficient granular media model for reinforcement learning. Our model can be parameterized to represent diverse types of terrain from very soft beach sand to hard asphalt. In addition, we introduce an adaptive control architecture that can implicitly identify the terrain properties as the robot feels the terrain. The identified parameters are then used to boost the locomotion performance of the legged robot. We applied our techniques to the Raibo robot, a dynamic quadrupedal robot developed in-house. The trained networks demonstrated high-speed locomotion capabilities on deformable terrains: The robot was able to run on soft beach sand at 3.03 meters per second although the feet were completely buried in the sand during the stance phase. We also demonstrate its ability to generalize to different terrains by presenting running experiments on vinyl tile flooring, athletic track, grass, and a soft air mattress.},
	number = {74},
	urldate = {2023-08-13},
	journal = {Science Robotics},
	author = {Choi, Suyoung and Ji, Gwanghyeon and Park, Jeongsoo and Kim, Hyeongjun and Mun, Juhyeok and Lee, Jeong Hyun and Hwangbo, Jemin},
	month = jan,
	year = {2023},
	note = {Publisher: American Association for the Advancement of Science},
	keywords = {/unread},
	pages = {eade2256},
}

@inproceedings{leeQuadrupedRobotObstacle2006,
	title = {Quadruped robot obstacle negotiation via reinforcement learning},
	doi = {10.1109/ROBOT.2006.1642158},
	abstract = {Legged robots can, in principle, traverse a large variety of obstacles and terrains. In this paper, we describe a successful application of reinforcement learning to the problem of negotiating obstacles with a quadruped robot. Our algorithm is based on a two-level hierarchical decomposition of the task, in which the high-level controller selects the sequence of foot-placement positions, and the low-level controller generates the continuous motions to move each foot to the specified positions. The high-level controller uses an estimate of the value function to guide its search; this estimate is learned partially from supervised data. The low-level controller is obtained via policy search. We demonstrate that our robot can successfully climb over a variety of obstacles which were not seen at training time},
	booktitle = {Proceedings 2006 {IEEE} {International} {Conference} on {Robotics} and {Automation}, 2006. {ICRA} 2006.},
	author = {Lee, Honglak and Shen, Yirong and Yu, Chih-Han and Singh, G. and Ng, A.Y.},
	month = may,
	year = {2006},
	note = {ISSN: 1050-4729},
	keywords = {/unread, Computer science, Foot, Learning, Leg, Legged locomotion, Mobile robots, Motion control, Path planning, Robot kinematics, Robotics and automation},
	pages = {3003--3010},
}

@inproceedings{wangHierarchicalGaitGeneration2021,
	title = {Hierarchical {Gait} {Generation} for {Modular} {Robots} {Using} {Deep} {Reinforcement} {Learning}},
	doi = {10.1109/ICM46511.2021.9385659},
	abstract = {Modular robots have the ability to perform versatile locomotion with a high diversity of morphologies. However, designing robust locomotion gaits for arbitrary robot morphologies remains exceptionally challenging. In this paper, a two-level hierarchical locomotion framework is presented for addressing modular robot locomotion tasks. The framework combines a central pattern generator controller (CPG) with a neural network trained by deep reinforcement learning. First, the low-level CPG controllers are learned by offline optimization and generate robust straight walking gaits. Second, a high-level neural network is then learned using deep reinforcement learning via trial-and-errors. The high-level learned controller can modulate the low-level CPG parameters based on online inputs including robot states and user commands. Simulation experiments are employed on a 3D modular robot. The results show that the proposed method achieves better overall performance than the baseline methods on different locomotion skills including straight walking, velocity tracking, and circular turning. Simulation results confirm the effectiveness and robustness of the proposed method.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Mechatronics} ({ICM})},
	author = {Wang, Jiayu and Hu, Chuxiong and Zhu, Yu},
	month = mar,
	year = {2021},
	keywords = {/unread, Legged locomotion, Morphology, Neural networks, Reinforcement learning, Robots, Robustness, Task analysis, central pattern generator, locomotion control, modular robot},
	pages = {1--6},
}

@article{nakamuraReinforcementLearningBiped2007,
	title = {Reinforcement learning for a biped robot based on a {CPG}-actor-critic method},
	volume = {20},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S089360800700024X},
	doi = {10.1016/j.neunet.2007.01.002},
	abstract = {Animals’ rhythmic movements, such as locomotion, are considered to be controlled by neural circuits called central pattern generators (CPGs), which generate oscillatory signals. Motivated by this biological mechanism, studies have been conducted on the rhythmic movements controlled by CPG. As an autonomous learning framework for a CPG controller, we propose in this article a reinforcement learning method we call the “CPG-actor-critic” method. This method introduces a new architecture to the actor, and its training is roughly based on a stochastic policy gradient algorithm presented recently. We apply this method to an automatic acquisition problem of control for a biped robot. Computer simulations show that training of the CPG can be successfully performed by our method, thus allowing the biped robot to not only walk stably but also adapt to environmental changes.},
	language = {en},
	number = {6},
	urldate = {2023-08-13},
	journal = {Neural Networks},
	author = {Nakamura, Yutaka and Mori, Takeshi and Sato, Masa-aki and Ishii, Shin},
	month = aug,
	year = {2007},
	keywords = {/unread, Actor-critic model, Biped walking, Central pattern generator, Policy gradient method, Reinforcement learning},
	pages = {723--735},
}

@article{whiteheadLearningPerceiveAct1991,
	title = {Learning to perceive and act by trial and error},
	volume = {7},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/BF00058926},
	doi = {10.1007/BF00058926},
	abstract = {This article considers adaptive control architectures that integrate active sensory-motor systems with decision systems based on reinforcement learning. One unavoidable consequence of active perception is that the agent's internal representation often confounds external world states. We call this phoenomenon Perceptual aliasing and show that it destabilizes existing reinforcement learning algorithms with respect to the optimal decision policy. We then describe a new decision system that overcomes these difficulties for a restricted class of decision problems. The system incorporates a perceptual subcycle within the overall decision cycle and uses a modified learning algorithm to suppress the effects of perceptual aliasing. The result is a control architecture that learns not only how to solve a task but also where to focus its visual attention in order to collect necessary sensory information.},
	language = {en},
	number = {1},
	urldate = {2023-08-13},
	journal = {Machine Learning},
	author = {Whitehead, Steven D. and Ballard, Dana H.},
	month = jul,
	year = {1991},
	keywords = {/unread, Reinforcement learning, deictic representations, hidden state, non-Markov decision problems, sensory-motor integration},
	pages = {45--83},
}

@article{gongReviewGaitOptimization2010,
	title = {A {Review} of {Gait} {Optimization} {Based} on {Evolutionary} {Computation}},
	volume = {2010},
	issn = {1687-9724},
	url = {https://www.hindawi.com/journals/acisc/2010/413179/},
	doi = {10.1155/2010/413179},
	abstract = {Gait generation is very important as it directly affects the quality of locomotion of legged robots. As this is an optimization problem with constraints, it readily lends itself to Evolutionary Computation methods and solutions. This paper reviews the techniques used in evolution-based gait optimization, including why Evolutionary Computation techniques should be used, how fitness functions should be composed, and the selection of genetic operators and control parameters. This paper also addresses further possible improvements in the efficiency and quality of evolutionary gait optimization, some problems that have not yet been resolved and the perspectives for related future research.},
	language = {en},
	urldate = {2023-08-13},
	journal = {Applied Computational Intelligence and Soft Computing},
	author = {Gong, Daoxiong and Yan, Jie and Zuo, Guoyu},
	month = jun,
	year = {2010},
	note = {Publisher: Hindawi},
	keywords = {/unread},
	pages = {e413179},
}

@article{gehringPracticeMakesPerfect2016,
	title = {Practice {Makes} {Perfect}: {An} {Optimization}-{Based} {Approach} to {Controlling} {Agile} {Motions} for a {Quadruped} {Robot}},
	volume = {23},
	issn = {1558-223X},
	shorttitle = {Practice {Makes} {Perfect}},
	doi = {10.1109/MRA.2015.2505910},
	abstract = {This article approaches the problem of controlling quadrupedal running and jumping motions with a parameterized, model-based, state-feedback controller. Inspired by the motor learning principles observed in nature, our method automatically fine tunes the parameters of our controller by repeatedly executing slight variations of the same motion task. This learn-through-practice process is performed in simulation to best exploit computational resources and to prevent the robot from damaging itself. To ensure that the simulation results match the behavior of the hardware platform, we introduce and validate an accurate model of the compliant actuation system. The proposed method is experimentally verified on the torque-controllable quadruped robot StarlETH by executing squat jumps and dynamic gaits, such as a running trot, pronk, and a bounding gait.},
	number = {1},
	journal = {IEEE Robotics \& Automation Magazine},
	author = {Gehring, Christian and Coros, Stelian and Hutter, Marco and Dario Bellicoso, Carmine and Heijnen, Huub and Diethelm, Remo and Bloesch, Michael and Fankhauser, Peter and Hwangbo, Jemin and Hoepflinger, Mark and Siegwart, Roland},
	month = mar,
	year = {2016},
	note = {Conference Name: IEEE Robotics \& Automation Magazine},
	keywords = {/unread, Actuators, Dynamics, Legged locomotion, Motion control, Robot kinematics},
	pages = {34--43},
}

@inproceedings{daiWholebodyMotionPlanning2014,
	title = {Whole-body motion planning with centroidal dynamics and full kinematics},
	doi = {10.1109/HUMANOIDS.2014.7041375},
	abstract = {To plan dynamic, whole-body motions for robots, one conventionally faces the choice between a complex, full-body dynamic model containing every link and actuator of the robot, or a highly simplified model of the robot as a point mass. In this paper we explore a powerful middle ground between these extremes. We exploit the fact that while the full dynamics of humanoid robots are complicated, their centroidal dynamics (the evolution of the angular momentum and the center of mass (COM) position) are much simpler. By treating the dynamics of the robot in centroidal form and directly optimizing the joint trajectories for the actuated degrees of freedom, we arrive at a method that enjoys simpler dynamics, while still having the expressiveness required to handle kinematic constraints such as collision avoidance or reaching to a target. We further require that the robot's COM and angular momentum as computed from the joint trajectories match those given by the centroidal dynamics. This ensures that the dynamics considered by our optimization are equivalent to the full dynamics of the robot, provided that the robot's actuators can supply sufficient torque. We demonstrate that this algorithm is capable of generating highly-dynamic motion plans with examples of a humanoid robot negotiating obstacle course elements and gait optimization for a quadrupedal robot. Additionally, we show that we can plan without pre-specifying the contact sequence by exploiting the complementarity conditions between contact forces and contact distance.},
	booktitle = {2014 {IEEE}-{RAS} {International} {Conference} on {Humanoid} {Robots}},
	author = {Dai, Hongkai and Valenzuela, Andrés and Tedrake, Russ},
	month = nov,
	year = {2014},
	note = {ISSN: 2164-0580},
	keywords = {/unread, Collision avoidance, Dynamics, Joints, Kinematics, Optimization, Robots, Trajectory},
	pages = {295--302},
}

@article{koldaOptimizationDirectSearch2003,
	title = {Optimization by {Direct} {Search}: {New} {Perspectives} on {Some} {Classical} and {Modern} {Methods}},
	volume = {45},
	issn = {0036-1445},
	shorttitle = {Optimization by {Direct} {Search}},
	url = {https://epubs.siam.org/doi/abs/10.1137/S003614450242889},
	doi = {10.1137/S003614450242889},
	abstract = {This paper addresses the problem of minimization of a nonsmooth function under general nonsmooth constraints when no derivatives of the objective or constraint functions are available. We introduce the mesh adaptive direct search (MADS) class of algorithms which extends the generalized pattern search (GPS) class by allowing local exploration, called polling, in an asymptotically dense set of directions in the space of optimization variables. This means that under certain hypotheses, including a weak constraint qualification due to Rockafellar, MADS can treat constraints by the extreme barrier approach of setting the objective to infinity for infeasible points and treating the problem as unconstrained.The main GPS convergence result is to identify limit points \${\textbackslash}hat\{x\}\$, where the Clarke generalized derivatives are nonnegative in a finite set of directions, called refining directions. Although in the unconstrained case, nonnegative combinations of these directions span the whole space, the fact that there can only be finitely many GPS refining directions limits rigorous justification of the barrier approach to finitely many linear constraints for GPS. The main result of this paper is that the general MADS framework is flexible enough to allow the generation of an asymptotically dense set of refining directions along which the Clarke derivatives are nonnegative. We propose an instance of MADS for which the refining directions are dense in the hypertangent cone at \${\textbackslash}hat\{x\}\$ with probability 1 whenever the iterates associated with the refining directions converge to a single \${\textbackslash}hat\{x\}\$. The instance of MADS is compared to versions of GPS on some test problems. We also illustrate the limitation of our results with examples.An erratum to this article has been appended at the end of the pdf file.},
	number = {3},
	urldate = {2023-08-13},
	journal = {SIAM Review},
	author = {Kolda, Tamara G. and Lewis, Robert Michael and Torczon, Virginia},
	month = jan,
	year = {2003},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	keywords = {/unread},
	pages = {385--482},
}

@misc{haarnojaSoftActorCriticAlgorithms2019,
	title = {Soft {Actor}-{Critic} {Algorithms} and {Applications}},
	url = {http://arxiv.org/abs/1812.05905},
	abstract = {Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.},
	urldate = {2023-06-15},
	publisher = {arXiv},
	author = {Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
	month = jan,
	year = {2019},
	note = {arXiv:1812.05905 [cs, stat]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
}

@article{zhangUnderstandingDeepLearning2021,
	title = {Understanding deep learning (still) requires rethinking generalization},
	volume = {64},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/3446776},
	doi = {10.1145/3446776},
	abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small gap between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models. We supplement this republication with a new section at the end summarizing recent progresses in the field since the original version of this paper.},
	number = {3},
	urldate = {2023-08-13},
	journal = {Communications of the ACM},
	author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	year = {2021},
	keywords = {/unread},
	pages = {107--115},
}

@article{jiSynthesizingOptimalGait2022,
	title = {Synthesizing the optimal gait of a quadruped robot with soft actuators using deep reinforcement learning},
	volume = {78},
	issn = {0736-5845},
	url = {https://www.sciencedirect.com/science/article/pii/S0736584522000692},
	doi = {10.1016/j.rcim.2022.102382},
	abstract = {Quadruped robots have the advantages of traversing complex terrains that are difficult for wheeled robots. Most of the reported quadruped robots are built by rigid parts. This paper proposes a new design of quadruped robots using soft actuators driven by tendons as the four legs. Compared to the rigid robots, the proposed soft quadruped robot has inherent safety, less weight and simpler mechanism for fabrication and control, but the corresponding challenge is that the accurate mathematical model applicable to model-based control design of the soft robot is difficult to derive by dynamics. To synthesize the optimal gait controller of the soft-legged robot, the paper makes the following contributions. First, the flexible components of the quadruped robot are modeled with different finite element and lumped parameter methods. The model accuracy and computation efficiency are analyzed. Second, soft actor–critic methods and curriculum learning are applied to learn the optimal gaits for different walking tasks. Third, The learned gaits are implemented in an in-house robot to transport hand tools. Preliminary results show that the robot can walk forward and correct the walking directions.},
	language = {en},
	urldate = {2022-10-14},
	journal = {Robotics and Computer-Integrated Manufacturing},
	author = {Ji, Qinglei and Fu, Shuo and Tan, Kaige and Thorapalli Muralidharan, Seshagopalan and Lagrelius, Karin and Danelia, David and Andrikopoulos, Georgios and Wang, Xi Vincent and Wang, Lihui and Feng, Lei},
	month = dec,
	year = {2022},
	note = {4 citations (Semantic Scholar/DOI) [2023-04-11]
2 citations (Crossref) [2022-12-07]},
	keywords = {/unread, Motion control, Quadruped robot, Reinforcement learning, Robot gait, Soft actuators, Tendon-driven motion},
	pages = {102382},
}

@inproceedings{jiOmnidirectionalWalkingQuadruped2022,
	title = {Omnidirectional walking of a quadruped robot enabled by compressible tendon-driven soft actuators},
	doi = {10.1109/IROS47612.2022.9981314},
	abstract = {Using soft actuators as legs, soft quadruped robots have shown great potential in traversing unstructured and complex terrains and environments. However, unlike rigid robots whose gaits can be generated using foot pattern design and kinematic model of the rigid legs, the gait generation of soft quadruped robots remains challenging due to the high DoFs of the soft actuators and the uncertain deformations during their contact with the ground. This study is based on a quadruped robot using four Compressible Tendon-driven Soft Actuators (CTSAs) as the legs, with the actuator's compression motion being utilized to improve the walking performance of the robot. For the gait design, an inverse kinematics model considering the compression of the CTSA is developed and validated in simulation. Based on this model, walking gaits realizing different motion speeds and directions are generated. Closed loop direction and speed controllers are developed for increasing the robustness and precision of the robot walking. Simulation and experimental results show that omnidirectional locomotion and complex walking tasks can be realized by tuning the gait parameters and the motions are resistant to external disturbances.},
	booktitle = {2022 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Ji, Qinglei and Fu, Shuo and Feng, Lei and Andrikopoulos, George and Wang, Xi Vincent and Wang, Lihui},
	month = oct,
	year = {2022},
	note = {0 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2153-0866},
	keywords = {/unread, Actuators, Control and Learning for Soft Robots, Kinematics, Legged locomotion, Modeling, Motion Control, Quadrupedal robots, Robot sensing systems, Soft Sensors and Actuators, Ten-don/Wire Mechanism, Trajectory, Turning},
	pages = {11015--11022},
}

@article{lewisReinforcementLearningFeedback2012,
	title = {Reinforcement {Learning} and {Feedback} {Control}: {Using} {Natural} {Decision} {Methods} to {Design} {Optimal} {Adaptive} {Controllers}},
	volume = {32},
	issn = {1941-000X},
	shorttitle = {Reinforcement {Learning} and {Feedback} {Control}},
	doi = {10.1109/MCS.2012.2214134},
	abstract = {This article describes the use of principles of reinforcement learning to design feedback controllers for discrete- and continuous-time dynamical systems that combine features of adaptive control and optimal control. Adaptive control [1], [2] and optimal control [3] represent different philosophies for designing feedback controllers. Optimal controllers are normally designed of ine by solving Hamilton JacobiBellman (HJB) equations, for example, the Riccati equation, using complete knowledge of the system dynamics. Determining optimal control policies for nonlinear systems requires the offline solution of nonlinear HJB equations, which are often difficult or impossible to solve. By contrast, adaptive controllers learn online to control unknown systems using data measured in real time along the system trajectories. Adaptive controllers are not usually designed to be optimal in the sense of minimizing user-prescribed performance functions. Indirect adaptive controllers use system identification techniques to first identify the system parameters and then use the obtained model to solve optimal design equations [1]. Adaptive controllers may satisfy certain inverse optimality conditions [4].},
	number = {6},
	journal = {IEEE Control Systems Magazine},
	author = {Lewis, Frank L. and Vrabie, Draguna and Vamvoudakis, Kyriakos G.},
	month = dec,
	year = {2012},
	note = {Conference Name: IEEE Control Systems Magazine},
	keywords = {/unread, Adaptive control, Decision making, Design methodology, Feedback control, Learning systems, Optimal control, Reinforcement learning},
	pages = {76--105},
}

@article{poulakakisSpringLoadedInverted2009,
	title = {The {Spring} {Loaded} {Inverted} {Pendulum} as the {Hybrid} {Zero} {Dynamics} of an {Asymmetric} {Hopper}},
	volume = {54},
	issn = {1558-2523},
	doi = {10.1109/TAC.2009.2024565},
	abstract = {A hybrid controller that induces provably stable running gaits on an asymmetric spring loaded inverted pendulum (ASLIP) is developed. The controller acts on two levels. On the first level, continuous within-stride control asymptotically imposes a (virtual) holonomic constraint corresponding to a desired torso posture, and creates an invariant surface on which the two-degree-of-freedom restriction dynamics of the closed-loop system (i.e., the hybrid zero dynamics) is diffeomorphic to the center-of-mass dynamics of a spring loaded inverted pendulum (SLIP). On the second level, event-based control stabilizes the closed-loop hybrid system along a periodic orbit of the SLIP dynamics. The controller's performance is discussed through comparison with a second control law that creates a one-degree-of-freedom non-compliant hybrid zero dynamics. Both controllers induce identical steady-state behaviors (i.e., periodic solutions). Under transient conditions, however, the controller inducing a compliant hybrid zero dynamics based on the SLIP accommodates significantly larger disturbances, with less actuator effort, and without violation of the unilateral ground force constraints.},
	number = {8},
	journal = {IEEE Transactions on Automatic Control},
	author = {Poulakakis, Ioannis and Grizzle, Jessy W.},
	month = aug,
	year = {2009},
	note = {Conference Name: IEEE Transactions on Automatic Control},
	keywords = {/unread, Actuators, Animals, Context modeling, Control systems, Dynamic running, Hybrid Zero Dynamics (HZD), Leg, Motion control, Predictive models, Robot kinematics, Spring Loaded Inverted Pendulum (SLIP), Springs, Torso, legged robots},
	pages = {1779--1793},
}

@article{chenImplementationOmnidirectionalCrawl2001,
	title = {Implementation of omnidirectional crawl for a quadruped robot},
	volume = {15},
	issn = {0169-1864},
	url = {https://doi.org/10.1163/15685530152116218},
	doi = {10.1163/15685530152116218},
	abstract = {As a reptile animal crawls in a cluttered environment, so a quadruped robot should be able to crawl on an irregular ground profile with its static stability by adopting the straightgoing and standstill-turning free gaits. The generalized and explicit formulations for the automatic generation of straight-going gaits and various standstill-turning gaits are presented in this paper. The maximized stride for the straight-going gait and the maximum turning angle for the turning gait of a quadruped robot named TITAN-VIII in a gait cycle are discussed by considering the robot's mechanism constraints and the irregularities of the ground profile. The control algorithm, including control of the joint positions of the robot, is described to implement the desired walking path of the quadruped robot. The effectiveness of the proposed method is demonstrated through experimental result.},
	number = {2},
	urldate = {2023-07-08},
	journal = {Advanced Robotics},
	author = {Chen, Xuedong and Watanabe, Keigo and Kiguchi, Kazuo and Izumi, Kiyotaka},
	month = jan,
	year = {2001},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1163/15685530152116218},
	keywords = {/unread, GAIT CONTROL, GAIT GENERATION, OMNIDIRECTIONAL CRAWL, QUADRUPED ROBOT, STANDSTILL-TURNING GAIT, STRAIGHT-GOING GAIT},
	pages = {169--190},
}

@article{jiConcurrentTrainingControl2022,
	title = {Concurrent {Training} of a {Control} {Policy} and a {State} {Estimator} for {Dynamic} and {Robust} {Legged} {Locomotion}},
	volume = {7},
	issn = {2377-3766},
	doi = {10.1109/LRA.2022.3151396},
	abstract = {In this letter, we propose a locomotion training framework where a control policy and a state estimator are trained concurrently. The framework consists of a policy network which outputs the desired joint positions and a state estimation network which outputs estimates of the robot’s states such as the base linear velocity, foot height, and contact probability. We exploit a fast simulation environment to train the networks and the trained networks are transferred to the real robot. The trained policy and state estimator are capable of traversing diverse terrains such as a hill, slippery plate, and bumpy road. We also demonstrate that the learned policy can run at up to 3.75 m/s on normal flat ground and 3.54 m/s on a slippery plate with the coefficient of friction of 0.22.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Ji, Gwanghyeon and Mun, Juhyeok and Kim, Hyeongjun and Hwangbo, Jemin},
	month = apr,
	year = {2022},
	note = {Conference Name: IEEE Robotics and Automation Letters},
	keywords = {/unread, History, Legged locomotion, Legged robots, Neural networks, Quadrupedal robots, Robots, Sensors, Training, reinforcement learning},
	pages = {4630--4637},
}

@article{sprowitzDynamicTrotGait2013,
	title = {Towards dynamic trot gait locomotion: {Design}, control, and experiments with {Cheetah}-cub, a compliant quadruped robot},
	volume = {32},
	issn = {0278-3649},
	shorttitle = {Towards dynamic trot gait locomotion},
	url = {https://doi.org/10.1177/0278364913489205},
	doi = {10.1177/0278364913489205},
	abstract = {We present the design of a novel compliant quadruped robot, called Cheetah-cub, and a series of locomotion experiments with fast trotting gaits. The robot’s leg configuration is based on a spring-loaded, pantograph mechanism with multiple segments. A dedicated open-loop locomotion controller was derived and implemented. Experiments were run in simulation and in hardware on flat terrain and with a step down, demonstrating the robot’s self-stabilizing properties. The robot reached a running trot with short flight phases with a maximum Froude number of FR = 1.30, or 6.9 body lengths per second. Morphological parameters such as the leg design also played a role. By adding distal in-series elasticity, self-stability and maximum robot speed improved. Our robot has several advantages, especially when compared with larger and stiffer quadruped robot designs. (1) It is, to the best of the authors’ knowledge, the fastest of all quadruped robots below 30kg (in terms of Froude number and body lengths per second). (2) It shows self-stabilizing behavior over a large range of speeds with open-loop control. (3) It is lightweight, compact, and electrically powered. (4) It is cheap, easy to reproduce, robust, and safe to handle. This makes it an excellent tool for research of multi-segment legs in quadruped robots.},
	language = {en},
	number = {8},
	urldate = {2023-07-08},
	journal = {The International Journal of Robotics Research},
	author = {Spröwitz, Alexander and Tuleu, Alexandre and Vespignani, Massimo and Ajallooeian, Mostafa and Badri, Emilie and Ijspeert, Auke Jan},
	month = jul,
	year = {2013},
	note = {Publisher: SAGE Publications Ltd STM},
	keywords = {/unread},
	pages = {932--950},
}

@article{neuhausComprehensiveSummaryInstitute2011,
	title = {Comprehensive summary of the {Institute} for {Human} and {Machine} {Cognition}’s                 experience with {LittleDog}},
	volume = {30},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364910390538},
	doi = {10.1177/0278364910390538},
	abstract = {We discuss the main issues and challenges with quadrupedal locomotion over rough terrain in the context of the Defense Advanced Research Projects Agency’s Learning Locomotion program. We present our controller for the LittleDog platform, which allows for continuous transition between a static crawl gait and a dynamic trot gait depending on the roughness of the terrain. We provide detailed descriptions for some of our key algorithm components, such as a fast footstep planner for rough terrain, a body pose finder for a given support polygon, and a new type of parameterized gait. We present the results of our algorithm, which proved successful in the program, crossing all 10 terrain boards on the final test at an average speed of 11.2 cm/s. We conclude with a discussion on the applicability of this work for platforms other than LittleDog and in environments other than the Learning Locomotion designed tests.},
	language = {en},
	number = {2},
	urldate = {2023-07-11},
	journal = {The International Journal of Robotics Research},
	author = {Neuhaus, Peter D and Pratt, Jerry E and Johnson, Matthew J},
	month = feb,
	year = {2011},
	note = {Publisher: SAGE Publications Ltd STM},
	keywords = {/unread},
	pages = {216--235},
}

@article{liHumanoidsLearningWalk2013,
	title = {Humanoids {Learning} to {Walk}: {A} {Natural} {CPG}-{Actor}-{Critic} {Architecture}},
	volume = {7},
	issn = {1662-5218},
	shorttitle = {Humanoids {Learning} to {Walk}},
	url = {https://www.frontiersin.org/articles/10.3389/fnbot.2013.00005},
	abstract = {The identification of learning mechanisms for locomotion has been the subject of much research for some time but many challenges remain. Dynamic systems theory (DST) offers a novel approach to humanoid learning through environmental interaction. Reinforcement learning (RL) has offered a promising method to adaptively link the dynamic system to the environment it interacts with via a reward-based value system. In this paper, we propose a model that integrates the above perspectives and applies it to the case of a humanoid (NAO) robot learning to walk the ability of which emerges from its value-based interaction with the environment. In the model, a simplified central pattern generator (CPG) architecture inspired by neuroscientific research and DST is integrated with an actor-critic approach to RL (cpg-actor-critic). In the cpg-actor-critic architecture, least-square-temporal-difference based learning converges to the optimal solution quickly by using natural gradient learning and balancing exploration and exploitation. Futhermore, rather than using a traditional (designer-specified) reward it uses a dynamic value function as a stability indicator that adapts to the environment. The results obtained are analyzed using a novel DST-based embodied cognition approach. Learning to walk, from this perspective, is a process of integrating levels of sensorimotor activity and value.},
	urldate = {2023-07-10},
	journal = {Frontiers in Neurorobotics},
	author = {LI, CAI and Lowe, Robert and Ziemke, Tom},
	year = {2013},
	keywords = {/unread},
}

@article{ibarzHowTrainYour2021,
	title = {How to train your robot with deep reinforcement learning: lessons we have learned},
	volume = {40},
	issn = {0278-3649},
	shorttitle = {How to train your robot with deep reinforcement learning},
	url = {https://doi.org/10.1177/0278364920987859},
	doi = {10.1177/0278364920987859},
	abstract = {Deep reinforcement learning (RL) has emerged as a promising approach for autonomously acquiring complex behaviors from low-level sensor observations. Although a large portion of deep RL research has focused on applications in video games and simulated control, which does not connect with the constraints of learning in real environments, deep RL has also demonstrated promise in enabling physical robots to learn complex skills in the real world. At the same time, real-world robotics provides an appealing domain for evaluating such algorithms, as it connects directly to how humans learn: as an embodied agent in the real world. Learning to perceive and move in the real world presents numerous challenges, some of which are easier to address than others, and some of which are often not considered in RL research that focuses only on simulated domains. In this review article, we present a number of case studies involving robotic deep RL. Building off of these case studies, we discuss commonly perceived challenges in deep RL and how they have been addressed in these works. We also provide an overview of other outstanding challenges, many of which are unique to the real-world robotics setting and are not often the focus of mainstream RL research. Our goal is to provide a resource both for roboticists and machine learning researchers who are interested in furthering the progress of deep RL in the real world.},
	language = {en},
	number = {4-5},
	urldate = {2023-03-31},
	journal = {The International Journal of Robotics Research},
	author = {Ibarz, Julian and Tan, Jie and Finn, Chelsea and Kalakrishnan, Mrinal and Pastor, Peter and Levine, Sergey},
	month = apr,
	year = {2021},
	note = {182 citations (Semantic Scholar/DOI) [2023-04-11]
Publisher: SAGE Publications Ltd STM},
	keywords = {/unread},
	pages = {698--721},
}

@phdthesis{lagreliusComparingFourModelling2022,
	title = {Comparing {Four} {Modelling} {Methods} for the {Simulation} of a {Soft} {Quadruped} {Robot}},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-321098},
	abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
	language = {eng},
	urldate = {2022-11-16},
	school = {KTH Royal Institute of Technology},
	author = {Lagrelius, Karin},
	year = {2022},
	keywords = {Soft robot},
}

@phdthesis{jiLearningbasedControl4D2022,
	address = {Stockholm, Sweden},
	title = {Learning-based {Control} for {4D} {Printing} and {Soft} {Robotics}},
	abstract = {Exploiting novel sensors and actuators made of flexible and smart materials becomes a new trend in robotics research. The studies on the design, production, and control of the new type of robots motivate the research fields of soft robots and 4D printed robots. 3D Printing (3DP) is an additive manufacturing technology that is widely used in printing flexible materials to fabricate soft robots. 4D Printing (4DP) combines 3DP technologies with smart materials to produce transformable devices. 4DP first prints structures with specifically designed responsive materials. When external stimuli such as temperature, voltage, or magnetic field are applied to the printed structure, it changes shape in a programmable way. The shape morphing property of 4DP makes it a novel approach to the actuators of robots.},
	language = {en},
	school = {KTH Royal Institute of Technology},
	author = {Ji, Qinglei},
	year = {2022},
	keywords = {/unread},
}

@article{gangulyOptimisedBuildingEnergy2020,
	title = {Optimised building energy and indoor microclimatic predictions using knowledge-based system identification in a historical art gallery},
	volume = {32},
	issn = {1433-3058},
	url = {https://doi.org/10.1007/s00521-019-04224-7},
	doi = {10.1007/s00521-019-04224-7},
	abstract = {This paper presents a system identification (SID) model for an historical art gallery of great cultural significance. These buildings require tight indoor temperature and moisture controls that demand significant energy from air handling units. Complex dynamic building systems, stringent conservation restrictions, and lack of detailed monitoring make diagnosing and optimising their energy use difficult. Building simulation software programmes have proven to be effective, but have tended to rely on data generated by simulation models. This study shows how artificial neural network (ANN) models trained with historical real data can predict a building’s energy use and the optimal indoor microclimate necessary for conservation. Four ANN target-data scenarios were designed for optimised model predictions, and 12 ANN training algorithms were tested with six architectural scenarios collecting daily and hourly data. The ANN models used a randomised 80\% sample of the database, with the remainder (20\%) validating the models. The model displayed a high coefficient of correlation (0.99), with the mean square error and mean absolute error less than 0.1\% and 2\%, respectively. This ANN-based SID tool efficiently represents a complex building system and could be an ideal method for investigating optimisation strategies prior to their implementation.},
	language = {en},
	number = {8},
	urldate = {2023-07-11},
	journal = {Neural Computing and Applications},
	author = {Ganguly, Shashwat and Ahmed, Afaq and Wang, Fan},
	month = apr,
	year = {2020},
	keywords = {/unread, Artificial neural networks, Energy prediction model, Historical art gallery building, Indoor microclimatic control, Optimisation, System identification},
	pages = {3349--3366},
}

@inproceedings{silverDeterministicPolicyGradient2014,
	title = {Deterministic {Policy} {Gradient} {Algorithms}},
	url = {https://proceedings.mlr.press/v32/silver14.html},
	abstract = {In this paper we consider deterministic policy gradient algorithms for reinforcement learning with continuous actions. The deterministic policy gradient has a particularly appealing form: it is the expected gradient of the action-value function. This simple form means that the deterministic policy gradient can be estimated much more efficiently than the usual stochastic policy gradient. To ensure adequate exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic target policy from an exploratory behaviour policy. Deterministic policy gradient algorithms outperformed their stochastic counterparts in several benchmark problems, particularly in high-dimensional action spaces.},
	language = {en},
	urldate = {2023-07-11},
	booktitle = {Proceedings of the 31st {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
	month = jan,
	year = {2014},
	note = {ISSN: 1938-7228},
	keywords = {/unread},
	pages = {387--395},
}

@inproceedings{pengSimtoRealTransferRobotic2018,
	title = {Sim-to-{Real} {Transfer} of {Robotic} {Control} with {Dynamics} {Randomization}},
	doi = {10.1109/ICRA.2018.8460528},
	abstract = {Simulations are attractive environments for training agents as they provide an abundant source of data and alleviate certain safety concerns during the training process. But the behaviours developed by agents in simulation are often specific to the characteristics of the simulator. Due to modeling error, strategies that are successful in simulation may not transfer to their real world counterparts. In this paper, we demonstrate a simple method to bridge this “reality gap”. By randomizing the dynamics of the simulator during training, we are able to develop policies that are capable of adapting to very different dynamics, including ones that differ significantly from the dynamics on which the policies were trained. This adaptivity enables the policies to generalize to the dynamics of the real world without any training on the physical system. Our approach is demonstrated on an object pushing task using a robotic arm. Despite being trained exclusively in simulation, our policies are able to maintain a similar level of performance when deployed on a real robot, reliably moving an object to a desired location from random initial configurations. We explore the impact of various design decisions and show that the resulting policies are robust to significant calibration error.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Peng, Xue Bin and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
	month = may,
	year = {2018},
	note = {ISSN: 2577-087X},
	keywords = {/unread, Adaptation models, Data models, Robots, Robustness, Task analysis, Training, Trajectory},
	pages = {3803--3810},
}

@inproceedings{duanBenchmarkingDeepReinforcement2016,
	title = {Benchmarking {Deep} {Reinforcement} {Learning} for {Continuous} {Control}},
	url = {https://proceedings.mlr.press/v48/duan16.html},
	abstract = {Recently, researchers have made significant progress combining the advances in deep learning for learning feature representations with reinforcement learning. Some notable examples include training agents to play Atari games based on raw pixel data and to acquire advanced manipulation skills using raw sensory inputs. However, it has been difficult to quantify progress in the domain of continuous control due to the lack of a commonly adopted benchmark. In this work, we present a benchmark suite of continuous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, tasks with partial observations, and tasks with hierarchical structure. We report novel findings based on the systematic evaluation of a range of implemented reinforcement learning algorithms. Both the benchmark and reference implementations are released at https://github.com/rllab/rllab in order to facilitate experimental reproducibility and to encourage adoption by other researchers.},
	language = {en},
	urldate = {2023-07-11},
	booktitle = {Proceedings of {The} 33rd {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
	month = jun,
	year = {2016},
	note = {ISSN: 1938-7228},
	keywords = {/unread},
	pages = {1329--1338},
}

@article{tangModelbasedOnlineLearning2021,
	title = {Model-based online learning and adaptive control for a “human-wearable soft robot” integrated system},
	volume = {40},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/0278364919873379},
	doi = {10.1177/0278364919873379},
	abstract = {Soft robots are considered intrinsically safe with regard to human?robot interaction. This has motivated the development and investigation of soft medical robots, such as soft robotic gloves for stroke rehabilitation. However, the output force of conventional purely soft actuators is usually limited. This restricts their application in stroke rehabilitation, which requires a large force and bidirectional movement. In addition, accurate control of soft actuators is difficult owing to the nonlinearity of purely soft actuators. In this study, a soft robotic glove is designed based on a soft-elastic composite actuator (SECA) that integrates an elastic torque compensating layer to increase the output force as well as achieving bidirectional movement. Such a hybrid design also significantly reduces the degree of nonlinearity compared with a purely soft actuator. A model-based online learning and adaptive control algorithm is proposed for the wearable soft robotic glove, taking its interaction environment into account, namely, the human hand/finger. The designed hybrid controller enables the soft robotic glove to adapt to different hand conditions for reference tracking. Experimental results show that satisfactory tracking performance can be achieved on both healthy subjects and stroke subjects (with the tracking root mean square error (RMSE) {\textless} 0.05 rad). Meanwhile, the controller can output an actuator?finger model for each individual subject (with the learning error RMSE {\textless} 0.06 rad), which provides information on the condition of the finger and, thus, has further potential clinical application.},
	language = {en},
	number = {1},
	urldate = {2022-12-08},
	journal = {The International Journal of Robotics Research},
	author = {Tang, Zhi Qiang and Heung, Ho Lam and Tong, Kai Yu and Li, Zheng},
	month = jan,
	year = {2021},
	note = {30 citations (Semantic Scholar/DOI) [2023-04-11]
Publisher: SAGE Publications Ltd STM},
	keywords = {/unread},
	pages = {256--276},
}

@inproceedings{kalakrishnanFastRobustQuadruped2010,
	title = {Fast, robust quadruped locomotion over challenging terrain},
	doi = {10.1109/ROBOT.2010.5509805},
	abstract = {We present a control architecture for fast quadruped locomotion over rough terrain. We approach the problem by decomposing it into many sub-systems, in which we apply state-of-the-art learning, planning, optimization and control techniques to achieve robust, fast locomotion. Unique features of our control strategy include: (1) a system that learns optimal foothold choices from expert demonstration using terrain templates, (2) a body trajectory optimizer based on the Zero-Moment Point (ZMP) stability criterion, and (3) a floating-base inverse dynamics controller that, in conjunction with force control, allows for robust, compliant locomotion over unperceived obstacles. We evaluate the performance of our controller by testing it on the LittleDog quadruped robot, over a wide variety of rough terrain of varying difficulty levels. We demonstrate the generalization ability of this controller by presenting test results from an independent external test team on terrains that have never been shown to us.},
	booktitle = {2010 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Kalakrishnan, Mrinal and Buchli, Jonas and Pastor, Peter and Mistry, Michael and Schaal, Stefan},
	month = may,
	year = {2010},
	note = {ISSN: 1050-4729},
	keywords = {/unread, Foot, Force control, Leg, Legged locomotion, Mobile robots, Optimal control, Robust control, Robustness, Size control, Software testing},
	pages = {2665--2670},
}

@inproceedings{bledtMITCheetahDesign2018,
	title = {{MIT} {Cheetah} 3: {Design} and {Control} of a {Robust}, {Dynamic} {Quadruped} {Robot}},
	shorttitle = {{MIT} {Cheetah} 3},
	doi = {10.1109/IROS.2018.8593885},
	abstract = {This paper introduces a new robust, dynamic quadruped, the MIT Cheetah 3. Like its predecessor, the Cheetah 3 exploits tailored mechanical design to enable simple control strategies for dynamic locomotion and features high-bandwidth proprioceptive actuators to manage physical interaction with the environment. A new leg design is presented that includes proprioceptive actuation on the abduction/adduction degrees of freedom in addition to an expanded range of motion on the hips and knees. To make full use of these new capabilities, general balance and locomotion controllers for Cheetah 3 are presented. These controllers are embedded into a modular control architecture that allows the robot to handle unexpected terrain disturbances through reactive gait modification and without the need for external sensors or prior environment knowledge. The efficiency of the robot is demonstrated by a low Cost of Transport (CoT) over multiple gaits at moderate speeds, with the lowest CoT of 0.45 found during trotting. Experiments showcase the ability to blindly climb up stairs as a result of the full system integration. These results collectively represent a promising step toward a platform capable of generalized dynamic legged locomotion.},
	booktitle = {2018 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Bledt, Gerardo and Powell, Matthew J. and Katz, Benjamin and Di Carlo, Jared and Wensing, Patrick M. and Kim, Sangbae},
	month = oct,
	year = {2018},
	note = {324 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2153-0866},
	keywords = {/unread, Actuators, Force, Knee, Legged locomotion, Robot sensing systems, Torque},
	pages = {2245--2252},
}

@inproceedings{hutterANYmalHighlyMobile2016,
	title = {{ANYmal} - a highly mobile and dynamic quadrupedal robot},
	doi = {10.1109/IROS.2016.7758092},
	abstract = {This paper introduces ANYmal, a quadrupedal robot that features outstanding mobility and dynamic motion capability. Thanks to novel, compliant joint modules with integrated electronics, the 30 kg, 0.5 m tall robotic dog is torque controllable and very robust against impulsive loads during running or jumping. The presented machine was designed with a focus on outdoor suitability, simple maintenance, and user-friendly handling to enable future operation in real world scenarios. Performance tests with the joint actuators indicated a torque control bandwidth of more than 70 Hz, high disturbance rejection capability, as well as impact robustness when moving with maximal velocity. It is demonstrated in a series of experiments that ANYmal can execute walking gaits, dynamically trot at moderate speed, and is able to perform special maneuvers to stand up or crawl very steep stairs. Detailed measurements unveil that even full-speed running requires less than 280 W, resulting in an autonomy of more than 2 h.},
	booktitle = {2016 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Hutter, Marco and Gehring, Christian and Jud, Dominic and Lauber, Andreas and Bellicoso, C. Dario and Tsounis, Vassilios and Hwangbo, Jemin and Bodie, Karen and Fankhauser, Peter and Bloesch, Michael and Diethelm, Remo and Bachmann, Samuel and Melzer, Amir and Hoepflinger, Mark},
	month = oct,
	year = {2016},
	note = {ISSN: 2153-0866},
	keywords = {/unread, Actuators, Dynamics, Legged locomotion, Robot sensing systems, Torque},
	pages = {38--44},
}

@article{kochOptimizationbasedWalkingGeneration2012,
	series = {10th {IFAC} {Symposium} on {Robot} {Control}},
	title = {Optimization-based walking generation for humanoid robot},
	volume = {45},
	issn = {1474-6670},
	url = {https://www.sciencedirect.com/science/article/pii/S147466701633659X},
	doi = {10.3182/20120905-3-HR-2030.00189},
	abstract = {The generation of walking motions for humanoid robots is a challenging task. From the infinite number of possibilities to move the body of the robot with its redundant degrees of freedom (DOF) forward, the task is to determine those motions that are stable, feasible within the robots kinematic and dynamic limitations, and also resemble the way we expect an anthropomorphic system to walk. Several approaches have been developed and implemented on humanoids in the past years, however most of them require fixing several characteristics of the gait, such as foot placement or step time, in advance, and none has lead to truly human-like walking performance. The purpose of this paper is to show that mathematical trajectory optimization or optimal control can be very helpful to generate walking motions for humanoid robots. We propose a method that uses dynamic model information of the robot as well as efficient optimal control techniques to determine joint trajectories and actuator torques at the same time. Foot placement and step times are also left free for optimization. The method is applied to the humanoid robot HRP-2 with 36 DOF and 30 actuators. Different optimization criteria are evaluated, such as maximization of efficiency, walking speed or postural stability, and a minimization of joint torques or angular amplitudes. ZMP constraints (or alternative stability constraints) can be taken into account in the optimization. The results show that different objective functions and constraints have a considerable influence on the resulting gait.},
	language = {en},
	number = {22},
	urldate = {2023-07-08},
	journal = {IFAC Proceedings Volumes},
	author = {Koch, Kai Henning and Mombaur, Katja and Soueres, Philippe},
	month = jan,
	year = {2012},
	keywords = {/unread, HRP-2, Humanoid robot, Optimal Control, Walking motion generation},
	pages = {498--504},
}

@inproceedings{farshidianRealtimeMotionPlanning2017,
	title = {Real-time motion planning of legged robots: {A} model predictive control approach},
	shorttitle = {Real-time motion planning of legged robots},
	doi = {10.1109/HUMANOIDS.2017.8246930},
	abstract = {We introduce a real-time, constrained, nonlinear Model Predictive Control for the motion planning of legged robots. The proposed approach uses a constrained optimal control algorithm known as SLQ. We improve the efficiency of this algorithm by introducing a multi-processing scheme for estimating value function in its backward pass. This pass has been often calculated as a single process. This parallel SLQ algorithm can optimize longer time horizons without proportional increase in its computation time. Thus, our MPC algorithm can generate optimized trajectories for the next few phases of the motion within only a few milliseconds. This outperforms the state of the art by at least one order of magnitude. The performance of the approach is validated on a quadruped robot for generating dynamic gaits such as trotting.},
	booktitle = {2017 {IEEE}-{RAS} 17th {International} {Conference} on {Humanoid} {Robotics} ({Humanoids})},
	author = {Farshidian, Farbod and Jelavic, Edo and Satapathy, Asutosh and Giftthaler, Markus and Buchli, Jonas},
	month = nov,
	year = {2017},
	note = {ISSN: 2164-0580},
	keywords = {/unread, Heuristic algorithms, Legged locomotion, Mathematical model, Planning, Robot kinematics, Trajectory},
	pages = {577--584},
}

@inproceedings{jannerWhenTrustYour2019,
	title = {When to {Trust} {Your} {Model}: {Model}-{Based} {Policy} {Optimization}},
	shorttitle = {When to {Trust} {Your} {Model}},
	url = {http://arxiv.org/abs/1906.08253},
	doi = {10.48550/arXiv.1906.08253},
	abstract = {Designing effective model-based reinforcement learning algorithms is difficult because the ease of data generation must be weighed against the bias of model-generated data. In this paper, we study the role of model usage in policy optimization both theoretically and empirically. We first formulate and analyze a model-based reinforcement learning algorithm with a guarantee of monotonic improvement at each step. In practice, this analysis is overly pessimistic and suggests that real off-policy data is always preferable to model-generated on-policy data, but we show that an empirical estimate of model generalization can be incorporated into such analysis to justify model usage. Motivated by this analysis, we then demonstrate that a simple procedure of using short model-generated rollouts branched from real data has the benefits of more complicated model-based algorithms without the usual pitfalls. In particular, this approach surpasses the sample efficiency of prior model-based methods, matches the asymptotic performance of the best model-free algorithms, and scales to horizons that cause other model-based methods to fail entirely.},
	urldate = {2023-04-21},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} ({NeurIPS})},
	author = {Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
	month = jun,
	year = {2019},
	note = {arXiv:1906.08253 [cs, stat]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{liDevelopmentFieldEvaluation2023,
	title = {Development and field evaluation of a robotic harvesting system for plucking high-quality tea},
	volume = {206},
	issn = {0168-1699},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169923000479},
	doi = {10.1016/j.compag.2023.107659},
	abstract = {The critical issue of the robotic harvesting high-quality tea is to realize tea shoot detection, plucking point localization, and motion planning. In addition, the accuracy and efficiency of the robotic plucking of high-quality tea in the field are essential. Therefore, a robotic harvesting system is proposed in this paper by combining deep learning, point cloud processing, and spatial path planning. First, the deep learning method and the compressed YOLOv3 network are used to quickly and accurately identify tea shoots. Second, an efficient point cloud processing-based 3D localization algorithm for high-quality tea plucking points was proposed. The genetic algorithm is then used to shorten the end-effector's motion path by optimizing the plucking sequences. Eventually, a harvester robot with a parallel manipulator was developed to conduct field plucking experiments and evaluate the effectiveness of the proposed harvesting system. All experimental results demonstrate that the success rates of detection, localization, and motion plucking are 85.16 \%, 78.90 \%, and 80.23 \%, respectively. Furthermore, the overall process harvesting success rate is 53.91 \%, and the average plucking time for a single shoot is 2.233 s. Therefore, the proposed harvesting approach can provide technical support for the precise and rapid harvesting of high-quality tea.},
	language = {en},
	urldate = {2023-07-03},
	journal = {Computers and Electronics in Agriculture},
	author = {Li, Yatao and Wu, Shunkai and He, Leiying and Tong, Junhua and Zhao, Runmao and Jia, Jiangming and Chen, Jianneng and Wu, Chuanyu},
	month = mar,
	year = {2023},
	keywords = {/unread, High-quality tea, Plucking sequence optimization, Point cloud process, Tea harvesting robots},
	pages = {107659},
}

@book{QuadrupedalLocomotion2006,
	address = {London},
	title = {Quadrupedal {Locomotion}},
	isbn = {978-1-84628-306-2},
	url = {http://link.springer.com/10.1007/1-84628-307-8},
	language = {en},
	urldate = {2023-07-08},
	publisher = {Springer},
	year = {2006},
	doi = {10.1007/1-84628-307-8},
	keywords = {/unread, Hexapod, algorithms, kinematics, proving, robot, robotics, sensor},
}

@misc{noauthor_quadrupedal_nodate,
	title = {Quadrupedal {Locomotion}: {An} {Introduction} to the {Control} of {Four}-legged {Robots} {\textbar} {SpringerLink}},
	url = {https://link.springer.com/book/10.1007/1-84628-307-8},
	urldate = {2023-07-08},
	keywords = {/unread},
}

@inproceedings{wangHierarchicalReinforcementLearning2022,
	title = {A {Hierarchical} {Reinforcement} {Learning} {Framework} based on {Soft} {Actor}-{Critic} for {Quadruped} {Gait} {Generation}},
	doi = {10.1109/ROBIO55434.2022.10011919},
	abstract = {Recently, reinforcement learning has become a promising control method of legged robot. However, it is challenging to train from scratch which requires perfect networks and reward design. In this paper, a hierarchical reinforcement learning framework based on Soft Actor-Critic has been proposed to find the appropriate gait of quadruped robot in the environment. The framework is composed of a low-level policy for generating joint reference trajectory and a high-level policy for gait optimization. In low-level policy, we use radial basis network and evolutionary computation solver to change the shape of reference trajectory in order to search for a better reference trajectory. In high-level policy, joint angle increment is learned to optimize gait. The experimental results show that the hierarchical framework is better than that of using Soft Actor-Critic only.},
	booktitle = {2022 {IEEE} {International} {Conference} on {Robotics} and {Biomimetics} ({ROBIO})},
	author = {Wang, Yu and Jia, Wenchuan and Sun, Yi},
	month = dec,
	year = {2022},
	keywords = {/unread, Evolutionary computation, Radial basis function networks, Reinforcement learning, Shape, Space exploration, Training, Trajectory},
	pages = {1970--1975},
}

@article{denavitKinematicNotationLowerPair1955,
	title = {A {Kinematic} {Notation} for {Lower}-{Pair} {Mechanisms} {Based} on {Matrices}},
	volume = {22},
	issn = {0021-8936},
	url = {https://doi.org/10.1115/1.4011045},
	doi = {10.1115/1.4011045},
	abstract = {A symbolic notation devised by Reuleaux to describe mechanisms did not recognize the necessary number of variables needed for complete description. A reconsideration of the problem leads to a symbolic notation which permits the complete description of the kinematic properties of all lower-pair mechanisms by means of equations. The symbolic notation also yields a method for studying lower-pair mechanisms by means of matrix algebra; two examples of application to space mechanisms are given.},
	number = {2},
	urldate = {2023-07-06},
	journal = {Journal of Applied Mechanics},
	author = {Denavit, J. and Hartenberg, R. S.},
	month = dec,
	year = {1955},
	keywords = {/unread},
	pages = {215--221},
}

@article{billardTrendsChallengesRobot2019,
	title = {Trends and challenges in robot manipulation},
	volume = {364},
	url = {https://www.science.org/doi/full/10.1126/science.aat8414},
	doi = {10.1126/science.aat8414},
	abstract = {Dexterous manipulation is one of the primary goals in robotics. Robots with this capability could sort and package objects, chop vegetables, and fold clothes. As robots come to work side by side with humans, they must also become human-aware. Over the past decade, research has made strides toward these goals. Progress has come from advances in visual and haptic perception and in mechanics in the form of soft actuators that offer a natural compliance. Most notably, immense progress in machine learning has been leveraged to encapsulate models of uncertainty and to support improvements in adaptive and robust control. Open questions remain in terms of how to enable robots to deal with the most unpredictable agent of all, the human.},
	number = {6446},
	urldate = {2023-07-03},
	journal = {Science},
	author = {Billard, Aude and Kragic, Danica},
	month = jun,
	year = {2019},
	note = {Publisher: American Association for the Advancement of Science},
	keywords = {/unread},
	pages = {eaat8414},
}

@article{hyunHighSpeedTrotrunning2014,
	title = {High speed trot-running: {Implementation} of a hierarchical controller using proprioceptive impedance control on the {MIT} {Cheetah}},
	copyright = {Creative Commons Attribution-Noncommercial-Share Alike},
	issn = {0278-3649},
	shorttitle = {High speed trot-running},
	url = {https://dspace.mit.edu/handle/1721.1/98270},
	abstract = {This paper presents implementation of a highly dynamic running gait with a hierarchical controller on the MIT Cheetah. The developed controller enables high-speed running of up to 6 m/s (Froude number of Fr ≈ 7.34) incorporating proprioceptive feedback and programmable virtual leg compliance of the MIT Cheetah. To achieve a stable and fast trot gait, we applied three control strategies: (a) programmable virtual leg compliance that provides instantaneous reflexes to external disturbance and facilitates the self-stabilizing shown in the passive dynamics of locomotion; (b) tunable stance-trajectory design, intended to adjust impulse at each foot-end in the stance phase in a high speed trot-running according to the equilibrium-point hypothesis; and (c) a gait-pattern modulation that imposes a desired cyclic gait-pattern taking cues from proprioceptive TD feedback. Based on three strategies, the controller is hierarchically structured. The control parameters for forward speeds, a specific gait-pattern, and desired leg trajectories are managed by a high-level controller. It consists of both a gait-pattern modulator with proprioceptive leg TD detection and a leg-trajectory generator using a Bèzier curve and a tunable amplitude sinusoidal wave. Instead of employing physical spring/dampers in the robot’s leg, the programmable virtual leg compliance is realized using proprioceptive impedance control in individual low-level leg controllers. 
To verify the developed controller, a robot dynamic simulator is constructed based on the model parameters of the MIT Cheetah. The controller parameters are tuned with the simulator to achieve self-stability, and then applied to the MIT Cheetah in an experimental environment. Using leg kinematics and applied motor current feedbacks, the MIT Cheetah achieved a stable trot-running gait in the sagittal plane.},
	language = {en\_US},
	urldate = {2023-07-06},
	journal = {Prof. Kim via Angie Locknar},
	author = {Hyun, D. J. and Seok, S. and Lee, J. and Kim, S.},
	month = aug,
	year = {2014},
	note = {Accepted: 2015-09-01T12:16:26Z
Publisher: Sage Publications},
	keywords = {/unread},
}

@article{hawkesSoftRobotThat2017,
	title = {A soft robot that navigates its environment through growth},
	volume = {2},
	issn = {2470-9476},
	doi = {10.1126/scirobotics.aan3028},
	abstract = {Across kingdoms and length scales, certain cells and organisms navigate their environments not through locomotion but through growth. This pattern of movement is found in fungal hyphae, developing neurons, and trailing plants, and is characterized by extension from the tip of the body, length change of hundreds of percent, and active control of growth direction. This results in the abilities to move through tightly constrained environments and form useful three-dimensional structures from the body. We report a class of soft pneumatic robot that is capable of a basic form of this behavior, growing substantially in length from the tip while actively controlling direction using onboard sensing of environmental stimuli; further, the peak rate of lengthening is comparable to rates of animal and robot locomotion. This is enabled by two principles: Pressurization of an inverted thin-walled vessel allows rapid and substantial lengthening of the tip of the robot body, and controlled asymmetric lengthening of the tip allows directional control. Further, we demonstrate the abilities to lengthen through constrained environments by exploiting passive deformations and form three-dimensional structures by lengthening the body of the robot along a path. Our study helps lay the foundation for engineered systems that grow to navigate the environment.},
	language = {eng},
	number = {8},
	journal = {Science Robotics},
	author = {Hawkes, Elliot W. and Blumenschein, Laura H. and Greer, Joseph D. and Okamura, Allison M.},
	month = jul,
	year = {2017},
	pmid = {33157883},
	note = {409 citations (Crossref) [2022-12-07]},
	keywords = {/unread},
	pages = {eaan3028},
}

@misc{fletcherTrot2012,
	title = {Trot},
	url = {http://vanat.cvm.umn.edu/gaits/trot.html},
	abstract = {A running trot is shown in the above cartoon. The step sequence of the trot is shown at the right. The trot is a two-beat gait. Right and left diagonals alternate in supporting weight, i.e., the right forelimb and left hind limb move in unison as do left forelimb and right hind limb. The diagonal is named for the involved forelimb (right/left). Actually, the hind limb of the diagonal impacts slightly earlier than the fore limb, though they appear to impact simultaneously. The hind limb provides both vertical and forward propulsion. The trunk is carried rigidly, undergoing only vertical oscillations, and the neck and head are fixed in an upright position during the trot. In the running trot (quick trot; brisk trot; flying trot) a suspension phase intervenes between each diagonal support phase (illustrated above and left). As the stride is lengthened in the running trot, interference can become a problem (the hind paw hits the ipsilateral forelimb). To avoid interference, the fore paw must be lifted before the ipsilateral hind paw arrives, or the hind paw must land to the side of the fore paw, or the animal must resort to crab-running (trunk at an angle to the line of progression). In a slow trot, the suspension phase is absent, so the body is always supported by one diagonal or the other. If the support phase is prolonged and the swing phase is shortened, three-limb support may intervene between the diagonal support phases. The trot is a common gait in all domestic quadrupeds. It is well-suited for rough, irregular ground and for traveling long distances at a fair rate of speed. Work is spread evenly over all four limbs, and diagonal support makes it easy to maintain equilibrium. The trot is the natural foraging gait of most wild animals. Relative to other quadrupeds, the dog exhibits a greater variety of trot variations (dog-trot; thrown trot; swung trot). In a "dog-trot", the forelimb precedes the hindlimb at impact and lift. The German Shepherd typically exhibits suspension (running trot; flying trot) when it trots. It's long body and low center of gravity of precludes interference and the need for compensatory crab-running. The running trot is used by racing Standardbred horses. Interference is avoided by developing a long-bodied (long-coupled) horse, or the problem is minimized by using protective shoes.},
	language = {en},
	urldate = {2023-03-06},
	journal = {Trot},
	author = {Fletcher, Thomas F. and Datt (nee Johnson), Vicki L.},
	month = aug,
	year = {2012},
	keywords = {/unread},
}

@inproceedings{leeTrajectoryDesignControl2017,
	title = {Trajectory design and control of quadruped robot for trotting over obstacles},
	doi = {10.1109/IROS.2017.8206368},
	abstract = {Various control strategies using trajectory planning, object recognition and learning are researched for avoiding obstacles when legged robot is walking. In this paper, designed trajectory by using Non Uniform Basis Spline (NUBS) curve and control strategy, by using proposed trajectory, to effectively overcome obstacles are presented. The trajectory designed by NUBS curve has several advantages: 1) local modification, 2) tracking velocity control for each domain, and 3) low degree trajectory with a large number of control points. The robot gets remarkable effectiveness when these advantages are used to generate the trajectory for walking and overcoming obstacles. By implementation of the proposed control strategy, quadruped robot can walk over obstacles while keeping its gait, speed and balance without collision although adjusting relatively preferable state which is more suitable position or posture of the walking robot shortly before encountering obstacles is not required. The proposed trajectory and control strategy are discussed, and performance is validated through experimental evaluations.},
	booktitle = {2017 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Lee, Young Hun and Lee, Yoon Haeng and Lee, Hyunyong and Phan, Luong Tin and Kang, Hansol and Kim, Uikyum and Jeon, Jeongmin and Choi, Hyouk Ryeol},
	month = sep,
	year = {2017},
	note = {ISSN: 2153-0866},
	keywords = {/unread, Collision avoidance, Foot, Legged locomotion, Robot sensing systems, Trajectory, Velocity control},
	pages = {4897--4902},
}

@inproceedings{zhangEffectiveSoftRobot2017,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Toward {Effective} {Soft} {Robot} {Control} via {Reinforcement} {Learning}},
	isbn = {978-3-319-65289-4},
	doi = {10.1007/978-3-319-65289-4_17},
	abstract = {A soft robot is a kind of robot that is constructed with soft, deformable and elastic materials. Control of soft robots presents complex modeling and planning challenges. We introduce a new approach to accomplish that, making two key contributions: designing an abstract representation of the state of soft robots, and developing a reinforcement learning method to derive effective control policies. The reinforcement learning process can be trained quickly by ignoring the specific materials and structural properties of the soft robot. We apply the approach to the Honeycomb PneuNets Soft Robot and demonstrate the effectiveness of the training method and its ability to produce good control policies under different conditions.},
	language = {en},
	booktitle = {Intelligent {Robotics} and {Applications}},
	publisher = {Springer International Publishing},
	author = {Zhang, Haochong and Cao, Rongyun and Zilberstein, Shlomo and Wu, Feng and Chen, Xiaoping},
	editor = {Huang, YongAn and Wu, Hao and Liu, Honghai and Yin, Zhouping},
	year = {2017},
	note = {23 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread, PneuNets, Reinforcement learning, Soft robot control},
	pages = {173--184},
}

@inproceedings{riedoThymioIIRobot2013,
	title = {Thymio {II}, a robot that grows wiser with children},
	doi = {10.1109/ARSO.2013.6705527},
	abstract = {Thymio II is a small robot developed for education. It aims at offering a wide public the possibility to understand the basics of robotics and programming. To achieve this, it aims at being appealing to a large age range and serve as a medium for several types of activities. In this study, we tested it in five different workshops of the EPFL Robotics Festival with various activities. The workshops target different age groups and the participants can control the robot via different means: built-in buttons, graphical programming and text programming. At the end of the activities, participants were asked to fill a short survey to give their impressions about the robot, their appreciation of the tasks and their motivations to take part. We could show through this feedback that Thymio II appeals to young children as much as to teenagers, to both girls and boys, and allows them to have fun and learn new things.},
	booktitle = {2013 {IEEE} {Workshop} on {Advanced} {Robotics} and its {Social} {Impacts}},
	author = {Riedo, Fanny and Chevalier, Morgane and Magnenat, Stéphane and Mondada, Francesco},
	month = nov,
	year = {2013},
	note = {ISSN: 2162-7576},
	keywords = {/unread, Computers, Conferences, Educational institutions, Programming profession, Robot sensing systems},
	pages = {187--193},
}

@article{huangSymmetryinformedReinforcementLearning2023,
	title = {Symmetry-informed {Reinforcement} {Learning} and {Its} {Application} to the {Attitude} {Control} of {Quadrotors}},
	issn = {2691-4581},
	doi = {10.1109/TAI.2023.3249683},
	abstract = {Symmetry is ubiquitous in nature, physics, and mathematics. However, a classical symmetry-agnostic Reinforcement Learning (RL) approach cannot guarantee to respect symmetry. Researchers have shown that if the symmetry of a system cannot be respected, the performance of a symmetry-agnostic RL approach can be inhibited. To this end, this paper develops a generally applicable Neural Network (NN) module with symmetry that can enforce the symmetry of a system to be respected. Based on the NN module with symmetry, this paper proposes a symmetry-informed Model-Based RL (MBRL) approach that respects symmetry and improves data efficiency. The symmetry-informed MBRL approach is applied to the attitude control of a quadrotor in simulation to evaluate the effectiveness of the approach. The simulation results show that the data efficiency of the symmetry-informed MBRL approach is much superior to that of a symmetry-agnostic MBRL approach. An NN module with symmetry can respect the symmetry of a quadrotor while a naive NN cannot enforce the symmetry of a quadrotor to be respected.},
	journal = {IEEE Transactions on Artificial Intelligence},
	author = {Huang, Junchang and Zeng, Weifeng and Xiong, Hao and Noack, Bernd R. and Hu, Gang and Liu, Shugao and Xu, Yuchen and Cao, Huanhui},
	year = {2023},
	note = {0 citations (Semantic Scholar/DOI) [2023-04-11]
Conference Name: IEEE Transactions on Artificial Intelligence},
	keywords = {/unread, Artificial neural networks, Attitude control, Data efficiency, Data models, Quadrotors, Reinforcement learning, Rotors, Torque, model-based reinforcement learning, neural network, quadrotor, symmetry},
	pages = {1--14},
}

@article{polydorosSurveyModelBasedReinforcement2017,
	title = {Survey of {Model}-{Based} {Reinforcement} {Learning}: {Applications} on {Robotics}},
	volume = {86},
	issn = {1573-0409},
	shorttitle = {Survey of {Model}-{Based} {Reinforcement} {Learning}},
	url = {https://doi.org/10.1007/s10846-017-0468-y},
	doi = {10.1007/s10846-017-0468-y},
	abstract = {Reinforcement learning is an appealing approach for allowing robots to learn new tasks. Relevant literature reveals a plethora of methods, but at the same time makes clear the lack of implementations for dealing with real life challenges. Current expectations raise the demand for adaptable robots. We argue that, by employing model-based reinforcement learning, the—now limited—adaptability characteristics of robotic systems can be expanded. Also, model-based reinforcement learning exhibits advantages that makes it more applicable to real life use-cases compared to model-free methods. Thus, in this survey, model-based methods that have been applied in robotics are covered. We categorize them based on the derivation of an optimal policy, the definition of the returns function, the type of the transition model and the learned task. Finally, we discuss the applicability of model-based reinforcement learning approaches in new applications, taking into consideration the state of the art in both algorithms and hardware.},
	language = {en},
	number = {2},
	urldate = {2023-02-28},
	journal = {Journal of Intelligent \& Robotic Systems},
	author = {Polydoros, Athanasios S. and Nalpantidis, Lazaros},
	month = may,
	year = {2017},
	note = {0 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread},
	pages = {153--173},
}

@phdthesis{daneliaStructureGaitOptimizationof2021,
	title = {Structure and {Gait} {Optimizationof} a {Soft} {Quadrupedal} {Robot}},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-305510},
	abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
	language = {eng},
	urldate = {2022-10-14},
	school = {KTH Royal Institute of Technology},
	author = {Danelia, David and Fu, Shuo},
	year = {2021},
	keywords = {/unread},
}

@article{jiaStabilityCriterionDynamic2018,
	title = {Stability {Criterion} for {Dynamic} {Gaits} of {Quadruped} {Robot}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/8/12/2381},
	doi = {10.3390/app8122381},
	abstract = {Dynamic-stability criteria are crucial for robot’s motion planning and balance recovery. Nevertheless, few studies focus on the motion stability of quadruped robots with dynamic gait, none of which have accurately evaluated the robots’ stability. To fill the gaps in this field, this paper presents a new stability criterion for the motion of quadruped robots with dynamic gaits running over irregular terrain. The traditional zero-moment point (ZMP) is improved to analyze the motion on irregular terrain precisely for dynamic gaits. A dynamic-stability criterion and measurement are proposed to determine the stability state of the robot and to evaluate its stability. The simulation results show the limitations of the existing stability criteria for dynamic gaits and indicate that the criterion proposed in this paper can accurately and efficiently evaluate the stability of a quadruped robot using such gaits.},
	language = {en},
	number = {12},
	urldate = {2023-03-15},
	journal = {Applied Sciences},
	author = {Jia, Yan and Luo, Xiao and Han, Baoling and Liang, Guanhao and Zhao, Jiaheng and Zhao, Yuting},
	month = dec,
	year = {2018},
	note = {10 citations (Semantic Scholar/DOI) [2023-04-11]
Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {/unread, dynamic gait, quadruped robot, stability criterion},
	pages = {2381},
}

@inproceedings{haarnojaSoftActorCriticOffPolicy2018,
	title = {Soft {Actor}-{Critic}: {Off}-{Policy} {Maximum} {Entropy} {Deep} {Reinforcement} {Learning} with a {Stochastic} {Actor}},
	shorttitle = {Soft {Actor}-{Critic}},
	url = {https://proceedings.mlr.press/v80/haarnoja18b.html},
	abstract = {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.},
	language = {en},
	urldate = {2023-04-27},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	month = jul,
	year = {2018},
	note = {ISSN: 2640-3498},
	keywords = {/unread},
	pages = {1861--1870},
}

@article{polygerinosSoftRoboticsReview2017,
	title = {Soft {Robotics}: {Review} of {Fluid}-{Driven} {Intrinsically} {Soft} {Devices}; {Manufacturing}, {Sensing}, {Control}, and {Applications} in {Human}-{Robot} {Interaction}},
	volume = {19},
	issn = {1527-2648},
	shorttitle = {Soft {Robotics}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/adem.201700016},
	doi = {10.1002/adem.201700016},
	abstract = {The emerging field of soft robotics makes use of many classes of materials including metals, low glass transition temperature (Tg) plastics, and high Tg elastomers. Dependent on the specific design, all of these materials may result in extrinsically soft robots. Organic elastomers, however, have elastic moduli ranging from tens of megapascals down to kilopascals; robots composed of such materials are intrinsically soft − they are always compliant independent of their shape. This class of soft machines has been used to reduce control complexity and manufacturing cost of robots, while enabling sophisticated and novel functionalities often in direct contact with humans. This review focuses on a particular type of intrinsically soft, elastomeric robot − those powered via fluidic pressurization.},
	language = {en},
	number = {12},
	urldate = {2022-12-07},
	journal = {Advanced Engineering Materials},
	author = {Polygerinos, Panagiotis and Correll, Nikolaus and Morin, Stephen A. and Mosadegh, Bobak and Onal, Cagdas D. and Petersen, Kirstin and Cianchetti, Matteo and Tolley, Michael T. and Shepherd, Robert F.},
	year = {2017},
	note = {558 citations (Semantic Scholar/DOI) [2023-04-11]
531 citations (Crossref) [2022-12-07]
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/adem.201700016},
	keywords = {/unread},
	pages = {1700016},
}

@article{tanShapeEstimation3D2022,
	title = {Shape {Estimation} of a {3D} {Printed} {Soft} {Sensor} {Using} {Multi}-{Hypothesis} {Extended} {Kalman} {Filter}},
	volume = {7},
	issn = {2377-3766},
	doi = {10.1109/LRA.2022.3187832},
	abstract = {This study develops a multi-hypothesis extended Kalman filter (MH-EKF) for the online estimation of the bending angle of a 3D printed soft sensor attached to soft actuators. Despite the advantage of compliance and low interference, the 3D printed soft sensor is susceptible to the hysteresis property and nonlinear effects. Improving measurement accuracy for sensors with hysteresis is a common challenge. Current studies mainly apply complex models and highly nonlinear functions to characterize the hysteresis, requiring a complicated parameter identification process and challenging real-time applications. This study enhances the model simplicity and the real-time performance for the hysteresis characterization. We identify the hysteresis by combining multiple polynomial functions and improving the sensor estimation with the proposed MH-EKF. We examine the performance of the filter in the real-time closed-loop control system. Compared with the baseline methods, the proposed approach shows improvements in the estimation accuracy with low computational complexity.},
	number = {3},
	journal = {IEEE Robotics and Automation Letters},
	author = {Tan, Kaige and Ji, Qinglei and Feng, Lei and Törngren, Martin},
	month = jul,
	year = {2022},
	note = {1 citations (Semantic Scholar/DOI) [2023-04-11]
Conference Name: IEEE Robotics and Automation Letters},
	keywords = {/unread, Actuators, Bending, Control, Hydraulic/Pneumatic Actuators, Hysteresis, Modeling, Resistance, Sensors, Shape, Soft Sensors and Actuators, Soft sensors, and Learning for Soft Robots},
	pages = {8383--8390},
}

@misc{tanSimtoRealLearningAgile2018,
	title = {Sim-to-{Real}: {Learning} {Agile} {Locomotion} {For} {Quadruped} {Robots}},
	shorttitle = {Sim-to-{Real}},
	url = {http://arxiv.org/abs/1804.10332},
	doi = {10.48550/arXiv.1804.10332},
	abstract = {Designing agile locomotion for quadruped robots often requires extensive expertise and tedious manual tuning. In this paper, we present a system to automate this process by leveraging deep reinforcement learning techniques. Our system can learn quadruped locomotion from scratch using simple reward signals. In addition, users can provide an open loop reference to guide the learning process when more control over the learned gait is needed. The control policies are learned in a physics simulator and then deployed on real robots. In robotics, policies trained in simulation often do not transfer to the real world. We narrow this reality gap by improving the physics simulator and learning robust policies. We improve the simulation using system identification, developing an accurate actuator model and simulating latency. We learn robust controllers by randomizing the physical environments, adding perturbations and designing a compact observation space. We evaluate our system on two agile locomotion gaits: trotting and galloping. After learning in simulation, a quadruped robot can successfully perform both gaits in the real world.},
	urldate = {2022-11-21},
	publisher = {arXiv},
	author = {Tan, Jie and Zhang, Tingnan and Coumans, Erwin and Iscen, Atil and Bai, Yunfei and Hafner, Danijar and Bohez, Steven and Vanhoucke, Vincent},
	month = may,
	year = {2018},
	note = {549 citations (Semantic Scholar/arXiv) [2023-04-11]
arXiv:1804.10332 [cs]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Robotics},
}

@inproceedings{liResearchMammalBionic2011,
	title = {Research of mammal bionic quadruped robots: {A} review},
	shorttitle = {Research of mammal bionic quadruped robots},
	doi = {10.1109/RAMECH.2011.6070476},
	abstract = {This paper focuses on the mammal bionic quadruped robots. The main challenge in this field is how to design the highly dynamical and high payload quadruped robots. This paper firstly introduces the history of bionic quadruped robots, particularly the landmark quadruped robots. Then the state-of-the art of drive mode for quadruped robots is reviewed. Subsequently, the development trend of quadruped robots is described. Based on the state-of-the art of quadruped robots, the technical difficulties of bionic quadruped robots are briefly reviewed. And the hydraulic quadruped robot developed in Shandong University is introduced. Finally, the summary and future work of the quadruped robots is given.},
	booktitle = {2011 {IEEE} 5th {International} {Conference} on {Robotics}, {Automation} and {Mechatronics} ({RAM})},
	author = {Li, Yibin and Li, Bin and Ruan, Jiuhong and Rong, Xuewen},
	month = sep,
	year = {2011},
	note = {ISSN: 2158-219X},
	keywords = {/unread, Educational institutions, Legged locomotion, Payloads, Robot kinematics, Robot sensing systems},
	pages = {166--171},
}

@article{fazeliSeeFeelAct2019,
	title = {See, feel, act: {Hierarchical} learning for complex manipulation skills with multisensory fusion},
	volume = {4},
	shorttitle = {See, feel, act},
	url = {https://www.science.org/doi/abs/10.1126/scirobotics.aav3123},
	doi = {10.1126/scirobotics.aav3123},
	abstract = {Humans are able to seamlessly integrate tactile and visual stimuli with their intuitions to explore and execute complex manipulation skills. They not only see but also feel their actions. Most current robotic learning methodologies exploit recent progress in computer vision and deep learning to acquire data-hungry pixel-to-action policies. These methodologies do not exploit intuitive latent structure in physics or tactile signatures. Tactile reasoning is omnipresent in the animal kingdom, yet it is underdeveloped in robotic manipulation. Tactile stimuli are only acquired through invasive interaction, and interpretation of the data stream together with visual stimuli is challenging. Here, we propose a methodology to emulate hierarchical reasoning and multisensory fusion in a robot that learns to play Jenga, a complex game that requires physical interaction to be played effectively. The game mechanics were formulated as a generative process using a temporal hierarchical Bayesian model, with representations for both behavioral archetypes and noisy block states. This model captured descriptive latent structures, and the robot learned probabilistic models of these relationships in force and visual domains through a short exploration phase. Once learned, the robot used this representation to infer block behavior patterns and states as it played the game. Using its inferred beliefs, the robot adjusted its behavior with respect to both its current actions and its game strategy, similar to the way humans play the game. We evaluated the performance of the approach against three standard baselines and show its fidelity on a real-world implementation of the game.},
	number = {26},
	urldate = {2023-02-28},
	journal = {Science Robotics},
	author = {Fazeli, N. and Oller, M. and Wu, J. and Wu, Z. and Tenenbaum, J. B. and Rodriguez, A.},
	month = jan,
	year = {2019},
	note = {80 citations (Semantic Scholar/DOI) [2023-04-11]
Publisher: American Association for the Advancement of Science},
	keywords = {/unread},
	pages = {eaav3123},
}

@incollection{huaReinforcementLearningFeedback2021,
	address = {Wiesbaden},
	title = {Reinforcement {Learning} and {Feedback} {Control}},
	isbn = {978-3-658-33034-7},
	url = {https://doi.org/10.1007/978-3-658-33034-7_3},
	abstract = {Reinforcement learning (RL) is a branch of machine learning that deals with making sequences of decisions. It refers to an agent that interacts with its environment, and receives an observation and reward. RL algorithms seek to maximize the agent’s total reward, given an unknown environment, through a trial-and-error learning process. In this chapter, we will apply RL methods to solve two fundamental feedback control problems, the linear quadratic regulator and the linear quadratic Gaussian.},
	language = {en},
	urldate = {2023-06-16},
	booktitle = {Reinforcement {Learning} {Aided} {Performance} {Optimization} of {Feedback} {Control} {Systems}},
	publisher = {Springer Fachmedien},
	author = {Hua, Changsheng},
	editor = {Hua, Changsheng},
	year = {2021},
	doi = {10.1007/978-3-658-33034-7_3},
	keywords = {/unread},
	pages = {27--57},
}

@inproceedings{chignoliRapidReliableQuadruped2022,
	title = {Rapid and {Reliable} {Quadruped} {Motion} {Planning} with {Omnidirectional} {Jumping}},
	doi = {10.1109/ICRA46639.2022.9812088},
	abstract = {Dynamic jumping with legged robots poses a challenging problem in planning and control. Formulating the jump optimization to allow fast online execution is difficult; efficiently using this capability to generate long-horizon motion plans further complicates the problem. In this work, we present a hierarchical planning framework to address this problem. We first formulate a real-time tractable trajectory optimization for performing omnidirectional jumping. We then embed the results of this optimization into a low dimensional jump feasibility classifier. This classifier is leveraged to produce geometric motion plans that select dynamically feasible jumps while mitigating the effects of the process noise. We deploy our framework on the Mini Cheetah Vision quadruped, demonstrating the robot's ability to generate and execute reliable, goal-oriented plans that involve forward, lateral, and rotational jumps onto surfaces as tall as the robot's nominal hip height. The ability to plan through omnidirectional jumping greatly expands the robot's mobility relative to planners that restrict jumping to the sagittal or frontal planes.},
	booktitle = {2022 {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Chignoli, Matthew and Morozov, Savva and Kim, Sangbae},
	month = may,
	year = {2022},
	note = {4 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread, Automation, Dynamics, Legged locomotion, Planning, Quadrupedal robots, Real-time systems, Reliability engineering},
	pages = {6621--6627},
}

@article{huangPlanningWalkingPatterns2001,
	title = {Planning walking patterns for a biped robot},
	volume = {17},
	issn = {2374-958X},
	doi = {10.1109/70.938385},
	abstract = {Biped robots have better mobility than conventional wheeled robots, but they tend to tip over easily. To be able to walk stably in various environments, such as on rough terrain, up and down slopes, or in regions containing obstacles, it is necessary for the robot to adapt to the ground conditions with a foot motion, and maintain its stability with a torso motion. When the ground conditions and stability constraint are satisfied, it is desirable to select a walking pattern that requires small torque and velocity of the joint actuators. We first formulate the constraints of the foot motion parameters. By varying the values of the constraint parameters, we can produce different types of foot motion to adapt to ground conditions. We then propose a method for formulating the problem of the smooth hip motion with the largest stability margin using only two parameters, and derive the hip trajectory by iterative computation. Finally, the correlation between the actuator specifications and the walking patterns is described through simulation studies, and the effectiveness of the proposed methods is confirmed by simulation examples and experimental results.},
	number = {3},
	journal = {IEEE Transactions on Robotics and Automation},
	author = {Huang, Qiang and Yokoi, K. and Kajita, S. and Kaneko, K. and Arai, H. and Koyachi, N. and Tanie, K.},
	month = jun,
	year = {2001},
	note = {901 citations (Semantic Scholar/DOI) [2023-04-11]
Conference Name: IEEE Transactions on Robotics and Automation},
	keywords = {/unread, Actuators, Computational modeling, Foot, Hip, Iterative methods, Legged locomotion, Mobile robots, Stability, Torque, Torso},
	pages = {280--289},
}

@inproceedings{chignoliOnlineTrajectoryOptimization2021,
	title = {Online {Trajectory} {Optimization} for {Dynamic} {Aerial} {Motions} of a {Quadruped} {Robot}},
	doi = {10.1109/ICRA48506.2021.9560855},
	abstract = {This work presents a two part framework for online planning and execution of dynamic aerial motions on a quadruped robot. Motions are planned via a centroidal momentum-based nonlinear optimization that is general enough to produce rich sets of novel dynamic motions based solely on the user-specified contact schedule and desired launch velocity of the robot. Since this nonlinear optimization is not tractable for real-time receding horizon control, motions are planned once via nonlinear optimization in preparation of an aerial motion and then tracked continuously using a variational-based optimal controller that offers robustness to the uncertainties that exist in the real hardware such as modeling error or disturbances. Motion planning typically takes between 0.05-0.15 s, while the optimal controller finds stabilizing feedback inputs at 500 Hz. Experimental results on the MIT Mini Cheetah demonstrate that the framework can reliably produce successful aerial motions such as jumps onto and off of platforms, spins, flips, barrel rolls, and running jumps over obstacles.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Chignoli, Matthew and Kim, Sangbae},
	month = may,
	year = {2021},
	note = {4 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2577-087X},
	keywords = {/unread, Dynamics, Legged locomotion, Reliability engineering, Robustness, Schedules, Tracking, Uncertainty},
	pages = {7693--7699},
}

@inproceedings{cebeOnlineDynamicTrajectory2021,
	title = {Online {Dynamic} {Trajectory} {Optimization} and {Control} for a {Quadruped} {Robot}},
	doi = {10.1109/ICRA48506.2021.9561592},
	abstract = {Legged robot locomotion requires the planning of stable reference trajectories, especially while traversing uneven terrain. The proposed trajectory optimization framework is capable of generating dynamically stable base and footstep trajectories for multiple steps. The locomotion task can be defined with contact locations, base motion or both, making the algorithm suitable for multiple scenarios (e.g., presence of moving obstacles). The planner uses a simplified momentum-based task space model for the robot dynamics, allowing computation times that are fast enough for online replanning. This fast planning capability also enables the quadruped to accommodate for drift and environmental changes. The algorithm is tested on simulation and a real robot across multiple scenarios, which includes uneven terrain, stairs and moving obstacles. The results show that the planner is capable of generating stable trajectories in the real robot even when a box of 15 cm height is placed in front of its path at the last moment.},
	booktitle = {2021 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Cebe, Oguzhan and Tiseo, Carlo and Xin, Guiyang and Lin, Hsiu-chin and Smith, Joshua and Mistry, Michael},
	month = may,
	year = {2021},
	note = {15 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2577-087X},
	keywords = {/unread, Computational modeling, Conferences, Dynamics, Heuristic algorithms, Legged locomotion, Planning, Stairs},
	pages = {12773--12779},
}

@article{jiOnlineReinforcementLearning2022,
	title = {Online reinforcement learning for the shape morphing adaptive control of {4D} printed shape memory polymer},
	volume = {126},
	issn = {0967-0661},
	url = {https://www.sciencedirect.com/science/article/pii/S096706612200123X},
	doi = {10.1016/j.conengprac.2022.105257},
	abstract = {Combining 3D printing and smart materials, 4D printing technologies enable the printed actuators to further change their shapes or other properties after prototyping. However, the shape morphing of 4D printed actuators suffers from poor controllability and low precision. One of the main challenges is that the 4D printed actuators are hard to be modeled and it is difficult to develop an appropriate controller for them. In this study, various popular reinforcement learning (RL) methods are applied to address the problem of online and adaptive model-free control of 4D printed shape memory polymer (SMP). Their training efficiencies are compared and an adaptive LQR controller based on Q learning is developed to realize efficient online learning. The RL controller achieves precise and quick shape control within 2−−3 learning episodes and is adaptive to the changing properties of SMP. The RL controller performance is then compared with a model-based LQR controller and shows high control precision and excellent adaptability to the varying control plant.},
	language = {en},
	urldate = {2022-11-16},
	journal = {Control Engineering Practice},
	author = {Ji, Qinglei and Wang, Xi Vincent and Wang, Lihui and Feng, Lei},
	month = sep,
	year = {2022},
	note = {3 citations (Semantic Scholar/DOI) [2023-04-11]
0 citations (Crossref) [2022-12-07]},
	keywords = {/unread, 4D printing, Closed loop control, Q-learning, Reinforcement learning, Shape memory polymer},
	pages = {105257},
}

@article{forsterOnManifoldPreintegrationRealTime2017,
	title = {On-{Manifold} {Preintegration} for {Real}-{Time} {Visual}–{Inertial} {Odometry}},
	volume = {33},
	issn = {1941-0468},
	doi = {10.1109/TRO.2016.2597321},
	abstract = {Current approaches for visual-inertial odometry (VIO) are able to attain highly accurate state estimation via nonlinear optimization. However, real-time optimization quickly becomes infeasible as the trajectory grows over time; this problem is further emphasized by the fact that inertial measurements come at high rate, hence, leading to the fast growth of the number of variables in the optimization. In this paper, we address this issue by preintegrating inertial measurements between selected keyframes into single relative motion constraints. Our first contribution is a preintegration theory that properly addresses the manifold structure of the rotation group. We formally discuss the generative measurement model as well as the nature of the rotation noise and derive the expression for the maximum a posteriori state estimator. Our theoretical development enables the computation of all necessary Jacobians for the optimization and a posteriori bias correction in analytic form. The second contribution is to show that the preintegrated inertial measurement unit model can be seamlessly integrated into a visual-inertial pipeline under the unifying framework of factor graphs. This enables the application of incremental-smoothing algorithms and the use of a structureless model for visual measurements, which avoids optimizing over the 3-D points, further accelerating the computation. We perform an extensive evaluation of our monocular VIO pipeline on real and simulated datasets. The results confirm that our modeling effort leads to an accurate state estimation in real time, outperforming state-of-the-art approaches.},
	number = {1},
	journal = {IEEE Transactions on Robotics},
	author = {Forster, Christian and Carlone, Luca and Dellaert, Frank and Scaramuzza, Davide},
	month = feb,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Robotics},
	keywords = {/unread, Computational modeling, Computer vision, Estimation, Jacobian matrices, Manifolds, Optimization, Real-time systems, Smoothing methods, sensor fusion, visual–inertial odometry (VIO)},
	pages = {1--21},
}

@inproceedings{nagabandiNeuralNetworkDynamics2018,
	title = {Neural {Network} {Dynamics} for {Model}-{Based} {Deep} {Reinforcement} {Learning} with {Model}-{Free} {Fine}-{Tuning}},
	doi = {10.1109/ICRA.2018.8463189},
	abstract = {Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that neural network dynamics models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits that accomplish various complex locomotion tasks. We further propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We empirically demonstrate on MuJoCo locomotion tasks that our pure model-based approach trained on just random action data can follow arbitrary trajectories with excellent sample efficiency, and that our hybrid algorithm can accelerate model-free learning on high-speed benchmark tasks, achieving sample efficiency gains of 3-5× on swimmer, cheetah, hopper, and ant agents. Videos can be found at https://sites.google.com/view/mbmf.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S. and Levine, Sergey},
	month = may,
	year = {2018},
	note = {729 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2577-087X},
	keywords = {/unread, Complexity theory, Data models, Heuristic algorithms, Machine learning, Neural networks, Predictive models, Task analysis},
	pages = {7559--7566},
}

@misc{levineOfflineReinforcementLearning2020,
	title = {Offline {Reinforcement} {Learning}: {Tutorial}, {Review}, and {Perspectives} on {Open} {Problems}},
	shorttitle = {Offline {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/2005.01643},
	abstract = {In this tutorial article, we aim to provide the reader with the conceptual tools needed to get started on research on offline reinforcement learning algorithms: reinforcement learning algorithms that utilize previously collected data, without additional online data collection. Offline reinforcement learning algorithms hold tremendous promise for making it possible to turn large datasets into powerful decision making engines. Effective offline reinforcement learning methods would be able to extract policies with the maximum possible utility out of the available data, thereby allowing automation of a wide range of decision-making domains, from healthcare and education to robotics. However, the limitations of current algorithms make this difficult. We will aim to provide the reader with an understanding of these challenges, particularly in the context of modern deep reinforcement learning methods, and describe some potential solutions that have been explored in recent work to mitigate these challenges, along with recent applications, and a discussion of perspectives on open problems in the field.},
	urldate = {2023-03-22},
	publisher = {arXiv},
	author = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
	month = nov,
	year = {2020},
	note = {858 citations (Semantic Scholar/arXiv) [2023-04-11]
arXiv:2005.01643 [cs, stat]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{hashemiMultibodyDynamicsControl2023,
	title = {Multibody dynamics and control using machine learning},
	issn = {1573-272X},
	url = {https://doi.org/10.1007/s11044-023-09884-x},
	doi = {10.1007/s11044-023-09884-x},
	abstract = {Artificial intelligence and mechanical engineering are two mature fields of science that intersect more and more often. Computer-aided mechanical analysis tools, including multibody dynamics software, are very versatile and have revolutionalized many industries. However, as shown by the literature presented in this review, combining the advantages of multibody system dynamics and machine learning creates new and exciting possibilities. For example, the multibody method can assist machine learning by providing synthetic data, while machine learning can provide fast and accurate subsystem models. The intersection of both approaches results in surrogate and hybrid modeling techniques, advanced control algorithms, and optimal design applications. A notable example is the development of autonomous systems for vehicles, robots, and mobile machinery. In our review we have found nontrivial, innovative, and even surprising applications of machine learning and multibody dynamics. This review focuses on applying neural networks, mainly deep learning, in connection with the multibody system method. Over one hundred and fifty papers are covered, and three main research areas are identified and introduced: data-driven modeling, model-based control and estimation, and data-driven control. The paper starts with a primer on machine learning and concludes with future research directions. The main goal is to provide a comprehensive and up-to-date review of existing literature to inspire further research.},
	language = {en},
	urldate = {2023-03-27},
	journal = {Multibody System Dynamics},
	author = {Hashemi, Arash and Orzechowski, Grzegorz and Mikkola, Aki and McPhee, John},
	month = feb,
	year = {2023},
	note = {0 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread, Data-driven control, Data-driven modeling, Deep learning, Machine learning, Model-based control, Multibody system dynamics},
}

@article{wangMotionPlanningBased2016,
	title = {Motion {Planning} {Based} on {Learning} {From} {Demonstration} for {Multiple}-{Segment} {Flexible} {Soft} {Robots} {Actuated} by {Electroactive} {Polymers}},
	volume = {1},
	issn = {2377-3766},
	doi = {10.1109/LRA.2016.2521384},
	abstract = {Multiple-segment flexible and soft robotic arms composed by ionic polymer–metal composite (IPMC) flexible actuators exhibit compliance but suffer from the difficulty of path planning due to their redundant degrees of freedom, although they are promising in complex tasks such as crossing body cavities to grasp objects. We propose a learning from demonstration method to plan the motion paths of IPMC-based manipulators, by statistics machine-learning algorithms. To encode demonstrated trajectories and estimate suitable paths for the manipulators to reproduce the task, models are built based on Gaussian mixture model and Gaussian mixture regression, respectively. The forward and inverse kinematic models of IPMC-based soft robotic arm are derived for the motion control. A flexible and soft robotic manipulator is implemented with six IPMC segments, and it verifies the learned paths by successfully completing a representative task of navigating through a narrow keyhole.},
	number = {1},
	journal = {IEEE Robotics and Automation Letters},
	author = {Wang, Hongqiang and Chen, Jie and Lau, Henry Y. K. and Ren, Hongliang},
	month = jan,
	year = {2016},
	note = {59 citations (Semantic Scholar/DOI) [2023-04-11]
45 citations (Crossref) [2022-12-07]
Conference Name: IEEE Robotics and Automation Letters},
	keywords = {/unread, Actuators, Electrodes, Flexible soft robot, Kinematics, Manipulators, Motion segmentation, Path planning, flexible soft robot, ionic polymer-metal composite, ionic polymer–metal composite, learning from demonstration, motion planning},
	pages = {391--398},
}

@article{gromovModelingControlRobotic2019,
	series = {12th {IFAC} {Symposium} on {Advances} in {Control} {Education} {ACE} 2019},
	title = {Modeling and {Control} of {Robotic} {Systems} {Course}: from {Fundamentals} to {Applications}},
	volume = {52},
	issn = {2405-8963},
	shorttitle = {Modeling and {Control} of {Robotic} {Systems} {Course}},
	url = {https://www.sciencedirect.com/science/article/pii/S2405896319305415},
	doi = {10.1016/j.ifacol.2019.08.204},
	abstract = {In this paper the Modeling and Control of Robotic Systems course to build the set of the professional skills is presented. This course is included in the curriculum of the master’s degree program and provided at the Faculty of Control Systems and Robotics of ITMO University. The selection of the tracks to build the professional skills are presented. An important part of the tracks is a using various technical equipment to build the skills and experience.},
	language = {en},
	number = {9},
	urldate = {2023-04-13},
	journal = {IFAC-PapersOnLine},
	author = {Gromov, Vladislav S. and Borisov, Oleg I. and Shavetov, Sergey S. and Pyrkin, Anton A. and Karashaeva, Fatimat B.},
	month = jan,
	year = {2019},
	keywords = {/unread, Control application, Control education, Industrial robots, Robotics, Ship control},
	pages = {224--229},
}

@phdthesis{deModularHoppingRunning2017,
	title = {Modular {Hopping} and {Running} via {Parallel} {Composition}},
	abstract = {Though multi-functional robot hardware has been created, the complexity in its functionality has been constrained by a lack of algorithms that appropriately manage flexible and autonomous reconfiguration of interconnections to physical and behavioral components.},
	language = {en},
	school = {University of Pennsylvania},
	author = {De, Avik},
	year = {2017},
	keywords = {/unread},
}

@inproceedings{calisirModelFreeReinforcementLearning2019,
	title = {Model-{Free} {Reinforcement} {Learning} {Algorithms}: {A} {Survey}},
	shorttitle = {Model-{Free} {Reinforcement} {Learning} {Algorithms}},
	doi = {10.1109/SIU.2019.8806389},
	abstract = {This paper aims to provide a comprehensive survey of the reinforcement learning algorithms given in the literature. Especially model-free reinforcement learning algorithms are given in details and the differences of these algorithms are handled. Finally, some open problems in reinforcement learning are presented for future researches.},
	booktitle = {2019 27th {Signal} {Processing} and {Communications} {Applications} {Conference} ({SIU})},
	author = {Çalışır, Sinan and Pehlivanoğlu, Meltem Kurt},
	month = apr,
	year = {2019},
	note = {13 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2165-0608},
	keywords = {/unread, Dogs, Markov processes, Monte Carlo methods, Noise measurement, Optimization, Reinforcement learning, Robots, artificial intelligence, deep reinforcement learning, learning, reinforcement learning algorithms},
	pages = {1--4},
}

@article{moerlandModelbasedReinforcementLearning2023,
	title = {Model-based {Reinforcement} {Learning}: {A} {Survey}},
	volume = {16},
	issn = {1935-8237, 1935-8245},
	shorttitle = {Model-based {Reinforcement} {Learning}},
	url = {https://www.nowpublishers.com/article/Details/MAL-086},
	doi = {10.1561/2200000086},
	abstract = {Model-based Reinforcement Learning: A Survey},
	language = {English},
	number = {1},
	urldate = {2023-03-22},
	journal = {Foundations and Trends® in Machine Learning},
	author = {Moerland, Thomas M. and Broekens, Joost and Plaat, Aske and Jonker, Catholijn M.},
	month = jan,
	year = {2023},
	note = {Publisher: Now Publishers, Inc.},
	keywords = {/unread},
	pages = {1--118},
}

@incollection{rayModelBasedReinforcementLearning2010,
	address = {Boston, MA},
	title = {Model-{Based} {Reinforcement} {Learning}},
	isbn = {978-0-387-30164-8},
	url = {https://doi.org/10.1007/978-0-387-30164-8_556},
	language = {en},
	urldate = {2022-11-07},
	booktitle = {Encyclopedia of {Machine} {Learning}},
	publisher = {Springer US},
	author = {Ray, Soumya and Tadepalli, Prasad},
	editor = {Sammut, Claude and Webb, Geoffrey I.},
	year = {2010},
	doi = {10.1007/978-0-387-30164-8_556},
	keywords = {/unread},
	pages = {690--693},
}

@article{zhangModelPredictiveControl2023,
	title = {Model {Predictive} {Control} of {Quadruped} {Robot} {Based} on {Reinforcement} {Learning}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/13/1/154},
	doi = {10.3390/app13010154},
	abstract = {For the locomotion control of a legged robot, both model predictive control (MPC) and reinforcement learning (RL) demonstrate powerful capabilities. MPC transfers the high-level task to the lower-level joint control based on the understanding of the robot and environment, model-free RL learns how to work through trial and error, and has the ability to evolve based on historical data. In this work, we proposed a novel framework to integrate the advantages of MPC and RL, we learned a policy for automatically choosing parameters for MPC. Unlike the end-to-end RL applications for control, our method does not need massive sampling data for training. Compared with the fixed parameters MPC, the learned MPC exhibits better locomotion performance and stability. The presented framework provides a new choice for improving the performance of traditional control.},
	language = {en},
	number = {1},
	urldate = {2023-05-16},
	journal = {Applied Sciences},
	author = {Zhang, Zhitong and Chang, Xu and Ma, Hongxu and An, Honglei and Lang, Lin},
	month = jan,
	year = {2023},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {/unread, model predictive control, parameter adaptive, quadruped robot, reinforcement learning},
	pages = {154},
}

@article{rogersMaterialsMechanicsStretchable2010,
	title = {Materials and {Mechanics} for {Stretchable} {Electronics}},
	volume = {327},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.1182383},
	doi = {10.1126/science.1182383},
	abstract = {Recent advances in mechanics and materials provide routes to integrated circuits that can offer the electrical properties of conventional, rigid wafer-based technologies but with the ability to be stretched, compressed, twisted, bent, and deformed into arbitrary shapes. Inorganic and organic electronic materials in microstructured and nanostructured forms, intimately integrated with elastomeric substrates, offer particularly attractive characteristics, with realistic pathways to sophisticated embodiments. Here, we review these strategies and describe applications of them in systems ranging from electronic eyeball cameras to deformable light-emitting displays. We conclude with some perspectives on routes to commercialization, new device opportunities, and remaining challenges for research.},
	language = {en},
	number = {5973},
	urldate = {2022-12-07},
	journal = {Science},
	author = {Rogers, John A. and Someya, Takao and Huang, Yonggang},
	month = mar,
	year = {2010},
	note = {3877 citations (Semantic Scholar/DOI) [2023-04-11]
3618 citations (Crossref) [2022-12-07]},
	keywords = {/unread},
	pages = {1603--1607},
}

@article{yangMagneticActuationSystems2020,
	title = {Magnetic {Actuation} {Systems} for {Miniature} {Robots}: {A} {Review}},
	volume = {2},
	copyright = {© 2020 The Authors. Published by WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim},
	issn = {2640-4567},
	shorttitle = {Magnetic {Actuation} {Systems} for {Miniature} {Robots}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aisy.202000082},
	doi = {10.1002/aisy.202000082},
	abstract = {A magnetic field, which is transparent and relatively safe to biological tissue, is a powerful tool for remote actuation and wireless control of magnetic devices. Furthermore, miniature robots can access complex and narrow regions of the human body as well as manipulate down to subcellular entities; however, integrating onboard components is difficult due to their limited size. Combining these two technologies, magnetic miniature robots have undergone rapid development during the past two decades, mainly because of their high potential in medical and bioengineering applications. To improve the scientific and clinical outcomes of these tiny agents, developing suitable and reliable actuation systems is essential. As a newly emerging field that has progressed in recent years, magnetic actuation systems offer a harmless and effective approach for the remote control of miniature robots via a dynamic magnetic field. Herein, a review on the state-of-the-art magnetic actuation systems for miniature robots is presented with the goal of providing readers with a better understanding of magnetic actuation and guidance for future system design.},
	language = {en},
	number = {9},
	urldate = {2023-07-03},
	journal = {Advanced Intelligent Systems},
	author = {Yang, Zhengxin and Zhang, Li},
	year = {2020},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/aisy.202000082},
	keywords = {/unread, biomedical applications, magnetic actuation, medical robots and systems, microrobots, miniature robots},
	pages = {2000082},
}

@article{hewingLearningbasedModelPredictive2020,
	title = {Learning-based model predictive control: {Toward} safe learning in control},
	volume = {3},
	shorttitle = {Learning-based model predictive control},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Hewing, Lukas and Wabersich, Kim P. and Menner, Marcel and Zeilinger, Melanie N.},
	year = {2020},
	note = {Publisher: Annual Reviews},
	keywords = {/unread, Review},
	pages = {269--296},
}

@misc{bemporadLinearTimevaryingNonlinear2022,
	address = {Piazza San Francesco 19, Lucca, Italy},
	title = {Linear time-varying and nonlinear {MPC}},
	url = {http://cse.lab.imtlucca.it/~bemporad/teaching/mpc/imt/2-ltv_nl_mpc.pdf},
	language = {en},
	urldate = {2022-12-13},
	author = {Bemporad, Alberto},
	month = mar,
	year = {2022},
	keywords = {/unread},
}

@article{mikiLearningRobustPerceptive2022,
	title = {Learning robust perceptive locomotion for quadrupedal robots in the wild},
	volume = {7},
	issn = {2470-9476},
	url = {https://www.science.org/doi/10.1126/scirobotics.abk2822},
	doi = {10.1126/scirobotics.abk2822},
	abstract = {Legged robots that can operate autonomously in remote and hazardous environments will greatly increase opportunities for exploration into underexplored areas. Exteroceptive perception is crucial for fast and energy-efficient locomotion: Perceiving the terrain before making contact with it enables planning and adaptation of the gait ahead of time to maintain speed and stability. However, using exteroceptive perception robustly for locomotion has remained a grand challenge in robotics. Snow, vegetation, and water visually appear as obstacles on which the robot cannot step or are missing altogether due to high reflectance. In addition, depth perception can degrade due to difficult lighting, dust, fog, reflective or transparent surfaces, sensor occlusion, and more. For this reason, the most robust and general solutions to legged locomotion to date rely solely on proprioception. This severely limits locomotion speed because the robot has to physically feel out the terrain before adapting its gait accordingly. Here, we present a robust and general solution to integrating exteroceptive and proprioceptive perception for legged locomotion. We leverage an attention-based recurrent encoder that integrates proprioceptive and exteroceptive input. The encoder is trained end to end and learns to seamlessly combine the different perception modalities without resorting to heuristics. The result is a legged locomotion controller with high robustness and speed. The controller was tested in a variety of challenging natural and urban environments over multiple seasons and completed an hour-long hike in the Alps in the time recommended for human hikers.
          , 
            A legged locomotion controller achieves high robustness and speed in the wild by combining multimodal information.},
	language = {en},
	number = {62},
	urldate = {2022-12-07},
	journal = {Science Robotics},
	author = {Miki, Takahiro and Lee, Joonho and Hwangbo, Jemin and Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco},
	month = jan,
	year = {2022},
	note = {140 citations (Semantic Scholar/DOI) [2023-04-11]
27 citations (Crossref) [2022-12-07]},
	keywords = {/unread},
	pages = {eabk2822},
}

@misc{haarnojaLearningWalkDeep2019,
	title = {Learning to {Walk} via {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1812.11103},
	abstract = {Deep reinforcement learning (deep RL) holds the promise of automating the acquisition of complex controllers that can map sensory inputs directly to low-level actions. In the domain of robotic locomotion, deep RL could enable learning locomotion skills with minimal engineering and without an explicit model of the robot dynamics. Unfortunately, applying deep RL to real-world robotic tasks is exceptionally difficult, primarily due to poor sample complexity and sensitivity to hyperparameters. While hyperparameters can be easily tuned in simulated domains, tuning may be prohibitively expensive on physical systems, such as legged robots, that can be damaged through extensive trial-and-error learning. In this paper, we propose a sample-efficient deep RL algorithm based on maximum entropy RL that requires minimal per-task tuning and only a modest number of trials to learn neural network policies. We apply this method to learning walking gaits on a real-world Minitaur robot. Our method can acquire a stable gait from scratch directly in the real world in about two hours, without relying on any model or simulation, and the resulting policy is robust to moderate variations in the environment. We further show that our algorithm achieves state-of-the-art performance on simulated benchmarks with a single set of hyperparameters. Videos of training and the learned policy can be found on the project website.},
	urldate = {2023-06-15},
	publisher = {arXiv},
	author = {Haarnoja, Tuomas and Ha, Sehoon and Zhou, Aurick and Tan, Jie and Tucker, George and Levine, Sergey},
	month = jun,
	year = {2019},
	note = {arXiv:1812.11103 [cs, stat]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
}

@article{shaoLearningFreeGait2022,
	title = {Learning {Free} {Gait} {Transition} for {Quadruped} {Robots} {Via} {Phase}-{Guided} {Controller}},
	volume = {7},
	issn = {2377-3766},
	doi = {10.1109/LRA.2021.3136645},
	abstract = {Gaits and transitions are key components in legged locomotion. For legged robots, describing and reproducing gaits as well as transitions remain longstanding challenges. Reinforcement learning has become a powerful tool to formulate controllers for legged robots. Learning multiple gaits and transitions, nevertheless, is related to the multi-task learning problems. In this work, we present a novel framework for training a simple control policy for a quadruped robot to locomote in various gaits. Four independent phases are used as the interface between the gait generator and the control policy, which characterizes the movement of four feet. Guided by the phases, the quadruped robot is able to locomote according to the generated gaits, such as walk, trot, pacing and bounding, and to make transitions among those gaits. More general phases can be used to generate complex gaits, such as mixed rhythmic dancing. With the control policy, the Black Panther robot, a medium-dog-sized quadruped robot, can perform all learned motor skills while following the velocity commands smoothly and robustly in natural environment.},
	number = {2},
	journal = {IEEE Robotics and Automation Letters},
	author = {Shao, Yecheng and Jin, Yongbin and Liu, Xianwei and He, Weiyan and Wang, Hongtao and Yang, Wei},
	month = apr,
	year = {2022},
	note = {14 citations (Semantic Scholar/DOI) [2023-04-11]
Conference Name: IEEE Robotics and Automation Letters},
	keywords = {/unread, Foot, Legged locomotion, Oscillators, Quadrupedal robots, Reinforcement learning, Robots, Task analysis, Training, legged robots, machine learning for robot control},
	pages = {1230--1237},
}

@article{hwangboLearningAgileDynamic2019,
	title = {Learning agile and dynamic motor skills for legged robots},
	volume = {4},
	issn = {2470-9476},
	url = {https://www.science.org/doi/10.1126/scirobotics.aau5872},
	doi = {10.1126/scirobotics.aau5872},
	abstract = {A method for learning agile control policies uses simulated data to enable precise, efficient movements in a complex physical robot.
          , 
            Legged robots pose one of the greatest challenges in robotics. Dynamic and agile maneuvers of animals cannot be imitated by existing methods that are crafted by humans. A compelling alternative is reinforcement learning, which requires minimal craftsmanship and promotes the natural evolution of a control policy. However, so far, reinforcement learning research for legged robots is mainly limited to simulation, and only few and comparably simple examples have been deployed on real systems. The primary reason is that training with real robots, particularly with dynamically balancing systems, is complicated and expensive. In the present work, we introduce a method for training a neural network policy in simulation and transferring it to a state-of-the-art legged system, thereby leveraging fast, automated, and cost-effective data generation schemes. The approach is applied to the ANYmal robot, a sophisticated medium-dog–sized quadrupedal system. Using policies trained in simulation, the quadrupedal machine achieves locomotion skills that go beyond what had been achieved with prior methods: ANYmal is capable of precisely and energy-efficiently following high-level body velocity commands, running faster than before, and recovering from falling even in complex configurations.},
	language = {en},
	number = {26},
	urldate = {2023-04-24},
	journal = {Science Robotics},
	author = {Hwangbo, Jemin and Lee, Joonho and Dosovitskiy, Alexey and Bellicoso, Dario and Tsounis, Vassilios and Koltun, Vladlen and Hutter, Marco},
	month = jan,
	year = {2019},
	keywords = {/unread},
	pages = {eaau5872},
}

@article{bechtelGroundingCognitionHeterarchical2021,
	title = {Grounding cognition: heterarchical control mechanisms in biology},
	volume = {376},
	shorttitle = {Grounding cognition},
	url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0751},
	doi = {10.1098/rstb.2019.0751},
	abstract = {We advance an account that grounds cognition, specifically decision-making, in an activity all organisms as autonomous systems must perform to keep themselves viable—controlling their production mechanisms. Production mechanisms, as we characterize them, perform activities such as procuring resources from their environment, putting these resources to use to construct and repair the organism's body and moving through the environment. Given the variable nature of the environment and the continual degradation of the organism, these production mechanisms must be regulated by control mechanisms that select when a production is required and how it should be carried out. To operate on production mechanisms, control mechanisms need to procure information through measurement processes and evaluate possible actions. They are making decisions. In all organisms, these decisions are made by multiple different control mechanisms that are organized not hierarchically but heterarchically. In many cases, they employ internal models of features of the environment with which the organism must deal. Cognition, in the form of decision-making, is thus fundamental to living systems which must control their production mechanisms.

This article is part of the theme issue ‘Basal cognition: conceptual tools and the view from the single cell’.},
	number = {1820},
	urldate = {2023-07-06},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Bechtel, William and Bich, Leonardo},
	month = jan,
	year = {2021},
	note = {Publisher: Royal Society},
	keywords = {/unread, chemotaxis, circadian rhythms, control mechanisms, decision-making, production mechanisms},
	pages = {20190751},
}

@misc{openaiGPT4TechnicalReport2023,
	title = {{GPT}-4 {Technical} {Report}},
	url = {http://arxiv.org/abs/2303.08774},
	doi = {10.48550/arXiv.2303.08774},
	abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
	urldate = {2023-07-03},
	publisher = {arXiv},
	author = {OpenAI},
	month = mar,
	year = {2023},
	note = {arXiv:2303.08774 [cs]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{liGaitPlanningStability2016,
	title = {Gait {Planning} and {Stability} {Control} of a {Quadruped} {Robot}},
	volume = {2016},
	issn = {1687-5265},
	url = {https://www.hindawi.com/journals/cin/2016/9853070/},
	doi = {10.1155/2016/9853070},
	abstract = {In order to realize smooth gait planning and stability control of a quadruped robot, a new controller algorithm based on CPG-ZMP (central pattern generator-zero moment point) is put forward in this paper. To generate smooth gait and shorten the adjusting time of the model oscillation system, a new CPG model controller and its gait switching strategy based on Wilson-Cowan model are presented in the paper. The control signals of knee-hip joints are obtained by the improved multi-DOF reduced order control theory. To realize stability control, the adaptive speed adjustment and gait switch are completed by the real-time computing of ZMP. Experiment results show that the quadruped robot’s gaits are efficiently generated and the gait switch is smooth in the CPG control algorithm. Meanwhile, the stability of robot’s movement is improved greatly with the CPG-ZMP algorithm. The algorithm in this paper has good practicability, which lays a foundation for the production of the robot prototype.},
	language = {en},
	urldate = {2023-05-16},
	journal = {Computational Intelligence and Neuroscience},
	author = {Li, Junmin and Wang, Jinge and Yang, Simon X. and Zhou, Kedong and Tang, Huijuan},
	month = apr,
	year = {2016},
	note = {Publisher: Hindawi},
	keywords = {/unread},
	pages = {e9853070},
}

@article{zhangFindingCriticalScenarios2023,
	title = {Finding {Critical} {Scenarios} for {Automated} {Driving} {Systems}: {A} {Systematic} {Mapping} {Study}},
	volume = {49},
	issn = {1939-3520},
	shorttitle = {Finding {Critical} {Scenarios} for {Automated} {Driving} {Systems}},
	doi = {10.1109/TSE.2022.3170122},
	abstract = {Scenario-based approaches have been receiving a huge amount of attention in research and engineering of automated driving systems. Due to the complexity and uncertainty of the driving environment, and the complexity of the driving task itself, the number of possible driving scenarios that an Automated Driving System or Advanced Driving-Assistance System may encounter is virtually infinite. Therefore it is essential to be able to reason about the identification of scenarios and in particular critical ones that may impose unacceptable risk if not considered. Critical scenarios are particularly important to support design, verification and validation efforts, and as a basis for a safety case. In this paper, we present the results of a systematic mapping study in the context of autonomous driving. The main contributions are: (i) introducing a comprehensive taxonomy for critical scenario identification methods; (ii) giving an overview of the state-of-the-art research based on the taxonomy encompassing 86 papers between 2017 and 2020; and (iii) identifying open issues and directions for further research. The provided taxonomy comprises three main perspectives encompassing the problem definition (the why), the solution (the methods to derive scenarios), and the assessment of the established scenarios. In addition, we discuss open research issues considering the perspectives of coverage, practicability, and scenario space explosion.},
	number = {3},
	journal = {IEEE Transactions on Software Engineering},
	author = {Zhang, Xinhai and Tao, Jianbo and Tan, Kaige and Törngren, Martin and Sánchez, José Manuel Gaspar and Ramli, Muhammad Rusyadi and Tao, Xin and Gyllenhammar, Magnus and Wotawa, Franz and Mohan, Naveen and Nica, Mihai and Felbinger, Hermann},
	month = mar,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Software Engineering},
	keywords = {/unread, Bibliographies, Complexity theory, Critical scenario, Roads, Systematics, Taxonomy, Terminology, Uncertainty, automated driving, systematic mapping study},
	pages = {991--1026},
}

@article{langExplorationRelationalDomains2012,
	title = {Exploration in {Relational} {Domains} for {Model}-based {Reinforcement} {Learning}},
	volume = {13},
	abstract = {A fundamental problem in reinforcement learning is balancing exploration and exploitation. We address this problem in the context of model-based reinforcement learning in large stochastic relational domains by developing relational extensions of the concepts of the E3 and R-MAX algorithms. Efﬁcient exploration in exponentially large state spaces needs to exploit the generalization of the learned model: what in a propositional setting would be considered a novel situation and worth exploration may in the relational setting be a well-known context in which exploitation is promising. To address this we introduce relational count functions which generalize the classical notion of state and action visitation counts. We provide guarantees on the exploration efﬁciency of our framework using count functions under the assumption that we had a relational KWIK learner and a near-optimal planner. We propose a concrete exploration algorithm which integrates a practically efﬁcient probabilistic rule learner and a relational planner (for which there are no guarantees, however) and employs the contexts of learned relational rules as features to model the novelty of states and actions. Our results in noisy 3D simulated robot manipulation problems and in domains of the international planning competition demonstrate that our approach is more effective than existing propositional and factored exploration techniques.},
	language = {en},
	journal = {Journal of Machine Learning Research},
	author = {Lang, Tobias and Toussaint, Marc and Kersting, Kristian},
	month = dec,
	year = {2012},
	keywords = {/unread},
	pages = {3725--3768},
}

@article{wangEfficientLearningRobust2022,
	title = {Efficient learning of robust quadruped bounding using pretrained neural networks},
	volume = {4},
	issn = {2631-6315},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/csy2.12062},
	doi = {10.1049/csy2.12062},
	abstract = {Bounding is one of the important gaits in quadrupedal locomotion for negotiating obstacles. The authors proposed an effective approach that can learn robust bounding gaits more efficiently despite its large variation in dynamic body movements. The authors first pretrained the neural network (NN) based on data from a robot operated by conventional model-based controllers, and then further optimised the pretrained NN via deep reinforcement learning (DRL). In particular, the authors designed a reward function considering contact points and phases to enforce the gait symmetry and periodicity, which improved the bounding performance. The NN-based feedback controller was learned in the simulation and directly deployed on the real quadruped robot Jueying Mini successfully. A variety of environments are presented both indoors and outdoors with the authors’ approach. The authors’ approach shows efficient computing and good locomotion results by the Jueying Mini quadrupedal robot bounding over uneven terrain. The cover image is based on the Research Article Efficient learning of robust quadruped bounding using pretrained neural networks by Zhicheng Wang et al., https://doi.org/10.1049/csy2.12062.},
	language = {en},
	number = {4},
	urldate = {2023-03-27},
	journal = {IET Cyber-Systems and Robotics},
	author = {Wang, Zhicheng and Li, Anqiao and Zheng, Yixiao and Xie, Anhuan and Li, Zhibin and Wu, Jun and Zhu, Qiuguo},
	year = {2022},
	note = {0 citations (Semantic Scholar/DOI) [2023-04-11]
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1049/csy2.12062},
	keywords = {/unread, legged locomotion, reinforcement learning, robot learning},
	pages = {331--338},
}

@inproceedings{dicarloDynamicLocomotionMIT2018,
	title = {Dynamic {Locomotion} in the {MIT} {Cheetah} 3 {Through} {Convex} {Model}-{Predictive} {Control}},
	doi = {10.1109/IROS.2018.8594448},
	abstract = {This paper presents an implementation of model predictive control (MPC) to determine ground reaction forces for a torque-controlled quadruped robot. The robot dynamics are simplified to formulate the problem as convex optimization while still capturing the full 3D nature of the system. With the simplified model, ground reaction force planning problems are formulated for prediction horizons of up to 0.5 seconds, and are solved to optimality in under 1 ms at a rate of 20-30 Hz. Despite using a simplified model, the robot is capable of robust locomotion at a variety of speeds. Experimental results demonstrate control of gaits including stand, trot, flying-trot, pronk, bound, pace, a 3-legged gait, and a full 3D gallop. The robot achieved forward speeds of up to 3 m/s, lateral speeds up to 1 m/s, and angular speeds up to 180 deg/sec. Our approach is general enough to perform all these behaviors with the same set of gains and weights.},
	booktitle = {2018 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Di Carlo, Jared and Wensing, Patrick M. and Katz, Benjamin and Bledt, Gerardo and Kim, Sangbae},
	month = oct,
	year = {2018},
	note = {ISSN: 2153-0866},
	keywords = {/unread, Convex functions, Dynamics, Legged locomotion, Predictive control, Predictive models, Robot kinematics},
	pages = {1--9},
}

@article{biswalDevelopmentQuadrupedWalking2021,
	title = {Development of quadruped walking robots: {A} review},
	volume = {12},
	issn = {2090-4479},
	shorttitle = {Development of quadruped walking robots},
	url = {https://www.sciencedirect.com/science/article/pii/S2090447920302501},
	doi = {10.1016/j.asej.2020.11.005},
	abstract = {Nowadays, design, development, and motion planning of a mobile robot explore research areas in the field of robotics. Mobile robots have an extensive area of applications in various fields like space exploration, military application, industrial use, and many more. Hence, the design and development of a mobile robot is a crucial part of the above application. Among all the mobile robot, the quadrupedal robot is a legged robot, which is superior to wheeled and tracked robot due to its potential to explore in all the terrain like the human and animal. In this paper, the survey concentrates on various design and development approaches for the quadrupedal robot, and environment perception techniques are discussed. Besides, Spot is one of the most advanced and intelligent quadrupedal robots. The performance of each quadruped robot and the future outline are provided in details.},
	language = {en},
	number = {2},
	urldate = {2022-11-16},
	journal = {Ain Shams Engineering Journal},
	author = {Biswal, Priyaranjan and Mohanty, Prases K.},
	month = jun,
	year = {2021},
	note = {67 citations (Semantic Scholar/DOI) [2023-04-11]
35 citations (Crossref) [2022-12-07]},
	keywords = {/unread, Actuator, Gait, Legged robot, Payload, Quadruped robot},
	pages = {2017--2031},
}

@article{jiDevelopment3DPrinted2022,
	title = {Development of a {3D} {Printed} {Multi}-{Axial} {Force} {Sensor}},
	url = {https://ebooks.iospress.nl/doi/10.3233/ATDE220178},
	doi = {10.3233/ATDE220178},
	urldate = {2022-10-14},
	journal = {SPS2022},
	author = {Ji, Qinglei and Fu, Shuo and Feng, Lei and Andrikopoulos, Georgios and Wang, Xi Vincent and Wang, Lihui},
	year = {2022},
	note = {0 citations (Crossref) [2022-12-07]
Publisher: IOS Press},
	keywords = {/unread},
	pages = {604--614},
}

@inproceedings{huDesignQuadrupedInspection2021,
	title = {Design of a {Quadruped} inspection {Robot} {Used} in {Substation}},
	volume = {4},
	doi = {10.1109/IMCEC51613.2021.9482003},
	abstract = {Nowadays, the substation inspection robot always uses wheeled chassis, which is suitable for running on relatively flat road. However, there are steps, stone road, stairs and other complex terrain in substation, so it is difficult to achieve full coverage of inspection area. In order to solve this problem, a prototype system of quadruped inspection robot is designed, and the hardware and software structure and design points are described in detail. In addition, the software system architecture based on B/S mode is also discussed briefly. Finally, the designed robot proposed in this paper is tested in a 500kV substation to verify the adaptability of the quadruped inspection robot to the complex terrain of the environment.},
	booktitle = {2021 {IEEE} 4th {Advanced} {Information} {Management}, {Communicates}, {Electronic} and {Automation} {Control} {Conference} ({IMCEC})},
	author = {Hu, Xuran and He, Feng and Xiao, Peng and Wang, Tao and Zhang, Decai and Zhou, Xingfu and Fan, Yan},
	month = jun,
	year = {2021},
	note = {ISSN: 2693-2776},
	keywords = {/unread, Inspection, Roads, Stairs, Substations, Temperature control, Temperature distribution, Temperature measurement, inspection, quadruped robot, substation},
	pages = {766--769},
}

@article{rusDesignFabricationControl2015,
	title = {Design, fabrication and control of soft robots},
	volume = {521},
	copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14543},
	doi = {10.1038/nature14543},
	abstract = {Conventionally, engineers have employed rigid materials to fabricate precise, predictable robotic systems, which are easily modelled as rigid members connected at discrete joints. Natural systems, however, often match or exceed the performance of robotic systems with deformable bodies. Cephalopods, for example, achieve amazing feats of manipulation and locomotion without a skeleton; even vertebrates such as humans achieve dynamic gaits by storing elastic energy in their compliant bones and soft tissues. Inspired by nature, engineers have begun to explore the design and control of soft-bodied robots composed of compliant materials. This Review discusses recent developments in the emerging field of soft robotics.},
	language = {en},
	number = {7553},
	urldate = {2022-12-07},
	journal = {Nature},
	author = {Rus, Daniela and Tolley, Michael T.},
	month = may,
	year = {2015},
	note = {3251 citations (Semantic Scholar/DOI) [2023-04-11]
2961 citations (Crossref) [2022-12-07]
Number: 7553
Publisher: Nature Publishing Group},
	keywords = {/unread, Engineering, Technology},
	pages = {467--475},
}

@inproceedings{matlDeformableElastoPlasticObject2021,
	title = {Deformable {Elasto}-{Plastic} {Object} {Shaping} using an {Elastic} {Hand} and {Model}-{Based} {Reinforcement} {Learning}},
	doi = {10.1109/IROS51168.2021.9636808},
	abstract = {Deformable solid objects such as clay or dough are prevalent in industrial and home environments. However, robotic manipulation of such objects has largely remained unexplored in literature due to the high complexity involved in representing and modeling their deformation. This work addresses the problem of shaping elasto-plastic dough by proposing to use a novel elastic end-effector to roll dough in a reinforcement learning framework. The transition model for the end-effector-to-dough interactions is learned from one hour of robot exploration, and doughs of different hydration levels are rolled out into varying lengths. Experimental results are encouraging, with the proposed framework accomplishing the task of rolling out dough into a specified length with 60\% fewer actions than a heuristic method. Furthermore, we show that estimating stiffness using the soft end-effector can be used to effectively initialize models, improving robot performance by approximately 40\% over incorrect model initialization.},
	booktitle = {2021 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Matl, Carolyn and Bajcsy, Ruzena},
	month = sep,
	year = {2021},
	note = {6 citations (Semantic Scholar/DOI) [2023-04-11]
ISSN: 2153-0866},
	keywords = {/unread, Deformable models, End effectors, Reinforcement learning, Service robots, Shape, Solid modeling, Solids},
	pages = {3955--3962},
}

@article{arulkumaranDeepReinforcementLearning2017,
	title = {Deep {Reinforcement} {Learning}: {A} {Brief} {Survey}},
	volume = {34},
	issn = {1558-0792},
	shorttitle = {Deep {Reinforcement} {Learning}},
	doi = {10.1109/MSP.2017.2743240},
	abstract = {Deep reinforcement learning (DRL) is poised to revolutionize the field of artificial intelligence (AI) and represents a step toward building autonomous systems with a higher-level understanding of the visual world. Currently, deep learning is enabling reinforcement learning (RL) to scale to problems that were previously intractable, such as learning to play video games directly from pixels. DRL algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera inputs in the real world. In this survey, we begin with an introduction to the general field of RL, then progress to the main streams of value-based and policy-based methods. Our survey will cover central algorithms in deep RL, including the deep Q-network (DQN), trust region policy optimization (TRPO), and asynchronous advantage actor critic. In parallel, we highlight the unique advantages of deep neural networks, focusing on visual understanding via RL. To conclude, we describe several current areas of research within the field.},
	number = {6},
	journal = {IEEE Signal Processing Magazine},
	author = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
	month = nov,
	year = {2017},
	note = {1404 citations (Semantic Scholar/DOI) [2023-04-11]
1252 citations (Crossref) [2022-12-07]
Conference Name: IEEE Signal Processing Magazine},
	keywords = {/unread, Artificial intelligence, Learning (artificial intelligence), Machine learning, Neural networks, Signal processing algorithms, Visualization},
	pages = {26--38},
}

@article{rosoliaDataDrivenPredictiveControl2018,
	title = {Data-{Driven} {Predictive} {Control} for {Autonomous} {Systems}},
	volume = {1},
	url = {https://doi.org/10.1146/annurev-control-060117-105215},
	doi = {10.1146/annurev-control-060117-105215},
	abstract = {In autonomous systems, the ability to make forecasts and cope with uncertain predictions is synonymous with intelligence. Model predictive control (MPC) is an established control methodology that systematically uses forecasts to compute real-time optimal control decisions. In MPC, at each time step an optimization problem is solved over a moving horizon. The objective is to find a control policy that minimizes a predicted performance index while satisfying operating constraints. Uncertainty in MPC is handled by optimizing over multiple uncertain forecasts. In this case, performance index and operating constraints take the form of functions defined over a probability space, and the resulting technique is called stochastic MPC. Our research over the past 10 years has focused on predictive control design methods that systematically handle uncertain forecasts in autonomous and semiautonomous systems. In the first part of this article, we present an overview of the approach we use, its main advantages, and its challenges. In the second part, we present our most recent results on data-driven predictive control. We show how to use data to efficiently formulate stochastic MPC problems and autonomously improve performance in repetitive tasks. The proposed framework is able to handle a large set of predicted scenarios in real time and learn from historical data.},
	number = {1},
	urldate = {2023-03-09},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Rosolia, Ugo and Zhang, Xiaojing and Borrelli, Francesco},
	year = {2018},
	note = {50 citations (Semantic Scholar/DOI) [2023-04-11]
\_eprint: https://doi.org/10.1146/annurev-control-060117-105215},
	keywords = {/unread, Data-driven control, Review},
	pages = {259--286},
}

@misc{wuDayDreamerWorldModels2022,
	title = {{DayDreamer}: {World} {Models} for {Physical} {Robot} {Learning}},
	shorttitle = {{DayDreamer}},
	url = {http://arxiv.org/abs/2206.14176},
	abstract = {To solve tasks in complex environments, robots need to learn from experience. Deep reinforcement learning is a common approach to robot learning but requires a large amount of trial and error to learn, limiting its deployment in the physical world. As a consequence, many advances in robot learning rely on simulators. On the other hand, learning inside of simulators fails to capture the complexity of the real world, is prone to simulator inaccuracies, and the resulting behaviors do not adapt to changes in the world. The Dreamer algorithm has recently shown great promise for learning from small amounts of interaction by planning within a learned world model, outperforming pure reinforcement learning in video games. Learning a world model to predict the outcomes of potential actions enables planning in imagination, reducing the amount of trial and error needed in the real environment. However, it is unknown whether Dreamer can facilitate faster learning on physical robots. In this paper, we apply Dreamer to 4 robots to learn online and directly in the real world, without simulators. Dreamer trains a quadruped robot to roll off its back, stand up, and walk from scratch and without resets in only 1 hour. We then push the robot and find that Dreamer adapts within 10 minutes to withstand perturbations or quickly roll over and stand back up. On two different robotic arms, Dreamer learns to pick and place multiple objects directly from camera images and sparse rewards, approaching human performance. On a wheeled robot, Dreamer learns to navigate to a goal position purely from camera images, automatically resolving ambiguity about the robot orientation. Using the same hyperparameters across all experiments, we find that Dreamer is capable of online learning in the real world, establishing a strong baseline. We release our infrastructure for future applications of world models to robot learning.},
	urldate = {2022-11-21},
	publisher = {arXiv},
	author = {Wu, Philipp and Escontrela, Alejandro and Hafner, Danijar and Goldberg, Ken and Abbeel, Pieter},
	month = jun,
	year = {2022},
	note = {27 citations (Semantic Scholar/arXiv) [2023-04-11]
arXiv:2206.14176 [cs]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics},
}

@article{wangCurrentResearchesFuture2018,
	title = {Current {Researches} and {Future} {Development} {Trend} of {Intelligent} {Robot}: {A} {Review}},
	volume = {15},
	issn = {1751-8520},
	shorttitle = {Current {Researches} and {Future} {Development} {Trend} of {Intelligent} {Robot}},
	url = {https://doi.org/10.1007/s11633-018-1115-1},
	doi = {10.1007/s11633-018-1115-1},
	abstract = {With the advancing of industrialization and the advent of the information age, intelligent robots play an increasingly important role in intelligent manufacturing, intelligent transportation system, the Internet of things, medical health and intelligent services. Based on working experiences in and reviews on intelligent robot studies both in China and abroad, the authors summarized researches on key and leading technologies related to human-robot collaboration, driverless technology, emotion recognition, brain-computer interface, bionic software robot and cloud platform, big data network, etc. The development trend of intelligent robot was discussed, and reflections on and suggestions to intelligent robot development in China were proposed. The review is not only meant to overview leading technologies of intelligent robot all over the world, but also provide related theories, methods and technical guidance to the technological and industrial development of intelligent robot in China.},
	language = {en},
	number = {5},
	urldate = {2023-03-09},
	journal = {International Journal of Automation and Computing},
	author = {Wang, Tian-Miao and Tao, Yong and Liu, Hui},
	month = oct,
	year = {2018},
	note = {4 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread, Intelligent robot, big data network, brain-computer interface, driverless technology, emotion recognition, human-robot collaboration},
	pages = {525--546},
}

@phdthesis{thorapallimuralidharanContinuumActuatorBased2020,
	address = {Stockholm, Sweden},
	title = {Continuum {Actuator} {Based} {Soft} {Quadruped} {Robot}},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-286348},
	abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
	language = {eng},
	urldate = {2022-10-14},
	school = {KTH Royal Institute of Technology},
	author = {Thorapalli Muralidharan, Seshagopalan and Zhu, Ruihao},
	year = {2020},
	keywords = {/unread, Soft robot},
}

@article{wangControlStrategiesSoft2022,
	title = {Control {Strategies} for {Soft} {Robot} {Systems}},
	volume = {4},
	issn = {2640-4567},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aisy.202100165},
	doi = {10.1002/aisy.202100165},
	abstract = {Soft robots have recently attracted increased attention because their characteristics of low-cost fabrication, durability, and deformability make them uniquely suited for applications in bio-integrated systems. Being fundamentally different from traditional rigid robots, soft robots exhibit properties of infinite degrees of freedom (DOF) and nonlinear materials properties that require innovations in control systems. With the rapid development of materials science, robotics, and artificial intelligence, the diversification of actuator mechanisms and algorithms has enabled a wide range of unique control strategies. This review summarizes the basics of actuator mechanisms and control strategies, including open-loop control, closed-loop control, and autonomous control, and discusses their implementation from diversified perspectives. Control strategies are evaluated based on their compatibility with materials sets, application goals, and implementation route. The emerging directions are forecasted from the perspectives of interfacing between controller and actuator, underactuated control strategies, and implementation of artificial intelligence (AI).},
	language = {en},
	number = {5},
	urldate = {2022-12-07},
	journal = {Advanced Intelligent Systems},
	author = {Wang, Jue and Chortos, Alex},
	year = {2022},
	note = {15 citations (Semantic Scholar/DOI) [2023-04-11]
4 citations (Crossref) [2022-12-07]
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/aisy.202100165},
	keywords = {/unread, control strategies, soft actuators, soft robots, underactuated system},
	pages = {2100165},
}

@inproceedings{bledtContactModelFusion2018,
	title = {Contact {Model} {Fusion} for {Event}-{Based} {Locomotion} in {Unstructured} {Terrains}},
	doi = {10.1109/ICRA.2018.8460904},
	abstract = {As legged robots are sent into unstructured environments, the ability to robustly manage contact transitions will be a critical skill. This paper introduces an approach to probabilistically fuse contact models, managing uncertainty in terrain geometry, dynamic modeling, and kinematics to improve the robustness of contact initiation at touchdown. A discrete-time extension of the generalized-momentum disturbance observer is presented to increase the accuracy of proprioceptive force control estimates. This information is fused with other contact priors under a framework of Kalman Filtering to increase robustness of the method. This approach results in accurate contact detection with 99.3 \% accuracy and a small 4-5ms delay. Using this new detector, an Event-Based Finite State Machine is implemented to deal with unexpected early and late contacts. This allows the robot to traverse cluttered environments by modifying the control actions for each individual leg based on the estimated contact state rather than adhering to a rigid time schedule regardless of actual contact state. Experiments with the MIT Cheetah 3 robot show the success of both the detection algorithm, as well as the Event-Based FSM while making unexpected contacts during trotting.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Bledt, Gerardo and Wensing, Patrick M. and Ingersoll, Sam and Kim, Sangbae},
	month = may,
	year = {2018},
	note = {ISSN: 2577-087X},
	keywords = {/unread, Disturbance observers, Force, Legged locomotion, Robot sensing systems, Robustness},
	pages = {4399--4406},
}

@phdthesis{janssonClosedLoopControl3D2021,
	address = {Stockholm, Sweden},
	title = {Closed-{Loop} {Control} of a {3D} {Printed} {Soft} {Actuator} with {Soft} {Position} {Sensors}},
	url = {http://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-304748},
	abstract = {This thesis performs closed-loop control of a 3D printed soft bending actuator with feedback from a 3D printed strain sensor. This process utilizes the Finite Element Method (FEM) to design a bello ...},
	language = {eng},
	urldate = {2022-12-12},
	school = {KTH Royal Institute of Technology},
	author = {Jansson, Jakob and Sjöberg, Mikael},
	year = {2021},
	keywords = {Closed loop control, Soft actuators},
}

@article{lutterCombiningPhysicsDeep2023,
	title = {Combining physics and deep learning to learn continuous-time dynamics models},
	issn = {0278-3649},
	url = {https://doi.org/10.1177/02783649231169492},
	doi = {10.1177/02783649231169492},
	abstract = {Deep learning has been widely used within learning algorithms for robotics. One disadvantage of deep networks is that these networks are black-box representations. Therefore, the learned approximations ignore the existing knowledge of physics or robotics. Especially for learning dynamics models, these black-box models are not desirable as the underlying principles are well understood and the standard deep networks can learn dynamics that violate these principles. To learn dynamics models with deep networks that guarantee physically plausible dynamics, we introduce physics-inspired deep networks that combine first principles from physics with deep learning. We incorporate Lagrangian mechanics within the model learning such that all approximated models adhere to the laws of physics and conserve energy. Deep Lagrangian Networks (DeLaN) parametrize the system energy using two networks. The parameters are obtained by minimizing the squared residual of the Euler?Lagrange differential equation. Therefore, the resulting model does not require specific knowledge of the individual system, is interpretable, and can be used as a forward, inverse, and energy model. Previously these properties were only obtained when using system identification techniques that require knowledge of the kinematic structure. We apply DeLaN to learning dynamics models and apply these models to control simulated and physical rigid body systems. The results show that the proposed approach obtains dynamics models that can be applied to physical systems for real-time control. Compared to standard deep networks, the physics-inspired models learn better models and capture the underlying structure of the dynamics.},
	language = {en},
	urldate = {2023-05-03},
	journal = {The International Journal of Robotics Research},
	author = {Lutter, Michael and Peters, Jan},
	month = apr,
	year = {2023},
	note = {Publisher: SAGE Publications Ltd STM},
	keywords = {/unread},
	pages = {02783649231169492},
}

@misc{wangBenchmarkingModelBasedReinforcement2019,
	title = {Benchmarking {Model}-{Based} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1907.02057},
	doi = {10.48550/arXiv.1907.02057},
	abstract = {Model-based reinforcement learning (MBRL) is widely seen as having the potential to be significantly more sample efficient than model-free RL. However, research in model-based RL has not been very standardized. It is fairly common for authors to experiment with self-designed environments, and there are several separate lines of research, which are sometimes closed-sourced or not reproducible. Accordingly, it is an open question how these various existing MBRL algorithms perform relative to each other. To facilitate research in MBRL, in this paper we gather a wide collection of MBRL algorithms and propose over 18 benchmarking environments specially designed for MBRL. We benchmark these algorithms with unified problem settings, including noisy environments. Beyond cataloguing performance, we explore and unify the underlying algorithmic differences across MBRL algorithms. We characterize three key research challenges for future MBRL research: the dynamics bottleneck, the planning horizon dilemma, and the early-termination dilemma. Finally, to maximally facilitate future research on MBRL, we open-source our benchmark in http://www.cs.toronto.edu/{\textasciitilde}tingwuwang/mbrl.html.},
	urldate = {2023-02-28},
	publisher = {arXiv},
	author = {Wang, Tingwu and Bao, Xuchan and Clavera, Ignasi and Hoang, Jerrick and Wen, Yeming and Langlois, Eric and Zhang, Shunshi and Zhang, Guodong and Abbeel, Pieter and Ba, Jimmy},
	month = jul,
	year = {2019},
	note = {234 citations (Semantic Scholar/arXiv) [2023-04-11]
arXiv:1907.02057 [cs, stat]},
	keywords = {/unread, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning},
}

@article{sunBalanceControlQuadruped2022,
	title = {Balance {Control} of a {Quadruped} {Robot} {Based} on {Foot} {Fall} {Adjustment}},
	volume = {12},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/12/5/2521},
	doi = {10.3390/app12052521},
	abstract = {To balance the diagonal gait of a quadruped robot, a dynamic balance control method is presented to improve the stability of the quadruped robot by adjusting its foot position. We set up a trunk-based coordinate system and a hip-based local coordinate system for the quadruped robot, established the kinematics equation of the robot, and designed a reasonable initial diagonal gait through the spring inverted pendulum model. The current trunk posture of the quadruped robot is obtained by collecting the data of its pitch and roll angle, and the foot position is predicted according to the current posture and initial gait of the quadruped robot. To reduce the impact of one leg landing on the ground and increase the stability of the quadruped robot, we adjust the landing point of the robot according to the landing time difference between the diagonal legs. The proposed method can adjust the body in such scenarios as planar walking and lateral impact resistance. It can reduce the disturbance during the robot motion and make the robot move smoothly. The validity of this method is verified by simulation experiments.},
	language = {en},
	number = {5},
	urldate = {2023-05-16},
	journal = {Applied Sciences},
	author = {Sun, Wenkai and Tian, Xiaojie and Song, Yong and Pang, Bao and Yuan, Xianfeng and Xu, Qingyang},
	month = jan,
	year = {2022},
	note = {Number: 5
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {/unread, attitude feedback, diagonal gait, dynamic balance control, landing time difference, quadruped robot},
	pages = {2521},
}

@article{zhongAnalysisResearchQuadruped2019,
	title = {Analysis and research of quadruped robot’s legs: {A} comprehensive review},
	volume = {16},
	issn = {1729-8806},
	shorttitle = {Analysis and research of quadruped robot’s legs},
	url = {https://doi.org/10.1177/1729881419844148},
	doi = {10.1177/1729881419844148},
	abstract = {As an important basic component of quadruped robots, mechanical legs provide the robots with excellent maneuverability and versatility, which determine the core application performance such as job adaptability, walking speed, and load capacity. A large number of robotics institutes for the last few decades have studied mechanical legs used by quadruped robots and published many research results. In this article, we collect these research results and classify them into three categories (prismatic legs, articulated legs, and redundant articulated legs) according to the degrees of freedom and then introduce and analyze them. On this basis, we summarize and study the design methods of the actuators and mechanical leg structures. Finally, we make some suggestions for the development of quadruped robot?s legs in the future. The motivation of this review is to summarize and analyze previous research efforts and provide useful guidance for future robotic designers to develop more efficient mechanical legs of quadruped robots.},
	language = {en},
	number = {3},
	urldate = {2023-02-27},
	journal = {International Journal of Advanced Robotic Systems},
	author = {Zhong, Yuhai and Wang, Runxiao and Feng, Huashan and Chen, Yasheng},
	month = may,
	year = {2019},
	note = {27 citations (Semantic Scholar/DOI) [2023-04-11]
Publisher: SAGE Publications},
	keywords = {/unread},
	pages = {1729881419844148},
}

@book{slotineAppliedNonlinearControl1991,
	address = {Englewood Cliffs, N.J},
	title = {Applied nonlinear control},
	isbn = {978-0-13-040890-7},
	language = {en},
	publisher = {Prentice Hall},
	author = {Slotine, J.-J. E. and Li, Weiping},
	year = {1991},
	keywords = {/unread, Nonlinear control theory},
}

@article{annaswamyAdaptiveControlIntersections2023,
	title = {Adaptive {Control} and {Intersections} with {Reinforcement} {Learning}},
	volume = {6},
	url = {https://doi.org/10.1146/annurev-control-062922-090153},
	doi = {10.1146/annurev-control-062922-090153},
	abstract = {This article provides an exposition of the field of adaptive control and its intersections with reinforcement learning. Adaptive control and reinforcement learning are two different methods that are both commonly employed for the control of uncertain systems. Historically, adaptive control has excelled at real-time control of systems with specific model structures through adaptive rules that learn the underlying parameters while providing strict guarantees on stability, asymptotic performance, and learning. Reinforcement learning methods are applicable to a broad class of systems and are able to produce near-optimal policies for highly complex control tasks. This is often enabled by significant offline training via simulation or the collection of large input-state datasets. This article attempts to compare adaptive control and reinforcement learning using a common framework. The problem statement in each field and highlights of their results are outlined. Two specific examples of dynamic systems are used to illustrate the details of the two methods, their advantages, and their deficiencies. The need for real-time control methods that leverage tools from both approaches is motivated through the lens of this common framework. Expected final online publication date for the Annual Review of Control, Robotics, and Autonomous Systems, Volume 14 is May 2023. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.},
	number = {1},
	urldate = {2023-03-09},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Annaswamy, Anuradha M.},
	year = {2023},
	note = {2 citations (Semantic Scholar/DOI) [2023-04-11]
\_eprint: https://doi.org/10.1146/annurev-control-062922-090153},
	keywords = {/unread, Review},
	pages = {null},
}

@article{rechtTourReinforcementLearning2019,
	title = {A {Tour} of {Reinforcement} {Learning}: {The} {View} from {Continuous} {Control}},
	volume = {2},
	shorttitle = {A {Tour} of {Reinforcement} {Learning}},
	url = {https://doi.org/10.1146/annurev-control-053018-023825},
	doi = {10.1146/annurev-control-053018-023825},
	abstract = {This article surveys reinforcement learning from the perspective of optimization and control, with a focus on continuous control applications. It reviews the general formulation, terminology, and typical experimental implementations of reinforcement learning as well as competing solution paradigms. In order to compare the relative merits of various techniques, it presents a case study of the linear quadratic regulator (LQR) with unknown dynamics, perhaps the simplest and best-studied problem in optimal control. It also describes how merging techniques from learning theory and control can provide nonasymptotic characterizations of LQR performance and shows that these characterizations tend to match experimental behavior. In turn, when revisiting more complex applications, many of the observed phenomena in LQR persist. In particular, theory and experiment demonstrate the role and importance of models and the cost of generality in reinforcement learning algorithms. The article concludes with a discussion of some of the challenges in designing learning systems that safely and reliably interact with complex and uncertain environments and how tools from reinforcement learning and control might be combined to approach these challenges.},
	number = {1},
	urldate = {2023-03-09},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Recht, Benjamin},
	year = {2019},
	note = {432 citations (Semantic Scholar/DOI) [2023-04-11]
\_eprint: https://doi.org/10.1146/annurev-control-053018-023825},
	keywords = {/unread, Review, control theory, machine learning, optimization, reinforcement learning},
	pages = {253--279},
}

@inproceedings{muralidharanSoftQuadrupedRobot2021,
	title = {A soft quadruped robot enabled by continuum actuators},
	doi = {10.1109/CASE49439.2021.9551496},
	abstract = {Soft robots are a group of robots made from highly compliant materials. Compared to their rigid counterparts, soft robots show better mobility and stronger adaptability to the environment. Specifically, soft quadruped robots, using four soft actuators as robot legs, have become a popular design, and are proven to be feasible and reliable in performing soft locomotion. Traditional soft quadruped robots are actuated using pneumatic forces which require high pressure sources. Additionally, the travel range of these robots are limited. This paper proposes a new design of soft quadruped robot that is fully actuated with electric motors. The main components of the robot are 3D printed and can be easily assembled. The four soft legs of the robot are modeled with experimental data and a closed loop controller is developed to regulate the deformation and motion. The legs can perform complex movement which enables the quadruped robot to move with different gaits.},
	booktitle = {2021 {IEEE} 17th {International} {Conference} on {Automation} {Science} and {Engineering} ({CASE})},
	author = {Muralidharan, Seshagopalan Thorapalli and Zhu, Ruihao and Ji, Qinglei and Feng, Lei and Wang, Xi Vincent and Wang, Lihui},
	month = aug,
	year = {2021},
	note = {3 citations (Semantic Scholar/DOI) [2023-04-11]
0 citations (Crossref) [2022-12-07]
ISSN: 2161-8089},
	keywords = {/unread, 3D printing, Actuators, Legged locomotion, Pneumatic systems, Printing, Reliability engineering, Soft quadruped robot, Soft robotics, Three-dimensional displays, closed loop control, continuum actuators},
	pages = {834--840},
}

@article{liQuadrupedRobotObstacle2022,
	title = {A quadruped robot obstacle avoidance and personnel following strategy based on ultra-wideband and three-dimensional laser radar},
	volume = {19},
	issn = {1729-8806},
	url = {https://doi.org/10.1177/17298806221114705},
	doi = {10.1177/17298806221114705},
	abstract = {To improve the human–computer interaction ability and environmental adaptability of the quadruped robot, especially the ability of the quadruped robot to follow people and avoid obstacles. In this article, the fusion of ultra-wideband positioning technology and three-dimensional laser radar is applied to a quadruped robot. The core is to scan the surrounding obstacle information through three-dimensional laser radar, locate the position of both the quadruped robot and the target person, complete the obstacle avoidance, and follow the task of the quadruped robot through an efficient path planning algorithm. To meet the high-precision positioning requirements, the ultra-wideband positioning system is used in this article. When calculating the coordinates, we propose a three-sided weighted least squares positioning algorithm. To improve the efficiency and stability of the quadruped robot in path search, based on the A* algorithm, this article improves and proposes an incremental A* algorithm based on a sliding window. The feasibility and effectiveness of our method are verified by computer simulation analysis and real experiments of the quadruped robot.},
	language = {en},
	number = {4},
	urldate = {2023-07-03},
	journal = {International Journal of Advanced Robotic Systems},
	author = {Li, Zhi and Li, Bin and Liang, Qixing and Liu, Weilong and Hou, Landong and Rong, Xuewen},
	month = jul,
	year = {2022},
	note = {Publisher: SAGE Publications},
	keywords = {/unread},
	pages = {17298806221114705},
}

@article{dingNovelDynamicLocomotion2020,
	title = {A {Novel} {Dynamic} {Locomotion} {Control} {Method} for {Quadruped} {Robots} {Running} on {Rough} {Terrains}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.3016312},
	abstract = {Quadruped robots have excellent application prospects whereas the locomotion control of them on rough terrains is still a challenging problem, especially for those of large scales. The existing methods are either too complicated or lack of accuracies due to assumptions used. This paper presents a novel control algorithm for quadruped robots running on rough terrains inspired by the virtual model control and the model predictive control. State recursions are carried out based on the dynamic model of the trunk during the standing phase. The modeling of the body is implemented in the self-defined motion reference frame that avoids global state estimations and accumulative errors. The force distribution of the standing legs is realized by quadratic optimization involving state predictions. Forces of the swing legs are calculated by the virtual spring-damping model that follow the desired trajectory which is robust to external disturbances. These two sub-controllers are combined by the time-force based state machine. Simulation results show that the quadruped robot obtains the adaptability to rough terrains and robustness to lateral pushes with the proposed method.},
	journal = {IEEE Access},
	author = {Ding, Chao and Zhou, Lelai and Li, Yibin and Rong, Xuewen},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {/unread, Adaptation models, Dynamics, Legged locomotion, Model predictive control, Robot kinematics, Robot sensing systems, Trajectory, quadratic optimization, quadruped robots, terrain adaptation, virtual model control},
	pages = {150435--150446},
}

@article{owakiQuadrupedRobotExhibiting2017,
	title = {A {Quadruped} {Robot} {Exhibiting} {Spontaneous} {Gait} {Transitions} from {Walking} to {Trotting} to {Galloping}},
	volume = {7},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-017-00348-9},
	doi = {10.1038/s41598-017-00348-9},
	abstract = {Abstract
            
              The manner in which quadrupeds change their locomotive patterns—walking, trotting, and galloping—with changing speed is poorly understood. In this paper, we provide evidence for interlimb coordination during gait transitions using a quadruped robot for which coordination between the legs can be self-organized through a simple “central pattern generator” (CPG) model. We demonstrate spontaneous gait transitions between energy-efficient patterns by changing only the parameter related to speed. Interlimb coordination was achieved with the use of local load sensing only without any preprogrammed patterns. Our model exploits
              physical communication
              through the body, suggesting that knowledge of physical communication is required to understand the leg coordination mechanism in legged animals and to establish design principles for legged robots that can reproduce flexible and efficient locomotion.},
	language = {en},
	number = {1},
	urldate = {2023-02-28},
	journal = {Scientific Reports},
	author = {Owaki, Dai and Ishiguro, Akio},
	month = mar,
	year = {2017},
	note = {0 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread},
	pages = {277},
}

@inproceedings{atkesonComparisonDirectModelbased1997,
	title = {A comparison of direct and model-based reinforcement learning},
	volume = {4},
	doi = {10.1109/ROBOT.1997.606886},
	abstract = {This paper compares direct reinforcement learning (no explicit model) and model-based reinforcement learning on a simple task: pendulum swing up. We find that in this task model-based approaches support reinforcement learning from smaller amounts of training data and efficient handling of changing goals.},
	booktitle = {Proceedings of {International} {Conference} on {Robotics} and {Automation}},
	author = {Atkeson, C.G. and Santamaria, J.C.},
	month = apr,
	year = {1997},
	note = {261 citations (Semantic Scholar/DOI) [2023-04-11]},
	keywords = {/unread, Computational modeling, Control system synthesis, Control systems, Educational institutions, Force control, Jacobian matrices, Learning, Robots, State-space methods, Training data},
	pages = {3557--3564 vol.4},
}

@inproceedings{drotman3DPrintedSoft2017,
	title = {{3D} printed soft actuators for a legged robot capable of navigating unstructured terrain},
	doi = {10.1109/ICRA.2017.7989652},
	abstract = {Soft robots have recently demonstrated impressive abilities to adapt to objects and their environment with limited sensing and actuation. However, mobile soft robots are typically fabricated using laborious molding processes that result in limited actuated degrees of freedom and hence limited locomotion capabilities. In this paper, we present a 3D printed robot with bellowed soft legs capable of rotation about two axes. This allows our robot to navigate rough terrain that previously posed a significant challenge to soft robots. We present models and FEM simulations for the soft leg modules and predict the robot locomotion capabilities. We use finite element analysis to simulate the actuation characteristics of these modules. We then compared the analytical and computational results to experimental results with a tethered prototype. The experimental soft robot is capable of lifting its legs 5.3 cm off the ground and is able to walk at speeds up to 20 mm/s (0.13 bl/s). This work represents a practical approach to the design and fabrication of functional mobile soft robots.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Drotman, Dylan and Jadhav, Saurabh and Karimi, Mahmood and de Zonia, Philip and Tolley, Michael T.},
	month = may,
	year = {2017},
	note = {118 citations (Semantic Scholar/DOI) [2023-04-11]
91 citations (Crossref) [2022-12-07]},
	keywords = {/unread, Actuators, Bellows, Force, Geometry, Legged locomotion, Three-dimensional print},
	pages = {5532--5538},
}

@inproceedings{meng2016ReviewQuadrupedRobots,
	title = {A review of quadruped robots and environment perception},
	doi = {10.1109/ChiCC.2016.7554355},
	abstract = {As legged robots are suitable to be used in unstructured environments, it becomes a popular field of research nowadays. In this paper, the development of quadruped robots is summarized. And several typical and recent robot systems are addressed in details, such as HyQ series, StarlETH, ANYmal, MIT Cheetah and BigDog, etc. Furthermore, some key techniques of environment perception for quadruped robots, including sensors, feature extraction and identification, mapping and SLAM, are also discussed. Finally, future researches of quadruped robots in environment perception are given.},
	booktitle = {2016 35th {Chinese} {Control} {Conference} ({CCC})},
	author = {Meng, Xiangrui and Wang, Shuo and Cao, Zhiqiang and Zhang, Leijie},
	month = jul,
	year = {2016},
	note = {2 citations (Semantic Scholar/DOI) [2023-04-11]
10 citations (Crossref) [2022-12-07]
ISSN: 1934-1768},
	keywords = {/unread, Legged locomotion, Navigation, Pneumatic systems, Quadruped robot, Robot sensing systems, environment perception, feature extraction, mapping and SLAM, sensors},
	pages = {6350--6356},
}

@article{brunke2022SafeLearningRobotics,
	title = {Safe {Learning} in {Robotics}: {From} {Learning}-{Based} {Control} to {Safe} {Reinforcement} {Learning}},
	volume = {5},
	shorttitle = {Safe {Learning} in {Robotics}},
	url = {https://doi.org/10.1146/annurev-control-042920-020211},
	doi = {10.1146/annurev-control-042920-020211},
	abstract = {The last half decade has seen a steep rise in the number of contributions on safe learning methods for real-world robotic deployments from both the control and reinforcement learning communities. This article provides a concise but holistic review of the recent advances made in using machine learning to achieve safe decision-making under uncertainties, with a focus on unifying the language and frameworks used in control theory and reinforcement learning research. It includes learning-based control approaches that safely improve performance by learning the uncertain dynamics, reinforcement learning approaches that encourage safety or robustness, and methods that can formally certify the safety of a learned control policy. As data- and learning-based robot control methods continue to gain traction, researchers must understand when and how to best leverage them in real-world scenarios where safety is imperative, such as when operating in close proximityto humans. We highlight some of the open challenges that will drive the field of robot learning in the coming years, and emphasize the need for realistic physics-based benchmarks to facilitate fair comparisons between control and reinforcement learning approaches.},
	number = {1},
	urldate = {2022-12-12},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Brunke, Lukas and Greeff, Melissa and Hall, Adam W. and Yuan, Zhaocong and Zhou, Siqi and Panerati, Jacopo and Schoellig, Angela P.},
	year = {2022},
	note = {121 citations (Semantic Scholar/DOI) [2023-04-11]
\_eprint: https://doi.org/10.1146/annurev-control-042920-020211},
	keywords = {/unread, Review, adaptive control, benchmarks, learning-based control, machine learning, model predictive control, robot learning, robotics, robust control, safe learning, safe reinforcement learning},
	pages = {411--444},
}

@article{borenstein_real-time_1989,
	title = {Real-time obstacle avoidance for fast mobile robots},
	volume = {19},
	issn = {2168-2909},
	doi = {10.1109/21.44033},
	abstract = {A real-time obstacle avoidance approach for mobile robots has been developed and implemented. It permits the detection of unknown obstacles simultaneously with the steering of the mobile robot to avoid collisions and advance toward the target. The novelty of this approach, entitled the virtual force field method, lies in the integration of two known concepts: certainty grids for obstacle representation and potential fields for navigation. This combination is especially suitable for the accommodation of inaccurate sensor data as well as for sensor fusion and makes possible continuous motion of the robot with stopping in front of obstacles. This navigation algorithm also takes into account the dynamic behavior of a fast mobile robot and solves the local minimum trap problem. Experimental results from a mobile robot running at a maximum speed of 0.78 m/s demonstrate the power of the algorithm.{\textless}{\textgreater}},
	number = {5},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics},
	author = {Borenstein, J. and Koren, Y.},
	month = sep,
	year = {1989},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics},
	keywords = {/unread, Cleaning, Collision avoidance, Force sensors, Intelligent control, Mobile robots, Navigation, Path planning, Resumes, Robot sensing systems, Sensor fusion},
	pages = {1179--1187},
}

@misc{noauthor_research_nodate,
	title = {Research of mammal bionic quadruped robots: {A} review},
	shorttitle = {Research of mammal bionic quadruped robots},
	url = {https://ieeexplore.ieee.org/abstract/document/6070476/},
	abstract = {This paper focuses on the mammal bionic quadruped robots. The main challenge in this field is how to design the highly dynamical and high payload quadruped robots. This paper firstly introduces the history of bionic quadruped robots, particularly the landmark quadruped robots. Then the state-of-the art of drive mode for quadruped robots is reviewed. Subsequently, the development trend of quadruped robots is described. Based on the state-of-the art of quadruped robots, the technical difficulties of bionic quadruped robots are briefly reviewed. And the hydraulic quadruped robot developed in Shandong University is introduced. Finally, the summary and future work of the quadruped robots is given.},
	language = {en-US},
	urldate = {2023-05-16},
	keywords = {/unread},
}

@misc{noauthor_addon_nodate,
	title = {Addon {Item}},
	keywords = {/unread},
}

@misc{fuD4RLDatasetsDeep2021,
	title = {{D4RL}: {Datasets} for {Deep} {Data}-{Driven} {Reinforcement} {Learning}},
	shorttitle = {{D4RL}},
	url = {http://arxiv.org/abs/2004.07219},
	abstract = {The offline reinforcement learning (RL) setting (also known as full batch RL), where a policy is learned from a static dataset, is compelling as progress enables RL methods to take advantage of large, previously-collected datasets, much like how the rise of large datasets has fueled results in supervised learning. However, existing online RL benchmarks are not tailored towards the offline setting and existing offline RL benchmarks are restricted to data generated by partially-trained agents, making progress in offline RL difficult to measure. In this work, we introduce benchmarks specifically designed for the offline setting, guided by key properties of datasets relevant to real-world applications of offline RL. With a focus on dataset collection, examples of such properties include: datasets generated via hand-designed controllers and human demonstrators, multitask datasets where an agent performs different tasks in the same environment, and datasets collected with mixtures of policies. By moving beyond simple benchmark tasks and data collected by partially-trained RL agents, we reveal important and unappreciated deficiencies of existing algorithms. To facilitate research, we have released our benchmark tasks and datasets with a comprehensive evaluation of existing algorithms, an evaluation protocol, and open-source examples. This serves as a common starting point for the community to identify shortcomings in existing offline RL methods and a collaborative route for progress in this emerging area.},
	urldate = {2023-04-21},
	publisher = {arXiv},
	author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
	month = feb,
	year = {2021},
	note = {arXiv:2004.07219 [cs, stat]},
	keywords = {/unread, Computer Science - Machine Learning, Statistics - Machine Learning},
}
